# @package _global_
model:
  name: CRN
  encoder:                              # Missing hyperparameters are to be filled in command line / with tune_hparams = True / selected with +backbone/crn_hparams=...
    _target_: src.models.crn.CRNEncoder
    seq_hidden_units:                   # rnn_hidden_units in the original terminology
    br_size:
    fc_hidden_units:
    dropout_rate:                       # Dropout of LSTM hidden layers + output layers
    num_layer: 1
    batch_size:
    optimizer:
      optimizer_cls: adam
      learning_rate:
      weight_decay: 0.0
      lr_scheduler: False

    tune_hparams: False                 # Hparam tuning
    tune_range: 50
    hparams_grid:
    resources_per_trial:

  train_decoder: True
  decoder:                                # Missing hyperparameters are to be filled in command line / with tune_hparams = True / selected with +backbone/crn_hparams=...
    _target_: src.models.crn.CRNDecoder
    seq_hidden_units:                     # rnn_hidden_units in the original terminology
    br_size:
    fc_hidden_units:
    dropout_rate:                         # Dropout of LSTM hidden layers + output layers
    num_layer: 1
    batch_size:
    optimizer:
      optimizer_cls: adam
      learning_rate:
      weight_decay: 0.0
      lr_scheduler: False

    tune_hparams: False                   # Hparam tuning
    tune_range: 30
    hparams_grid:
    resources_per_trial:

exp:
  weights_ema: False
  balancing: grad_reverse