# @package _global_
model:
  name: CT_TCN

  rep_encoder:
    _target_: src.models.rep_est.cotrans.COTransMoCoEncoder
    max_seq_length: ${sum:${dataset.max_seq_length},${dataset.projection_horizon}}  # Will be calculated dynamically
    seq_hidden_units:                    # transformer hidden units (d_h / d_model)
    d_model: ${model.rep_encoder.seq_hidden_units}
    dropout_rate:                        # Dropout between transformer layers + output layers + attentional dropout
    num_layer: 1
    num_heads: 2
    max_grad_norm:
    batch_size:
    attn_dropout: True
    disable_cross_attention: False
    isolate_subnetwork: _
    temporal_positional_encoding:
      absolute: False
      trainable: True
      max_relative_position: 15
    feature_positional_encoding:
      absolute: False
    momentum:
    temperature:
    optimizer:
      optimizer_cls:
      learning_rate:
      weight_decay:
      lr_scheduler:
    use_comp_contrast: True

    tune_hparams: False                 # Hparam tuning

  train_head: True
  
  est_head:
    _target_: src.models.rep_est.MoCo.TCNEstHead
    emb_dim: ${model.rep_encoder.seq_hidden_units}
    hidden_dim:
    batch_size:
    step_mse_loss_weights_type: avg
    optimizer:
      optimizer_cls:
      learning_rate:
      weight_decay:
      lr_scheduler:

    tune_hparams: False