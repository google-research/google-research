# Set up for model training and benchmarking of quantized models.
# It is a good option for model reduction and latency optimization.
# It is still experimental.
# It uses --feature_type 'mfcc_op' which is numerically different
# with 'mfcc_tf', so there can be a difference in accuracy with 'mfcc_tf' models
# Below are just examples - we did not run any hyper parameter optimization.

# For post training model quantization you should use mfcc_op as shown in below.
# Note model has to be trained with feature mfcc_op.


## Set up environment:
# create main folder
mkdir /tmp/test
cd /tmp/test

# set path to a main folder
KWS_PATH=/tmp/test

# copy content of kws_streaming to a folder
/tmp/test/kws_streaming

# set up virtual env
sudo pip install virtualenv
virtualenv --system-site-packages -p python3 ./venv3
source ./venv3/bin/activate

# install TensorFlow
# correct TensorFlow version is important
pip install --upgrade pip
pip install tf_nightly # was tested on tf_nightly-2.3.0.dev20200515-cp36-cp36m-manylinux2010_x86_64.whl

# install pydot and graphviz
pip install pydot
pip install graphviz

## Set up data sets:

# There are two versions of data sets for training KWS which are well described
# in https://arxiv.org/pdf/1804.03209.pdf
# data sets V1 [2017]: http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz
# data sets V2 [2018]: https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz

# download and set up path to data set V1 and set it up
wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz
mkdir data1
mv ./speech_commands_v0.01.tar.gz ./data1
cd ./data1
tar -xf ./speech_commands_v0.01.tar.gz
cd ../

# download and set up path to data set V2 and set it up
wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz
mkdir data2
mv ./speech_commands_v0.02.tar.gz ./data2
cd ./data2
tar -xf ./speech_commands_v0.02.tar.gz
cd ../


## Set up models:

# download and set up path to models trained and evaluated on data sets V1
wget https://storage.googleapis.com/kws_models/models1_q.zip
mkdir models1_q
mv ./models1_q.zip ./models1_q
cd ./models1_q
unzip ./models1_q.zip
cd ../

# download and set up path to models trained and evaluated on data sets V2
wget https://storage.googleapis.com/kws_models/models2_q.zip
mkdir models2_q
mv ./models2_q.zip ./models2_q
cd ./models2_q
unzip ./models2_q.zip
cd ../

# After all of these, main folder should have several subfolders:
# /tmp/test/
            kws_streaming
                         colab
                         data
                         experiments
                         layers
                         models
                         train
            data1
                 _background_noise_
                 bed
                 ...
            data2
                 _background_noise_
                 bed
                 ...
            models1_q
                   att_rnn
                   cnn
                   ...
            models2_q
                   att_rnn
                   cnn
                   ...


# Set up TFLite based neural network benchmarking on phone
# To build benchmarking tools for Android
# you will need https://docs.bazel.build/versions/master/bazel-overview.html

# build benchmarking binary
bazel build -c opt --config=android_arm --cxxopt='--std=c++17' third_party/tensorflow/lite/tools/benchmark:benchmark_model

# check that phone is connected
adb devices

# copy benchmarking binary to phone
adb push bazel-bin/third_party/tensorflow/lite/tools/benchmark/benchmark_model /data/local/tmp

# allow executing benchmarking file as a program
adb shell chmod +x /data/local/tmp/benchmark_model


# build benchmarking binary - for a case if Flex is used by neural network model
bazel build -c opt --config=android_arm --cxxopt='--std=c++17' third_party/tensorflow/lite/tools/benchmark:benchmark_model_plus_flex

# check that phone is connected
adb devices

# copy benchmarking binary to phone
adb push bazel-bin/third_party/tensorflow/lite/tools/benchmark/benchmark_model_plus_flex /data/local/tmp

# allow executing benchmarking file as a program
adb shell chmod +x /data/local/tmp/benchmark_model_plus_flex

# Set data path to data V1 or data V2
# for example data V1
DATA_PATH=$KWS_PATH/data1


# Set models path to models trained on data V1 or data V2
# for example data V1
MODELS_PATH=$KWS_PATH/models1_q

# or models trained on data V2
# MODELS_PATH=$KWS_PATH/models2_q

# Now we can run below commands with "--train 0"
# which will evaluate the model and produce
# accuracy report with TFLite modules.
# If you would like to re-train model from scratch then you should:
# set "--train 0" and remove model subfolder inside of $MODELS_PATH

# depending on which data sets to use, set DATA_PATH

# To train model training evaluation we can use bazel (commented below)
# or use standard python

# CMD_TRAIN="bazel run -c opt --copt=-mavx2 kws_streaming/train:model_train_eval --"
CMD_TRAIN="python -m kws_streaming.train.model_train_eval"


# svdf =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/svdf/ \
--mel_upper_edge_hertz 7000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 80 \
--dct_num_features 30 \
--resample 0.15 \
--alsologtostderr \
--time_shift_ms 100 \
--train 0 \
--feature_type 'mfcc_op' \
svdf \
--svdf_memory_size 4,10,10,10,10,10 \
--svdf_units1 256,256,256,256,256,256 \
--svdf_act "'relu','relu','relu','relu','relu','relu'" \
--svdf_units2 128,128,128,128,128,-1 \
--svdf_dropout 0.0,0.0,0.0,0.0,0.0,0.0 \
--svdf_pad 0 \
--dropout1 0.0 \
--units2 '' \
--act2 ''


# lstm_peep =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/lstm_peep/ \
--mel_upper_edge_hertz 7000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 40 \
--dct_num_features 20 \
--resample 0.15 \
--alsologtostderr \
--train 0 \
--lr_schedule 'exp' \
--use_spec_augment 1 \
--time_masks_number 2 \
--time_mask_max_size 10 \
--frequency_masks_number 2 \
--frequency_mask_max_size 5 \
--feature_type 'mfcc_op' \
lstm \
--lstm_units 500 \
--return_sequences 0 \
--use_peepholes 1 \
--num_proj 200 \
--dropout1 0.3 \
--units1 '' \
--act1 '' \
--stateful 0


# crnn =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/crnn/ \
--mel_upper_edge_hertz 7000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 40 \
--dct_num_features 20 \
--resample 0.15 \
--alsologtostderr \
--train 0 \
--lr_schedule 'exp' \
--use_spec_augment 1 \
--time_masks_number 2 \
--time_mask_max_size 10 \
--frequency_masks_number 2 \
--frequency_mask_max_size 5 \
--feature_type 'mfcc_op' \
crnn \
--cnn_filters '16,16' \
--cnn_kernel_size '(3,3),(5,3)' \
--cnn_act "'relu','relu'" \
--cnn_dilation_rate '(1,1),(1,1)' \
--cnn_strides '(1,1),(1,1)' \
--gru_units 256 \
--return_sequences 0 \
--dropout1 0.1 \
--units1 '128,256' \
--act1 "'linear','relu'" \
--stateful 0


# crnn_state =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/crnn_state/ \
--mel_upper_edge_hertz 7000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 40 \
--dct_num_features 20 \
--resample 0.15 \
--alsologtostderr \
--train 0 \
--lr_schedule 'exp' \
--use_spec_augment 1 \
--time_masks_number 2 \
--time_mask_max_size 10 \
--frequency_masks_number 2 \
--frequency_mask_max_size 5 \
--feature_type 'mfcc_op' \
crnn \
--cnn_filters '16,16' \
--cnn_kernel_size '(3,3),(5,3)' \
--cnn_act "'relu','relu'" \
--cnn_dilation_rate '(1,1),(1,1)' \
--cnn_strides '(1,1),(1,1)' \
--gru_units 256 \
--return_sequences 0 \
--dropout1 0.1 \
--units1 '128,256' \
--act1 "'linear','relu'" \
--stateful 1


# dnn =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/dnn/ \
--mel_upper_edge_hertz 7000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 40 \
--dct_num_features 20 \
--resample 0.15 \
--alsologtostderr \
--train 0 \
--lr_schedule 'exp' \
--use_spec_augment 1 \
--time_masks_number 2 \
--time_mask_max_size 10 \
--frequency_masks_number 2 \
--frequency_mask_max_size 5 \
--feature_type 'mfcc_op' \
dnn \
--units1 '64,128' \
--act1 "'relu','relu'" \
--pool_size 2 \
--strides 2 \
--dropout1 0.1 \
--units2 '128,256' \
--act2 "'linear','relu'"


# att_mh_rnn =====================
$CMD_TRAIN \
--data_url '' \
--data_dir $DATA_PATH/ \
--train_dir $MODELS_PATH/att_mh_rnn/ \
--mel_upper_edge_hertz 8000 \
--how_many_training_steps 20000,20000,20000,20000 \
--learning_rate 0.001,0.0005,0.0001,0.00002 \
--window_size_ms 40.0 \
--window_stride_ms 20.0 \
--mel_num_bins 40 \
--dct_num_features 20 \
--resample 0.15 \
--alsologtostderr \
--train 0 \
--lr_schedule 'exp' \
--use_spec_augment 1 \
--time_masks_number 2 \
--time_mask_max_size 10 \
--frequency_masks_number 2 \
--frequency_mask_max_size 5 \
--feature_type 'mfcc_op' \
att_mh_rnn \
--cnn_filters '10,1' \
--cnn_kernel_size '(5,1),(5,1)' \
--cnn_act "'relu','relu'" \
--cnn_dilation_rate '(1,1),(1,1)' \
--cnn_strides '(1,1),(1,1)' \
--rnn_layers 2 \
--rnn_type 'gru' \
--rnn_units 128 \
--heads 4 \
--dropout1 0.2 \
--units2 '64,32' \
--act2 "'relu','linear'"
