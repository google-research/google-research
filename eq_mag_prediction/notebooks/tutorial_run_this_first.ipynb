{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pe8rUDv13WU"
      },
      "source": [
        "Copyright 2024 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJURSVoJ1uTL"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaPyEsBRT34F"
      },
      "source": [
        "# imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcYUpswoTySv"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numbers\n",
        "import xarray as xr\n",
        "from sklearn import metrics as skl_metrics\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.colors as mpl_colors\n",
        "\n",
        "\n",
        "#--- for printing formatted text\n",
        "from IPython.display import display, Markdown\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "from absl import flags\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.ticker import FixedLocator\n",
        "import logging\n",
        "\n",
        "import gin\n",
        "gin.enter_interactive_mode()\n",
        "\n",
        "np.set_printoptions(precision=4, threshold=2500)\n",
        "\n",
        "from eq_mag_prediction.scripts import calculate_benchmark_gr_properties\n",
        "from eq_mag_prediction.scripts import magnitude_predictor_trainer   # import unused for gin config\n",
        "from eq_mag_prediction.forecasting import metrics, training_examples\n",
        "from eq_mag_prediction.forecasting import encoders\n",
        "from eq_mag_prediction.forecasting import one_region_model\n",
        "from eq_mag_prediction.utilities import geometry\n",
        "from eq_mag_prediction.utilities import statistics_utils as statistics\n",
        "from eq_mag_prediction.utilities import catalog_analysis\n",
        "from eq_mag_prediction.utilities import simulate_catalog\n",
        "from eq_mag_prediction.utilities import data_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-5qKI8wjQsL"
      },
      "source": [
        "For the notebook to run, it needs the working directory to be the notebooks directory in the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J57dU3P-jQsL"
      },
      "outputs": [],
      "source": [
        "assert os.path.basename(os.getcwd()) == 'notebooks'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhtAl0y3IuGP"
      },
      "source": [
        "# Catalogs and configurations\n",
        "\n",
        "Training a model takes two things: a catalog (data) and a configuration (adequate hyper parameters).\n",
        "\n",
        "### Catalogs\n",
        "Catalogs need to be in a standard format in order to work with the package properly.\n",
        "Ingestion is the process of importing a catalog to the relevant location and\n",
        "adjusting its format to fit the package. Scripts that ingest the catalogs\n",
        "we worked on and convert them to the standard format are in `./ingestion`.\n",
        "The ingested catalogs are in `./results/catalogs/ingested`.\n",
        "\n",
        "For technical reasons, we cannot include the catalogs in this repo. You can\n",
        "download the catalogs from links provided in the script for each catalog. For\n",
        "demonstration, we use a mock catalog containing random data, which we call\n",
        "`mock` catalog.\n",
        "\n",
        "### Configuraion\n",
        "We use [gin-config](https://github.com/google/gin-config) to define the\n",
        "hyperparameters. Example of `gin` files are available in\n",
        "`results/trained_model/[CATALOG_NAME]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbF9x1nhj3za"
      },
      "source": [
        "#### Define the model to be analysed\n",
        "\n",
        "```MODEL_NAME``` should take the name of the relevant subdirectory under ```results/trained_models```.\n",
        "\n",
        "If set to ```mock``` an artificial, random, catalog will be generated and used for the tutorial. The artificial catalog will then be ingested (i.e. saved into a standard format) and a gin configuration file for training will be stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE2LYNRuIuGP"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'mock'\n",
        "# MODEL_NAME = 'Hauksson'\n",
        "# MODEL_NAME = 'JMA'\n",
        "\n",
        "# The following code generates and ingests a mock catalog, and saves a gin configuration file:\n",
        "if MODEL_NAME.lower() == 'mock':\n",
        "  simulate_catalog.mock_catalog_and_config_ingestion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zNm-Jl4jQsM"
      },
      "source": [
        "# Compute features\n",
        "the features for training are cimputed as a seperate step in the trainig pipeline as it may result in heavy lifting computation.\n",
        "\n",
        "The script ```magnitude_prediction_compute_features.py``` should be run from the command line interface, and will compute features for a given configuration (the relevant catalog should be defines in the ```config.gin``` file). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSgedmmrjQsM"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/magnitude_prediction_compute_features.py --gin_path='../results/trained_models/mock/config.gin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhnzIHASjQsM"
      },
      "source": [
        "# Model training\n",
        "The script ```magnitude_predictor_trainer.py``` will use the previously computed features to train a model and save it to the destination directory. Model architecture and training parameters are defined in a ```config.gin``` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfBTvpRhjQsN"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/magnitude_predictor_trainer.py --gin_config='../results/trained_models/mock/config.gin' --output_dir='../results/trained_models/mock/' --gin_bindings='train_and_evaluate_magnitude_prediction_model.epochs=3'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN9I5SYgjQsN"
      },
      "source": [
        "# Load the trained model\n",
        "The previous step trained a model and saved it. In order to examine its performance and results we will load it into the notebook.\n",
        "\n",
        "More useful objects will be loaded into the notebook. Documentation can be seen in inline comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4urzkI8dIuGP"
      },
      "outputs": [],
      "source": [
        "experiment_dir = os.path.join(os.getcwd(), '..', 'results/trained_models/', MODEL_NAME)\n",
        "custom_objects={\n",
        "    '_repeat': encoders._repeat,\n",
        "    }\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(\n",
        "    os.path.join(experiment_dir, 'model'),\n",
        "    custom_objects={'_repeat': encoders._repeat},\n",
        "    compile=False,\n",
        "    # safe_mode=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vPJD9Qjj3zb"
      },
      "source": [
        "Align notebook environment with model training configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh8jho_ZIuGP"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(experiment_dir, 'config.gin')) as f:\n",
        "    with gin.unlock_config():\n",
        "        gin.parse_config(f.read(), skip_unknown=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzG9T0W1j3zb"
      },
      "source": [
        "### Load useful objects\n",
        "\n",
        "By defining the gin.config above we ensure the defined objects will be identical to those used in the feature computation and model training scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esR5VctSIuGQ"
      },
      "outputs": [],
      "source": [
        "domain = training_examples.CatalogDomain()  # contains catalog and examples (time and space coordinates of earthquakes)\n",
        "labels = training_examples.magnitude_prediction_labels(domain)  # magnitudes of events\n",
        "all_encoders = one_region_model.build_encoders(domain)  # Load the trained encoders\n",
        "\n",
        "one_region_model.compute_and_cache_features_scaler_encoder(\n",
        "    domain,\n",
        "    all_encoders,\n",
        "    force_recalculate = False,\n",
        ")\n",
        "\n",
        "# Load the computed features. Nescessary for preforming the prediction\n",
        "scaler_saving_dir = os.path.join(os.getcwd(), '..', 'results/trained_models', MODEL_NAME, 'scalers')\n",
        "features_and_models = one_region_model.load_features_and_construct_models(\n",
        "    domain, all_encoders, scaler_saving_dir\n",
        ")\n",
        "train_features = one_region_model.features_in_order(features_and_models, 0)\n",
        "validation_features = one_region_model.features_in_order(features_and_models, 1)\n",
        "test_features = one_region_model.features_in_order(features_and_models, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKKsutB5j3zb"
      },
      "source": [
        "### Generate forecasts\n",
        "\n",
        "These are the predicted parameters defining the magnitude distribution per example.\n",
        "forecasts is a ```np.ndarray``` of size (number of examples in set)x(number of parameters of pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-3IpyL8IuGQ"
      },
      "outputs": [],
      "source": [
        "forecasts = {}\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "    forecasts[set_name] = loaded_model.predict(locals()[f'{set_name}_features'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgp3aCy5j3zb"
      },
      "source": [
        "# Plot resulting magnitude distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI4RN7Yij3zb"
      },
      "source": [
        "Plot the pdf predicted by the model MAGNET.\n",
        "Colors indicate the label magnitude, values of labels will be marked by stars of the corresponding colors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmsWuD4pj3zb"
      },
      "outputs": [],
      "source": [
        "# set the relevant probability density function\n",
        "probability_density_function = metrics.kumaraswamy_mixture_instance\n",
        "\n",
        "BETA_OF_TRAIN_SET = catalog_analysis.estimate_beta(labels.train_labels, None, 'BPOS')\n",
        "MAG_THRESH = domain.magnitude_threshold\n",
        "DAY_TO_SECONDS = 60*60*24\n",
        "\n",
        "# Create a shift function for labels\n",
        "# probability_density_function is defined with a [0,1] support.\n",
        "# It is then stretched and renormalized to support the relevant magnitude span. \n",
        "try:\n",
        "    support_stretch = gin.query_parameter('train_and_evaluate_magnitude_prediction_model.pdf_support_stretch')\n",
        "except:\n",
        "    default_stretch = 7\n",
        "    message = f\"\u003cspan style='color:red; font-size:25px'\u003epdf_support_stretch not defined in gin, setting to default: {default_stretch}\u003c/span\u003e\"\n",
        "    display(Markdown(message))\n",
        "    support_stretch = default_stretch\n",
        "\n",
        "random_var_shift = MAG_THRESH\n",
        "random_var_stretch = support_stretch\n",
        "\n",
        "costum_shift_stretch = lambda x, random_var_shift=random_var_shift, random_var_stretch=random_var_stretch: np.minimum((x - random_var_shift) / random_var_stretch, 1)\n",
        "shift_strech_input = costum_shift_stretch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0zA4gYUj3zb"
      },
      "outputs": [],
      "source": [
        "#---- setup data\n",
        "samples_to_plot = 4\n",
        "plot_above_thresh = MAG_THRESH\n",
        "m_vec = np.linspace(MAG_THRESH, 9, 500)\n",
        "prob_density_inst = probability_density_function(forecasts['test'])\n",
        "prob_vecs = prob_density_inst.prob((m_vec[:, None] - random_var_shift)/random_var_stretch)/random_var_stretch\n",
        "\n",
        "test_labels_to_plot_from = labels.test_labels[labels.test_labels\u003e=plot_above_thresh]\n",
        "prob_vecs_to_plot_from = prob_vecs.numpy()[:, labels.test_labels\u003e=plot_above_thresh]\n",
        "\n",
        "\n",
        "p_for_mags = np.exp(BETA_OF_TRAIN_SET*test_labels_to_plot_from)\n",
        "p_for_mags /= p_for_mags.sum()\n",
        "rnd_seed = np.random.RandomState(seed=1905)\n",
        "label_idxs_to_plot = np.sort(rnd_seed.choice(prob_vecs_to_plot_from.shape[1],samples_to_plot, replace=False, p=p_for_mags))\n",
        "labels_to_plot = test_labels_to_plot_from[label_idxs_to_plot]\n",
        "\n",
        "\n",
        "#--- setup figure\n",
        "num_mags = 25\n",
        "min_mag = 2\n",
        "max_mag = 6.5\n",
        "m_scale = np.linspace(min_mag-0.01, max_mag, num_mags)\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "\n",
        "chosen_colormap = mpl.colormaps['coolwarm']\n",
        "colors = chosen_colormap(np.linspace(0,1,num_mags))\n",
        "colors2plot = colors[np.argmin(np.abs(test_labels_to_plot_from[label_idxs_to_plot][:,None] - m_scale[None,:]), axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfiRtY3Ij3zb"
      },
      "outputs": [],
      "source": [
        "#---- Plot\n",
        "f_dist_fig, ax_dist_fig = plt.subplots(1,1,)\n",
        "\n",
        "for idx, lbl_index in enumerate(label_idxs_to_plot):\n",
        "  p = ax_dist_fig.plot(m_vec, prob_vecs_to_plot_from[:, lbl_index], alpha=0.4, color=colors2plot[idx], linewidth=4);\n",
        "for idx, lbl_index in enumerate(label_idxs_to_plot):\n",
        "  x_mark = labels_to_plot[idx]\n",
        "  p_idx = np.argmin(np.abs(m_vec - x_mark))\n",
        "  y_mark = prob_vecs_to_plot_from[p_idx, lbl_index]\n",
        "  ax_dist_fig.scatter(x_mark, y_mark, s=50, marker='*', color=colors2plot[idx], edgecolor='black', linewidth=0.5, zorder=np.inf)\n",
        "\n",
        "\n",
        "# plot GR train set\n",
        "train_gr_curve = metrics.gr_likelihood(m_vec, BETA_OF_TRAIN_SET, MAG_THRESH)\n",
        "gr_handle = ax_dist_fig.plot(m_vec, train_gr_curve, 'k--', label='train_gr_likelihood', linewidth=3)\n",
        "ax_dist_fig.legend(handles=gr_handle, frameon=False)\n",
        "\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "sm = plt.cm.ScalarMappable(cmap=chosen_colormap, norm=norm_inst);\n",
        "\n",
        "cb = plt.colorbar(sm, ax=ax_dist_fig, label='True magnitude (label)')\n",
        "ax_dist_fig.set_xlabel('magnitude')\n",
        "ax_dist_fig.set_ylabel('p(magnitude)')\n",
        "ax_dist_fig.set_xscale('linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5BAMLVB2-VK"
      },
      "source": [
        "# Advanced users - further analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRav_icTuPOX"
      },
      "source": [
        "## Set relevant probability density and other definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og97zyM5tvbC"
      },
      "outputs": [],
      "source": [
        "timestamps_dict = calculate_benchmark_gr_properties.create_timestamps_dict(domain)\n",
        "test_timestamps = timestamps_dict['test']\n",
        "validation_timestamps = timestamps_dict['validation']\n",
        "train_timestamps = timestamps_dict['train']\n",
        "all_timestamps = np.concatenate([train_timestamps, validation_timestamps, test_timestamps])\n",
        "\n",
        "coordinates_dict = calculate_benchmark_gr_properties.create_coordinates_dict(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xej2uP02YOa"
      },
      "source": [
        "## Functions for computing likelihoods and baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_KVhGp8j3zb"
      },
      "outputs": [],
      "source": [
        "# Plot lines font colors etc...\n",
        "\n",
        "listed_colors_discrete = [\n",
        "    '#e41a1c',\n",
        "    '#377eb8',\n",
        "    '#4daf4a',\n",
        "    '#984ea3',\n",
        "    '#ff7f00',\n",
        "    '#ffff33',\n",
        "    '#f0027f',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiXCGIktYQ5E"
      },
      "outputs": [],
      "source": [
        "def likelihood_probability_func(\n",
        "      labels,\n",
        "      forecasts,\n",
        "      shift = random_var_shift,\n",
        "      stretch = random_var_stretch,\n",
        "      ):\n",
        "  # Create a tfp.distributions.Distribution instance:\n",
        "  random_variable = probability_density_function(\n",
        "      tf.convert_to_tensor(forecasts))\n",
        "  labels_tensor = tf.reshape(tf.convert_to_tensor(labels, dtype=forecasts.dtype), (-1,))\n",
        "  likelihood = random_variable.prob(shift_strech_input(labels_tensor))/stretch\n",
        "  return likelihood\n",
        "\n",
        "def split_name_to_model_and_set(name):\n",
        "  under_score_idx = name[::-1].find('_')\n",
        "  current_model = name[:-(under_score_idx+1)]\n",
        "  set_name = name[-(under_score_idx):]\n",
        "  return (current_model, set_name)\n",
        "\n",
        "def sort_strings_w_constraint(list_of_strings, start_with_constraint):\n",
        "  sorted_list = []\n",
        "  for cons in start_with_constraint:\n",
        "    cons_list = [l for l in list_of_strings if l.startswith(cons)]\n",
        "    cons_list.sort()\n",
        "    sorted_list += cons_list\n",
        "  remains_list = list(set(list_of_strings) - set(sorted_list))\n",
        "  remains_list.sort()\n",
        "  sorted_list += remains_list\n",
        "  return sorted_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zqJy47k6Vp_"
      },
      "source": [
        "# Compute model's results and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px0AqLqMjQsP"
      },
      "source": [
        "The following command computes benchmark magnitude predictors and caches the results.\u003cbr\u003e\n",
        "In order to perform the calculation, the script will require the *```domain```*,\n",
        "an instance of ```training_examples.CatalogDomain```. This is defined by the flag:\u003cbr\u003e\n",
        "```--domain_path='path/to/relevant/domain'```\n",
        "\n",
        "\n",
        "If benchmarks are already cached, they will not be recomputed unless specified explicitly by the flag \u003cbr\u003e\n",
        "```--force_recalculate=True```.\n",
        "\n",
        "If some benchmarks are to be excluded, specify in a dictionary format, for example:\u003cbr\u003e\n",
        "```--compute_benchmark='n_past_events_kde=False'```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uja7zLNOjQsP"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/calculate_benchmark_gr_properties.py --domain_path='../results/trained_models/mock/domain' --compute_benchmark='n_past_events_kde=False, spatial_gr=False' --force_recalculate=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbPRREP0xpo"
      },
      "source": [
        "### Collect $\\beta$ and $m_c$ for GR variation benchmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHXjNbg2jQsP"
      },
      "source": [
        "The following cell preforms the benchmark calculation, as the cmd above does, but with an in-notebook workaround.\n",
        "The function ```calculate_benchmark_gr_properties.compute_and_assign_benchmarks_all_sets``` will either calculate the benchmarks or load them if already calculated and cached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQSYjQpomr_O"
      },
      "outputs": [],
      "source": [
        "# Set cache path\n",
        "GR_PROPERTIES_CACHE = os.path.join(\n",
        "    os.getcwd(), '..', 'results/cached_benchmarks'\n",
        ")\n",
        "\n",
        "custom_args = [\n",
        "    f\"--{calculate_benchmark_gr_properties._CACHE_DIR.name}=GR_PROPERTIES_CACHE\",\n",
        "    f\"--{calculate_benchmark_gr_properties._FORCE_RECALCULATE.name}=False\",\n",
        "]\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS(custom_args)\n",
        "\n",
        "\n",
        "# show logging info while running\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Load the benchmarks\n",
        "LOAD_KDE = False\n",
        "gr_models_beta, gr_models_mc = calculate_benchmark_gr_properties.compute_and_assign_benchmarks_all_sets(\n",
        "    domain,\n",
        "    timestamps_dict,\n",
        "    coordinates_dict,\n",
        "    BETA_OF_TRAIN_SET,\n",
        "    MAG_THRESH,\n",
        "    # compute_benchmark={'spatial_gr':False},\n",
        "    compute_benchmark={'n_past_events_kde':LOAD_KDE, 'spatial_gr':False},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjMJlv7eIpyR"
      },
      "outputs": [],
      "source": [
        "# Rename some keys\n",
        "for k in iter(list(gr_models_beta.keys())):\n",
        "  if not k.startswith('gr_spatial'):\n",
        "    continue\n",
        "  k_new = k.replace('gr_spatial', 'spatial_gr')\n",
        "  gr_models_beta[k_new] = gr_models_beta.pop(k)\n",
        "  gr_models_mc[k_new] = gr_models_mc.pop(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2M9ghLDFIN"
      },
      "source": [
        "## Compute likelihoods of models and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxe951tIuGT"
      },
      "source": [
        "### Benchmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s_FQT7rDKV3"
      },
      "outputs": [],
      "source": [
        "gr_likelihoods_and_baselines = {}\n",
        "for k in gr_models_beta:\n",
        "  set_name = k.split('_')[-1]\n",
        "  if 'events_kde' in k:\n",
        "    gr_likelihoods_and_baselines[k] = np.array(\n",
        "        [kde(l) for kde,l in zip(gr_models_beta[k], getattr(labels, f'{set_name}_labels'))]\n",
        "        ).ravel()\n",
        "  else:\n",
        "    gr_likelihoods_and_baselines[k] = metrics.gr_likelihood(\n",
        "        getattr(labels, f'{set_name}_labels'),\n",
        "        gr_models_beta[k],\n",
        "        gr_models_mc[k],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWHZg8hIuGU"
      },
      "source": [
        "### Model's scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4AdQDiJK9E"
      },
      "outputs": [],
      "source": [
        "likelihoods_and_baselines = {}\n",
        "\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "  likelihoods_and_baselines[f'model_{MODEL_NAME}_likelihood_{set_name}'] = np.array(\n",
        "      likelihood_probability_func(\n",
        "          getattr(labels, f'{set_name}_labels'),\n",
        "          forecasts[set_name],\n",
        "          MAG_THRESH,\n",
        "          )\n",
        "      )\n",
        "\n",
        "likelihoods_and_baselines.update(gr_likelihoods_and_baselines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Wxu2G0vjMj"
      },
      "source": [
        "## Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMcQ4mrR3Vsn"
      },
      "outputs": [],
      "source": [
        "# Select benchmarks to display by commenting / uncommenting\n",
        "\n",
        "MODELS_TO_PLOT = [split_name_to_model_and_set(k)[0] for k in likelihoods_and_baselines.keys() if k.startswith('model_') \u0026 k.endswith('_test')]\n",
        "MODELS_TO_PLOT += [\n",
        "    'train_gr_likelihood',\n",
        "    'test_gr_likelihood',\n",
        "    # 'gr_last_10_days_constant_mc_likelihood',\n",
        "    'gr_last_100_days_constant_mc_likelihood',\n",
        "    # 'gr_last_1000_days_constant_mc_likelihood',\n",
        "    # 'gr_last_10_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_100_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_1000_days_fitted_mc_likelihood',\n",
        "    'n300_past_events_constant_mc',\n",
        "    # 'n300_present_events_constant_mc',\n",
        "    # 'n300_past_events_fitted_mc',\n",
        "    # 'n300_present_events_fitted_mc',\n",
        "    # 'spatial_gr_on_all_likelihood',\n",
        "    # 'spatial_gr_on_train_likelihood',\n",
        "    # 'gr_spatial_on_train_likelihood',\n",
        "    # 'spatial_gr_on_test_likelihood',\n",
        "    # 'n300_past_events_kde_constant_mc'\n",
        "]\n",
        "MODELS_TO_PLOT = sort_strings_w_constraint(MODELS_TO_PLOT, ['model', 'train', 'test', 'gr', 'n', 'saptial'])\n",
        "\n",
        "COLOR_PER_MODEL = {m:listed_colors_discrete[i] for i,m in enumerate(MODELS_TO_PLOT)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ukhMYaBIuGV"
      },
      "source": [
        "## Calculate the minus mean log-likelihood score   $-\u003c\\mathcal{L}\u003e$\n",
        "Lower score = better score.\n",
        "\n",
        "**Notice than with the default settings of the tutorial notebook, random data is used and MAGNET is expected to lose.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCz1tb4ZJ1fh"
      },
      "outputs": [],
      "source": [
        "def create_scores_summary_df(\n",
        "    likelihoods_and_baselines_dictionary,\n",
        "    per_set_boolean_filter=None,\n",
        "    exclude_zeros=False,\n",
        "    drop_nans=True\n",
        "    ):\n",
        "  model_names = set()\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    under_score_idx = k[::-1].find('_')\n",
        "    model_name = k[:-(under_score_idx+1)]\n",
        "    model_names.add(model_name)\n",
        "\n",
        "  summary_df = pd.DataFrame(\n",
        "      index=sort_strings_w_constraint(\n",
        "          list(model_names),\n",
        "           ['model_', 'train', 'test', 'gr_', 'n_'],\n",
        "          ),\n",
        "      columns=['train', 'validation', 'test'],\n",
        "      )\n",
        "\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    current_model, set_name = split_name_to_model_and_set(k)\n",
        "\n",
        "    total_logical = np.full_like(likelihoods_and_baselines_dictionary[k].ravel(), True).astype(bool)\n",
        "    if per_set_boolean_filter is not None:\n",
        "      total_logical = total_logical \u0026 per_set_boolean_filter[set_name]\n",
        "    if exclude_zeros:\n",
        "      total_logical = total_logical \u0026 (likelihoods_and_baselines_dictionary[k]!=0)\n",
        "    if drop_nans:\n",
        "      total_logical = total_logical \u0026 (~np.isnan(likelihoods_and_baselines_dictionary[k]))\n",
        "\n",
        "    summary_df.loc[current_model, set_name] = float(-np.log(likelihoods_and_baselines_dictionary[k][total_logical]).mean())\n",
        "  return summary_df.apply(pd.to_numeric)\n",
        "\n",
        "summary_df_mean_ll = create_scores_summary_df(likelihoods_and_baselines, drop_nans=True, exclude_zeros=True)\n",
        "summary_df_mean_ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLzxmylZrNKn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_grad_colormap(original_color):\n",
        "  listed_colors_discrete = [\n",
        "      list(original_color),\n",
        "      (1, 1, 1, 1),\n",
        "      ]\n",
        "  return mpl_colors.LinearSegmentedColormap.from_list('grad_colormap', np.array(listed_colors_discrete))\n",
        "\n",
        "\n",
        "def barplot_scores(scores_summary_df, models_to_plot_list, colors=None, set_name='test'):\n",
        "  data_column = scores_summary_df[set_name].loc[MODELS_TO_PLOT]\n",
        "  are_infs = np.isinf(data_column)\n",
        "  non_inf_max = data_column[~are_infs].max()\n",
        "  margin = (non_inf_max - data_column[~are_infs].min())/4\n",
        "  replace_inf_val = np.max(data_column[~are_infs]) + 2*margin\n",
        "  data_column[are_infs] = replace_inf_val\n",
        "  infs_bars = np.where(are_infs)[0]\n",
        "\n",
        "\n",
        "  f, ax = plt.subplots(1, 1)\n",
        "  bars_handle = ax.bar(\n",
        "      models_to_plot_list,\n",
        "      data_column,\n",
        "      color=colors\n",
        "      )\n",
        "  #-- account for infs:\n",
        "  if infs_bars.size \u003e 0:\n",
        "    bar_ax = bars_handle[0].axes\n",
        "    lim = bar_ax.get_xlim()+bar_ax.get_ylim()\n",
        "    for inf_idx in infs_bars:\n",
        "      bar = bars_handle[inf_idx]\n",
        "      bar.set_zorder(1)\n",
        "      original_color = bar.get_facecolor()\n",
        "      grad_colormap = get_grad_colormap(original_color)\n",
        "      bar.set_facecolor(\"none\")\n",
        "      x,y = bar.get_xy()\n",
        "      w, h = bar.get_width(), bar.get_height()\n",
        "      grad = np.atleast_2d(np.linspace(replace_inf_val, 0, 1000)).T\n",
        "      normalizer = mpl.colors.PowerNorm(0.8, vmin=replace_inf_val-margin, vmax=replace_inf_val)\n",
        "      ax.imshow(grad, extent=[x,x+w,y,y+h], aspect=\"auto\", zorder=0, cmap=grad_colormap, norm=normalizer)\n",
        "      ax.text(x+w/2, replace_inf_val, '$\\infty$', ha='center', color=original_color)\n",
        "    bar_ax.axis(lim)\n",
        "\n",
        "  max_y = data_column.max() + margin\n",
        "  min_y = data_column.min() - margin\n",
        "  ax.set_ylim(min_y, max_y)\n",
        "  for label in ax.get_xticklabels():\n",
        "    label.set(rotation=-30, horizontalalignment='left')\n",
        "  ax.set_ylabel(r'$-\\langle \\log \\leftparen \\mathtt{likelihood} \\rightparen \\rangle$')\n",
        "  return f, ax\n",
        "\n",
        "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
        "f_meanLL_barplot, ax_meanLL_barplot = barplot_scores(summary_df_mean_ll, MODELS_TO_PLOT, [COLOR_PER_MODEL[m] for m in MODELS_TO_PLOT])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//intelligence/earthquakes/colab:notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "142GRBMltYO8FTYzxJba0Nsuc2K6I3rU8",
          "timestamp": 1719071116469
        },
        {
          "file_id": "1x-ci7axx8_HPy-VThOywdPRnL9RCIZ73",
          "timestamp": 1707386996321
        },
        {
          "file_id": "1Ol2MByyPj9rv_dEMpqQWjXfVbrKY2R77",
          "timestamp": 1699277925468
        },
        {
          "file_id": "1X0uCXEsHaG6qH9nZBPo4yVFfjJ9bJySH",
          "timestamp": 1696314810048
        },
        {
          "file_id": "1Pel6FQL10BrAMuX44uk7E8YBtsJgErqA",
          "timestamp": 1691663081634
        },
        {
          "file_id": "1Rdt5eMiL31MblVNFT_GCF25qNGsooh0s",
          "timestamp": 1678092594120
        },
        {
          "file_id": "1cKMZ5nhX_tyW19rw3n1vonhRkLyukGg9",
          "timestamp": 1673957299492
        },
        {
          "file_id": "1Cda53khxHslAUQno6Lw02Ye4q7AWezjm",
          "timestamp": 1673869854946
        },
        {
          "file_id": "1GyuN0CLKvEEb6bufw5LTgqlnSop37Q39",
          "timestamp": 1673786767072
        },
        {
          "file_id": "1f3zM6j4DhjkA0Axhq_zGWSqL7tVK-Ijx",
          "timestamp": 1673444962135
        },
        {
          "file_id": "1FV55Uz5BggBpjsaGszKuXv3sUkWwiujo",
          "timestamp": 1672903019087
        },
        {
          "file_id": "1T7WlP4i5_9xe3H4klPFuIO0a55IN_BMY",
          "timestamp": 1669812340393
        },
        {
          "file_id": "1w-4UtNzqu0Jq0pnZt4gDyQNOX1aMRh_K",
          "timestamp": 1662983276624
        },
        {
          "file_id": "1aqEOiuBdr-UKuymkaqC2XL6psjnInZeJ",
          "timestamp": 1660034359535
        },
        {
          "file_id": "1qT62S_OaBOUQHlKcFnJQGrL9LK_aEPmz",
          "timestamp": 1658839391585
        },
        {
          "file_id": "1S4YbtcFlTECFwhSYu3REOT2D6gzkxJ_O",
          "timestamp": 1655717124037
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
