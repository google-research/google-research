{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pe8rUDv13WU"
      },
      "source": [
        "Copyright 2024 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJURSVoJ1uTL"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaPyEsBRT34F"
      },
      "source": [
        "# imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcYUpswoTySv"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numbers\n",
        "import xarray as xr\n",
        "from sklearn import metrics as skl_metrics\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.colors as mpl_colors\n",
        "\n",
        "\n",
        "#--- for printing formatted text\n",
        "from IPython.display import display, Markdown\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "from absl import flags\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.ticker import FixedLocator\n",
        "import logging\n",
        "\n",
        "import gin\n",
        "gin.enter_interactive_mode()\n",
        "\n",
        "np.set_printoptions(precision=4, threshold=2500)\n",
        "\n",
        "from eq_mag_prediction.scripts import calculate_benchmark_gr_properties\n",
        "from eq_mag_prediction.scripts import magnitude_predictor_trainer   # import unused for gin config\n",
        "from eq_mag_prediction.forecasting import metrics, training_examples\n",
        "from eq_mag_prediction.forecasting import encoders\n",
        "from eq_mag_prediction.forecasting import one_region_model\n",
        "from eq_mag_prediction.utilities import geometry\n",
        "from eq_mag_prediction.utilities import statistics_utils as statistics\n",
        "from eq_mag_prediction.utilities import catalog_analysis\n",
        "from eq_mag_prediction.utilities import simulate_catalog\n",
        "from eq_mag_prediction.utilities import data_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v37f3S_MXw-7"
      },
      "outputs": [],
      "source": [
        "# Plot lines font colors etc...\n",
        "\n",
        "listed_colors_discrete = [\n",
        "    '#e41a1c',\n",
        "    '#377eb8',\n",
        "    '#4daf4a',\n",
        "    '#984ea3',\n",
        "    '#ff7f00',\n",
        "    '#ffff33',\n",
        "    '#f0027f',\n",
        "]\n",
        "\n",
        "color_list_cmap = mpl_colors.ListedColormap(listed_colors_discrete)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-5qKI8wjQsL"
      },
      "source": [
        "For the notebook to run, it needs the working directory to be the notebooks directory in the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J57dU3P-jQsL"
      },
      "outputs": [],
      "source": [
        "assert os.path.basename(os.getcwd()) == 'notebooks'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhtAl0y3IuGP"
      },
      "source": [
        "# Catalogs and configurations\n",
        "\n",
        "Models needs two things to work: data (a catalog) and hyper parameters.\n",
        "\n",
        "### Catalogs\n",
        "Catalogs need to be in a standard format, this is the ingestion process. Scripts\n",
        "that ingest the catalogs we worked on and convert them to the standard format\n",
        "are in `./ingestion`. The ingested catalogs are in `./results/catalogs/ingested`.\n",
        "\n",
        "For technical reasons, we cannot include the catalogs in this repo. You can\n",
        "download the catalogs from links provided in the script for each catalog. For\n",
        "demonstration, we use a mock catalog containing random data, which we call\n",
        "`mock` catalog.\n",
        "\n",
        "### Configuraion\n",
        "We use [gin-config](https://github.com/google/gin-config) to define the\n",
        "hyperparameters. Example of `gin` files are available in\n",
        "`results/trained_model/[CATALOG_NAME]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTvi3eRcjQsM"
      },
      "source": [
        "The following code:\n",
        "1. Generates a mock catalog\n",
        "2. Ingests it to a standard format\n",
        "3. Generates a gin configuration file for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE2LYNRuIuGP"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'mock'\n",
        "# MODEL_NAME = 'Hauksson'\n",
        "# MODEL_NAME = 'JMA'\n",
        "\n",
        "# The following code generates and ingests a mock catalog.\n",
        "if MODEL_NAME.lower() == 'mock':\n",
        "  simulate_catalog.mock_catalog_and_config_ingestion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zNm-Jl4jQsM"
      },
      "source": [
        "#### Compute features from the catalog, and cache them for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSgedmmrjQsM"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/magnitude_prediction_compute_features.py --gin_path='../results/trained_models/mock/config.gin'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhnzIHASjQsM"
      },
      "source": [
        "#### Train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfBTvpRhjQsN"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/magnitude_predictor_trainer.py --gin_config='../results/trained_models/mock/config.gin' --output_dir='../results/trained_models/mock/' --gin_bindings='train_and_evaluate_magnitude_prediction_model.epochs=3'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN9I5SYgjQsN"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4urzkI8dIuGP"
      },
      "outputs": [],
      "source": [
        "experiment_dir = os.path.join(os.getcwd(), '..', 'results/trained_models/', MODEL_NAME)\n",
        "custom_objects={\n",
        "    '_repeat': encoders._repeat,\n",
        "    }\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(\n",
        "    os.path.join(experiment_dir, 'model'),\n",
        "    custom_objects={'_repeat': encoders._repeat},\n",
        "    compile=False,\n",
        "    # safe_mode=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh8jho_ZIuGP"
      },
      "outputs": [],
      "source": [
        "# set gin configs\n",
        "with open(os.path.join(experiment_dir, 'config.gin')) as f:\n",
        "    with gin.unlock_config():\n",
        "        gin.parse_config(f.read(), skip_unknown=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esR5VctSIuGQ"
      },
      "outputs": [],
      "source": [
        "domain = training_examples.CatalogDomain()\n",
        "labels = training_examples.magnitude_prediction_labels(domain)\n",
        "\n",
        "scaler_saving_dir = os.path.join(os.getcwd(), '..', 'results/trained_models', MODEL_NAME, 'scalers')\n",
        "\n",
        "labels = training_examples.magnitude_prediction_labels(domain)\n",
        "all_encoders = one_region_model.build_encoders(domain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckNGwIbZIuGQ"
      },
      "outputs": [],
      "source": [
        "one_region_model.compute_and_cache_features_scaler_encoder(\n",
        "    domain,\n",
        "    all_encoders,\n",
        "    force_recalculate = False,\n",
        ")\n",
        "features_and_models = one_region_model.load_features_and_construct_models(\n",
        "    domain, all_encoders, scaler_saving_dir\n",
        ")\n",
        "train_features = one_region_model.features_in_order(features_and_models, 0)\n",
        "validation_features = one_region_model.features_in_order(features_and_models, 1)\n",
        "test_features = one_region_model.features_in_order(features_and_models, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-3IpyL8IuGQ"
      },
      "outputs": [],
      "source": [
        "forecasts = {}\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "    forecasts[set_name] = loaded_model.predict(locals()[f'{set_name}_features'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5BAMLVB2-VK"
      },
      "source": [
        "# Analysis and plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRav_icTuPOX"
      },
      "source": [
        "## Set relevant probability density and other definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qXHtd1dduLK4"
      },
      "outputs": [],
      "source": [
        "# set the relevant probability density function\n",
        "probability_density_function = metrics.kumaraswamy_mixture_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yAwSgPL500z"
      },
      "outputs": [],
      "source": [
        "BETA_OF_TRAIN_SET = catalog_analysis.estimate_beta(labels.train_labels, None, 'BPOS')\n",
        "MAG_THRESH = domain.magnitude_threshold\n",
        "DAY_TO_SECONDS = 60*60*24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flIqONWBIuGS"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    support_stretch = gin.query_parameter('train_and_evaluate_magnitude_prediction_model.pdf_support_stretch')\n",
        "except:\n",
        "    default_stretch = 7\n",
        "    message = f\"\u003cspan style='color:red; font-size:25px'\u003epdf_support_stretch not defined in gin, setting to default: {default_stretch}\u003c/span\u003e\"\n",
        "    display(Markdown(message))\n",
        "    support_stretch = default_stretch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-UL2CraofCo"
      },
      "outputs": [],
      "source": [
        "# Create a shift function for labels\n",
        "\n",
        "random_var_shift = MAG_THRESH\n",
        "random_var_stretch = support_stretch\n",
        "\n",
        "costum_shift_stretch = lambda x, random_var_shift=random_var_shift, random_var_stretch=random_var_stretch: np.minimum((x - random_var_shift) / random_var_stretch, 1)\n",
        "shift_strech_input = costum_shift_stretch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og97zyM5tvbC"
      },
      "outputs": [],
      "source": [
        "timestamps_dict = calculate_benchmark_gr_properties.create_timestamps_dict(domain)\n",
        "test_timestamps = timestamps_dict['test']\n",
        "validation_timestamps = timestamps_dict['validation']\n",
        "train_timestamps = timestamps_dict['train']\n",
        "all_timestamps = np.concatenate([train_timestamps, validation_timestamps, test_timestamps])\n",
        "\n",
        "coordinates_dict = calculate_benchmark_gr_properties.create_coordinates_dict(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xej2uP02YOa"
      },
      "source": [
        "## Functions for computing likelihoods and baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiXCGIktYQ5E"
      },
      "outputs": [],
      "source": [
        "def likelihood_probability_func(\n",
        "      labels,\n",
        "      forecasts,\n",
        "      shift = random_var_shift,\n",
        "      stretch = random_var_stretch,\n",
        "      ):\n",
        "  # Create a tfp.distributions.Distribution instance:\n",
        "  random_variable = probability_density_function(\n",
        "      tf.convert_to_tensor(forecasts))\n",
        "  labels_tensor = tf.reshape(tf.convert_to_tensor(labels, dtype=forecasts.dtype), (-1,))\n",
        "  likelihood = random_variable.prob(shift_strech_input(labels_tensor))/stretch\n",
        "  return likelihood\n",
        "\n",
        "def split_name_to_model_and_set(name):\n",
        "  under_score_idx = name[::-1].find('_')\n",
        "  current_model = name[:-(under_score_idx+1)]\n",
        "  set_name = name[-(under_score_idx):]\n",
        "  return (current_model, set_name)\n",
        "\n",
        "def sort_strings_w_constraint(list_of_strings, start_with_constraint):\n",
        "  sorted_list = []\n",
        "  for cons in start_with_constraint:\n",
        "    cons_list = [l for l in list_of_strings if l.startswith(cons)]\n",
        "    cons_list.sort()\n",
        "    sorted_list += cons_list\n",
        "  remains_list = list(set(list_of_strings) - set(sorted_list))\n",
        "  remains_list.sort()\n",
        "  sorted_list += remains_list\n",
        "  return sorted_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zqJy47k6Vp_"
      },
      "source": [
        "# Compute model's results and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px0AqLqMjQsP"
      },
      "source": [
        "The following command computes benchmark magnitude predictors and caches the results.\u003cbr\u003e\n",
        "In order to perform the calculation, the script will require the *```domain```*,\n",
        "an instance of ```training_examples.CatalogDomain```. This is defined by the flag:\u003cbr\u003e\n",
        "```--domain_path='path/to/relevant/domain'```\n",
        "\n",
        "\n",
        "If benchmarks are already cached, they will not be recomputed unless specified explicitly by the flag \u003cbr\u003e\n",
        "```--force_recalculate=True```.\n",
        "\n",
        "If some benchmarks are to be excluded, specify in a dictionary format, for example:\u003cbr\u003e\n",
        "```--compute_benchmark='n_past_events_kde=False'```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uja7zLNOjQsP"
      },
      "outputs": [],
      "source": [
        "!python3 ../eq_mag_prediction/scripts/calculate_benchmark_gr_properties.py --domain_path='../results/trained_models/mock/domain' --compute_benchmark='n_past_events_kde=False, spatial_gr=False' --force_recalculate=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbPRREP0xpo"
      },
      "source": [
        "### Collect $\\beta$ and $m_c$ for GR variation benchmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHXjNbg2jQsP"
      },
      "source": [
        "The following cell preforms the benchmark calculation, as the cmd above does, but with an in-notebook workaround.\n",
        "The function ```calculate_benchmark_gr_properties.compute_and_assign_benchmarks_all_sets``` will either calculate the benchmarks or load them if already calculated and cached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQSYjQpomr_O"
      },
      "outputs": [],
      "source": [
        "# Set cache path\n",
        "GR_PROPERTIES_CACHE = os.path.join(\n",
        "    os.getcwd(), '..', 'results/cached_benchmarks'\n",
        ")\n",
        "\n",
        "custom_args = [\n",
        "    f\"--{calculate_benchmark_gr_properties._CACHE_DIR.name}=GR_PROPERTIES_CACHE\",\n",
        "    f\"--{calculate_benchmark_gr_properties._FORCE_RECALCULATE.name}=False\",\n",
        "]\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS(custom_args)\n",
        "\n",
        "\n",
        "# show logging info while running\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "# Load the benchmarks\n",
        "LOAD_KDE = False\n",
        "gr_models_beta, gr_models_mc = calculate_benchmark_gr_properties.compute_and_assign_benchmarks_all_sets(\n",
        "    domain,\n",
        "    timestamps_dict,\n",
        "    coordinates_dict,\n",
        "    BETA_OF_TRAIN_SET,\n",
        "    MAG_THRESH,\n",
        "    # compute_benchmark={'spatial_gr':False},\n",
        "    compute_benchmark={'n_past_events_kde':LOAD_KDE, 'spatial_gr':False},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjMJlv7eIpyR"
      },
      "outputs": [],
      "source": [
        "# Rename some keys\n",
        "for k in iter(list(gr_models_beta.keys())):\n",
        "  if not k.startswith('gr_spatial'):\n",
        "    continue\n",
        "  k_new = k.replace('gr_spatial', 'spatial_gr')\n",
        "  gr_models_beta[k_new] = gr_models_beta.pop(k)\n",
        "  gr_models_mc[k_new] = gr_models_mc.pop(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2M9ghLDFIN"
      },
      "source": [
        "## Compute likelihoods of models and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxe951tIuGT"
      },
      "source": [
        "### Benchmarks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s_FQT7rDKV3"
      },
      "outputs": [],
      "source": [
        "gr_likelihoods_and_baselines = {}\n",
        "for k in gr_models_beta:\n",
        "  set_name = k.split('_')[-1]\n",
        "  if 'events_kde' in k:\n",
        "    gr_likelihoods_and_baselines[k] = np.array(\n",
        "        [kde(l) for kde,l in zip(gr_models_beta[k], getattr(labels, f'{set_name}_labels'))]\n",
        "        ).ravel()\n",
        "  else:\n",
        "    gr_likelihoods_and_baselines[k] = metrics.gr_likelihood(\n",
        "        getattr(labels, f'{set_name}_labels'),\n",
        "        gr_models_beta[k],\n",
        "        gr_models_mc[k],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWHZg8hIuGU"
      },
      "source": [
        "### Model's scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4AdQDiJK9E"
      },
      "outputs": [],
      "source": [
        "likelihoods_and_baselines = {}\n",
        "\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "  likelihoods_and_baselines[f'model_{MODEL_NAME}_likelihood_{set_name}'] = np.array(\n",
        "      likelihood_probability_func(\n",
        "          getattr(labels, f'{set_name}_labels'),\n",
        "          forecasts[set_name],\n",
        "          MAG_THRESH,\n",
        "          )\n",
        "      )\n",
        "\n",
        "likelihoods_and_baselines.update(gr_likelihoods_and_baselines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Wxu2G0vjMj"
      },
      "source": [
        "## Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMcQ4mrR3Vsn"
      },
      "outputs": [],
      "source": [
        "# Select benchmarks to display\n",
        "\n",
        "MODELS_TO_PLOT = [split_name_to_model_and_set(k)[0] for k in likelihoods_and_baselines.keys() if k.startswith('model_') \u0026 k.endswith('_test')]\n",
        "MODELS_TO_PLOT += [\n",
        "    'train_gr_likelihood',\n",
        "    'test_gr_likelihood',\n",
        "    # 'gr_last_10_days_constant_mc_likelihood',\n",
        "    'gr_last_100_days_constant_mc_likelihood',\n",
        "    # 'gr_last_1000_days_constant_mc_likelihood',\n",
        "    # 'gr_last_10_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_100_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_1000_days_fitted_mc_likelihood',\n",
        "    'n300_past_events_constant_mc',\n",
        "    # 'n300_present_events_constant_mc',\n",
        "    # 'n300_past_events_fitted_mc',\n",
        "    # 'n300_present_events_fitted_mc',\n",
        "    # 'spatial_gr_on_all_likelihood',\n",
        "    # 'spatial_gr_on_train_likelihood',\n",
        "    # 'gr_spatial_on_train_likelihood',\n",
        "    # 'spatial_gr_on_test_likelihood',\n",
        "    # 'n300_past_events_kde_constant_mc'\n",
        "]\n",
        "MODELS_TO_PLOT = sort_strings_w_constraint(MODELS_TO_PLOT, ['model', 'train', 'test', 'gr', 'n', 'saptial'])\n",
        "\n",
        "COLOR_PER_MODEL = {m:listed_colors_discrete[i] for i,m in enumerate(MODELS_TO_PLOT)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfnGTQHiIuGU"
      },
      "source": [
        "#### display helper-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0STopfJl7Zb"
      },
      "outputs": [],
      "source": [
        "def create_scores_summary_df(\n",
        "    likelihoods_and_baselines_dictionary,\n",
        "    per_set_boolean_filter=None,\n",
        "    exclude_zeros=False,\n",
        "    drop_nans=True\n",
        "    ):\n",
        "  model_names = set()\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    under_score_idx = k[::-1].find('_')\n",
        "    model_name = k[:-(under_score_idx+1)]\n",
        "    model_names.add(model_name)\n",
        "\n",
        "  summary_df = pd.DataFrame(\n",
        "      index=sort_strings_w_constraint(\n",
        "          list(model_names),\n",
        "           ['model_', 'train', 'test', 'gr_', 'n_'],\n",
        "          ),\n",
        "      columns=['train', 'validation', 'test'],\n",
        "      )\n",
        "\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    current_model, set_name = split_name_to_model_and_set(k)\n",
        "\n",
        "    total_logical = np.full_like(likelihoods_and_baselines_dictionary[k].ravel(), True).astype(bool)\n",
        "    if per_set_boolean_filter is not None:\n",
        "      total_logical = total_logical \u0026 per_set_boolean_filter[set_name]\n",
        "    if exclude_zeros:\n",
        "      total_logical = total_logical \u0026 (likelihoods_and_baselines_dictionary[k]!=0)\n",
        "    if drop_nans:\n",
        "      total_logical = total_logical \u0026 (~np.isnan(likelihoods_and_baselines_dictionary[k]))\n",
        "\n",
        "    summary_df.loc[current_model, set_name] = float(-np.log(likelihoods_and_baselines_dictionary[k][total_logical]).mean())\n",
        "  return summary_df.apply(pd.to_numeric)\n",
        "\n",
        "\n",
        "\n",
        "def get_grad_colormap(original_color):\n",
        "  listed_colors_discrete = [\n",
        "      list(original_color),\n",
        "      (1, 1, 1, 1),\n",
        "      ]\n",
        "  return mpl_colors.LinearSegmentedColormap.from_list('grad_colormap', np.array(listed_colors_discrete))\n",
        "\n",
        "\n",
        "def barplot_scores(scores_summary_df, models_to_plot_list, colors=None, set_name='test'):\n",
        "  data_column = scores_summary_df[set_name].loc[MODELS_TO_PLOT]\n",
        "  are_infs = np.isinf(data_column)\n",
        "  non_inf_max = data_column[~are_infs].max()\n",
        "  margin = (non_inf_max - data_column[~are_infs].min())/4\n",
        "  replace_inf_val = np.max(data_column[~are_infs]) + 2*margin\n",
        "  data_column[are_infs] = replace_inf_val\n",
        "  infs_bars = np.where(are_infs)[0]\n",
        "\n",
        "\n",
        "  f, ax = plt.subplots(1, 1)\n",
        "  bars_handle = ax.bar(\n",
        "      models_to_plot_list,\n",
        "      data_column,\n",
        "      color=colors\n",
        "      )\n",
        "  #-- account for infs:\n",
        "  if infs_bars.size \u003e 0:\n",
        "    bar_ax = bars_handle[0].axes\n",
        "    lim = bar_ax.get_xlim()+bar_ax.get_ylim()\n",
        "    for inf_idx in infs_bars:\n",
        "      bar = bars_handle[inf_idx]\n",
        "      bar.set_zorder(1)\n",
        "      original_color = bar.get_facecolor()\n",
        "      grad_colormap = get_grad_colormap(original_color)\n",
        "      bar.set_facecolor(\"none\")\n",
        "      x,y = bar.get_xy()\n",
        "      w, h = bar.get_width(), bar.get_height()\n",
        "      grad = np.atleast_2d(np.linspace(replace_inf_val, 0, 1000)).T\n",
        "      normalizer = mpl.colors.PowerNorm(0.8, vmin=replace_inf_val-margin, vmax=replace_inf_val)\n",
        "      ax.imshow(grad, extent=[x,x+w,y,y+h], aspect=\"auto\", zorder=0, cmap=grad_colormap, norm=normalizer)\n",
        "      ax.text(x+w/2, replace_inf_val, '$\\infty$', ha='center', color=original_color)\n",
        "    bar_ax.axis(lim)\n",
        "\n",
        "  max_y = data_column.max() + margin\n",
        "  min_y = data_column.min() - margin\n",
        "  ax.set_ylim(min_y, max_y)\n",
        "  for label in ax.get_xticklabels():\n",
        "    label.set(rotation=-30, horizontalalignment='left')\n",
        "  ax.set_ylabel(r'$-\\langle \\log \\leftparen \\mathtt{likelihood} \\rightparen \\rangle$')\n",
        "  return f, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ukhMYaBIuGV"
      },
      "source": [
        "## Calculate the minus mean log-likelihood score   $-\u003c\\mathcal{L}\u003e$\n",
        "Lower score = better score.\n",
        "\n",
        "**Notice than with the default settings of the tutorial notebook, random data is used and MAGNET is expected to lose.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCz1tb4ZJ1fh"
      },
      "outputs": [],
      "source": [
        "#@title Minus mean log likelihood\n",
        "\n",
        "summary_df_mean_ll = create_scores_summary_df(likelihoods_and_baselines, drop_nans=True, exclude_zeros=True)\n",
        "summary_df_mean_ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLzxmylZrNKn"
      },
      "outputs": [],
      "source": [
        "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
        "f_meanLL_barplot, ax_meanLL_barplot = barplot_scores(summary_df_mean_ll, MODELS_TO_PLOT, [COLOR_PER_MODEL[m] for m in MODELS_TO_PLOT])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYM6mEG9jQsV"
      },
      "source": [
        "# Plot resulting distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lnj-9QMjQsV"
      },
      "source": [
        "Plot the pdf predicted by the model MAGNET.\n",
        "Colors indicate the label magnitude, values of labels will be marked by stars of the corresponding colors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFCZpYg6jQsV"
      },
      "outputs": [],
      "source": [
        "#---- setup data\n",
        "samples_to_plot = 4\n",
        "plot_above_thresh = MAG_THRESH\n",
        "m_vec = np.linspace(MAG_THRESH, 9, 500)\n",
        "prob_density_inst = probability_density_function(forecasts['test'])\n",
        "prob_vecs = prob_density_inst.prob((m_vec[:, None] - random_var_shift)/random_var_stretch)/random_var_stretch\n",
        "\n",
        "test_labels_to_plot_from = labels.test_labels[labels.test_labels\u003e=plot_above_thresh]\n",
        "prob_vecs_to_plot_from = prob_vecs.numpy()[:, labels.test_labels\u003e=plot_above_thresh]\n",
        "\n",
        "\n",
        "p_for_mags = np.exp(BETA_OF_TRAIN_SET*test_labels_to_plot_from)\n",
        "p_for_mags /= p_for_mags.sum()\n",
        "rnd_seed = np.random.RandomState(seed=1905)\n",
        "label_idxs_to_plot = np.sort(rnd_seed.choice(prob_vecs_to_plot_from.shape[1],samples_to_plot, replace=False, p=p_for_mags))\n",
        "labels_to_plot = test_labels_to_plot_from[label_idxs_to_plot]\n",
        "\n",
        "\n",
        "#--- setup figure\n",
        "num_mags = 25\n",
        "min_mag = 2\n",
        "max_mag = 6.5\n",
        "m_scale = np.linspace(min_mag-0.01, max_mag, num_mags)\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "\n",
        "chosen_colormap = mpl.colormaps['coolwarm']\n",
        "colors = chosen_colormap(np.linspace(0,1,num_mags))\n",
        "colors2plot = colors[np.argmin(np.abs(test_labels_to_plot_from[label_idxs_to_plot][:,None] - m_scale[None,:]), axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beAM4irHjQsV"
      },
      "outputs": [],
      "source": [
        "#---- Plot\n",
        "f_dist_fig, ax_dist_fig = plt.subplots(1,1,)\n",
        "\n",
        "for idx, lbl_index in enumerate(label_idxs_to_plot):\n",
        "  p = ax_dist_fig.plot(m_vec, prob_vecs_to_plot_from[:, lbl_index], alpha=0.4, color=colors2plot[idx], linewidth=4);\n",
        "for idx, lbl_index in enumerate(label_idxs_to_plot):\n",
        "  x_mark = labels_to_plot[idx]\n",
        "  p_idx = np.argmin(np.abs(m_vec - x_mark))\n",
        "  y_mark = prob_vecs_to_plot_from[p_idx, lbl_index]\n",
        "  ax_dist_fig.scatter(x_mark, y_mark, s=50, marker='*', color=colors2plot[idx], edgecolor='black', linewidth=0.5, zorder=np.inf)\n",
        "\n",
        "\n",
        "# plot GR train set\n",
        "train_gr_curve = metrics.gr_likelihood(m_vec, BETA_OF_TRAIN_SET, MAG_THRESH)\n",
        "gr_handle = ax_dist_fig.plot(m_vec, train_gr_curve, 'k--', label='train_gr_likelihood', linewidth=3)\n",
        "ax_dist_fig.legend(handles=gr_handle, frameon=False)\n",
        "\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "sm = plt.cm.ScalarMappable(cmap=chosen_colormap, norm=norm_inst);\n",
        "\n",
        "cb = plt.colorbar(sm, ax=ax_dist_fig, label='True magnitude (label)')\n",
        "ax_dist_fig.set_xlabel('magnitude')\n",
        "ax_dist_fig.set_ylabel('p(magnitude)')\n",
        "ax_dist_fig.set_xscale('linear')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//intelligence/earthquakes/colab:notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "142GRBMltYO8FTYzxJba0Nsuc2K6I3rU8",
          "timestamp": 1719071116469
        },
        {
          "file_id": "1x-ci7axx8_HPy-VThOywdPRnL9RCIZ73",
          "timestamp": 1707386996321
        },
        {
          "file_id": "1Ol2MByyPj9rv_dEMpqQWjXfVbrKY2R77",
          "timestamp": 1699277925468
        },
        {
          "file_id": "1X0uCXEsHaG6qH9nZBPo4yVFfjJ9bJySH",
          "timestamp": 1696314810048
        },
        {
          "file_id": "1Pel6FQL10BrAMuX44uk7E8YBtsJgErqA",
          "timestamp": 1691663081634
        },
        {
          "file_id": "1Rdt5eMiL31MblVNFT_GCF25qNGsooh0s",
          "timestamp": 1678092594120
        },
        {
          "file_id": "1cKMZ5nhX_tyW19rw3n1vonhRkLyukGg9",
          "timestamp": 1673957299492
        },
        {
          "file_id": "1Cda53khxHslAUQno6Lw02Ye4q7AWezjm",
          "timestamp": 1673869854946
        },
        {
          "file_id": "1GyuN0CLKvEEb6bufw5LTgqlnSop37Q39",
          "timestamp": 1673786767072
        },
        {
          "file_id": "1f3zM6j4DhjkA0Axhq_zGWSqL7tVK-Ijx",
          "timestamp": 1673444962135
        },
        {
          "file_id": "1FV55Uz5BggBpjsaGszKuXv3sUkWwiujo",
          "timestamp": 1672903019087
        },
        {
          "file_id": "1T7WlP4i5_9xe3H4klPFuIO0a55IN_BMY",
          "timestamp": 1669812340393
        },
        {
          "file_id": "1w-4UtNzqu0Jq0pnZt4gDyQNOX1aMRh_K",
          "timestamp": 1662983276624
        },
        {
          "file_id": "1aqEOiuBdr-UKuymkaqC2XL6psjnInZeJ",
          "timestamp": 1660034359535
        },
        {
          "file_id": "1qT62S_OaBOUQHlKcFnJQGrL9LK_aEPmz",
          "timestamp": 1658839391585
        },
        {
          "file_id": "1S4YbtcFlTECFwhSYu3REOT2D6gzkxJ_O",
          "timestamp": 1655717124037
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
