{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pe8rUDv13WU"
      },
      "source": [
        "Copyright 2024 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJURSVoJ1uTL"
      },
      "outputs": [],
      "source": [
        "#@title License\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaPyEsBRT34F"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcYUpswoTySv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numbers\n",
        "import xarray as xr\n",
        "from sklearn import metrics as skl_metrics\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.colors as mpl_colors\n",
        "\n",
        "\n",
        "#--- for printing formatted text\n",
        "from IPython.display import display, Markdown\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "from absl import flags\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib.ticker import FixedLocator\n",
        "import logging\n",
        "\n",
        "import gin\n",
        "gin.enter_interactive_mode()\n",
        "\n",
        "np.set_printoptions(precision=4, threshold=2500)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6ouhtnGFLi0"
      },
      "outputs": [],
      "source": [
        "from eq_mag_prediction.scripts import calculate_benchmark_gr_properties\n",
        "from eq_mag_prediction.scripts import magnitude_predictor_trainer   # import unused for gin config\n",
        "from eq_mag_prediction.forecasting import metrics, training_examples\n",
        "from eq_mag_prediction.forecasting import encoders\n",
        "from eq_mag_prediction.forecasting import one_region_model\n",
        "from eq_mag_prediction.utilities import geometry\n",
        "from eq_mag_prediction.utilities import statistics_utils as statistics\n",
        "from eq_mag_prediction.utilities import catalog_analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZdUC6nyR1pw"
      },
      "source": [
        "# Plotting settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwWNiH_8R3cN"
      },
      "source": [
        "## Colors settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4Nz5hLjUSOZG"
      },
      "outputs": [],
      "source": [
        "# @title Create warm-cool gradient colormap\n",
        "\n",
        "listed_colors_discrete_warm_cool =[\n",
        "    '#081d58',\n",
        "    '#253494',\n",
        "    '#225ea8',\n",
        "    '#1d91c0',\n",
        "    '#41b6c4',\n",
        "    '#7fcdbb',\n",
        "    '#c7e9b4',\n",
        "    '#edf8b1',\n",
        "    '#ffffcc',\n",
        "    '#ffeda0',\n",
        "    '#fed976',\n",
        "    '#feb24c',\n",
        "    '#fd8d3c',\n",
        "    '#fc4e2a',\n",
        "    '#e31a1c',\n",
        "    '#bd0026',\n",
        "    '#800026',\n",
        "]\n",
        "\n",
        "warn_cold_cmap = mpl_colors.LinearSegmentedColormap.from_list('warn_cold_cmap', listed_colors_discrete_warm_cool)\n",
        "warn_cold_cmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjUn-fqfT_sF"
      },
      "outputs": [],
      "source": [
        "#@title Discrete colors\n",
        "\n",
        "listed_colors_discrete = [\n",
        "    '#e41a1c',\n",
        "    '#377eb8',\n",
        "    '#4daf4a',\n",
        "    '#984ea3',\n",
        "    '#ff7f00',\n",
        "    '#ffff33',\n",
        "    '#f0027f',\n",
        "]\n",
        "\n",
        "color_list_cmap = mpl_colors.ListedColormap(listed_colors_discrete)\n",
        "color_list_cmap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpNEnBEHYOsj"
      },
      "source": [
        "## Plot properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "v37f3S_MXw-7"
      },
      "outputs": [],
      "source": [
        "#@title Plot lines res font etc...\n",
        "\n",
        "FONT_SIZE = 8     #@param{type:'number'}\n",
        "TITLE_SIZE = 6    #@param{type:'number'}\n",
        "\n",
        "MARKER_SIZE = 4\n",
        "AXIS_LINE = 0.5     #@param{type:'number'}\n",
        "PLOT_LINE_WIDTH = 2 #@param{type:'number'}\n",
        "\n",
        "FIG_WIDTH = 3 #@param{type:'number'}\n",
        "FIG_HEIGHT = 3 #@param{type:'number'}\n",
        "light_grey = '#EDEDED'\n",
        "\n",
        "figure_dpi = 150 #@param{type:'number'}\n",
        "\n",
        "rc_params = {'axes.linewidth': AXIS_LINE,\n",
        "             'axes.titlesize': TITLE_SIZE,     # font size of the axes title\n",
        "             'axes.labelsize': FONT_SIZE,      # font size of the x and y labels\n",
        "             'axes.prop_cycle': mpl.cycler(color=listed_colors_discrete),\n",
        "\n",
        "             'font.family': 'STIXGeneral',\n",
        "             'font.sans-serif': 'Lato',\n",
        "             'font.weight': 'normal',\n",
        "             'font.size': FONT_SIZE,           # controls default text sizes\n",
        "\n",
        "             'legend.frameon': True,           # don't show a box around the legend\n",
        "             'legend.fontsize': FONT_SIZE,     # legend font size\n",
        "\n",
        "             'figure.titlesize': FONT_SIZE,   # font size of the figure title\n",
        "             'figure.figsize': (FIG_WIDTH, FIG_HEIGHT),   # font size of the figure title\n",
        "             'figure.dpi' : figure_dpi,\n",
        "\n",
        "             'lines.linewidth': PLOT_LINE_WIDTH\n",
        "}\n",
        "\n",
        "mpl.rcParams.update(rc_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhtAl0y3IuGP"
      },
      "source": [
        "# Loadings and Configs\n",
        "models, features, labels, forecasts...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE2LYNRuIuGP"
      },
      "outputs": [],
      "source": [
        "# MODEL_NAME = 'Hauksson'\n",
        "MODEL_NAME = 'JMA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4urzkI8dIuGP"
      },
      "outputs": [],
      "source": [
        "experiment_dir = os.path.join(os.getcwd(), '..', 'results/trained_models/', MODEL_NAME)\n",
        "custom_objects={\n",
        "    '_repeat': encoders._repeat,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fWaxFJwIuGP"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "loaded_model = tf.keras.models.load_model(\n",
        "    os.path.join(experiment_dir, 'model'),\n",
        "    custom_objects={'_repeat': encoders._repeat},\n",
        "    compile=False,\n",
        "    # safe_mode=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh8jho_ZIuGP"
      },
      "outputs": [],
      "source": [
        "# set gin configs\n",
        "with open(os.path.join(experiment_dir, 'config.gin')) as f:\n",
        "    with gin.unlock_config():\n",
        "        gin.parse_config(f.read(), skip_unknown=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrTugdjBIuGQ"
      },
      "outputs": [],
      "source": [
        "print(gin.config_str())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esR5VctSIuGQ"
      },
      "outputs": [],
      "source": [
        "domain = training_examples.CatalogDomain()\n",
        "labels = training_examples.magnitude_prediction_labels(domain)\n",
        "\n",
        "scaler_saving_dir = os.path.join(os.getcwd(), '..', 'results/trained_models', MODEL_NAME, 'scalers')\n",
        "\n",
        "labels = training_examples.magnitude_prediction_labels(domain)\n",
        "all_encoders = one_region_model.build_encoders(domain)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWmAYZAcIuGQ"
      },
      "outputs": [],
      "source": [
        "all_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckNGwIbZIuGQ"
      },
      "outputs": [],
      "source": [
        "one_region_model.compute_and_cache_features_scaler_encoder(\n",
        "    domain,\n",
        "    all_encoders,\n",
        "    force_recalculate = False,\n",
        ")\n",
        "features_and_models = one_region_model.load_features_and_construct_models(\n",
        "    domain, all_encoders, scaler_saving_dir\n",
        ")\n",
        "train_features = one_region_model.features_in_order(features_and_models, 0)\n",
        "validation_features = one_region_model.features_in_order(features_and_models, 1)\n",
        "test_features = one_region_model.features_in_order(features_and_models, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-3IpyL8IuGQ"
      },
      "outputs": [],
      "source": [
        "forecasts = {}\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "    forecasts[set_name] = loaded_model.predict(locals()[f'{set_name}_features'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5BAMLVB2-VK"
      },
      "source": [
        "# Analysis and plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIQCvx2WIftn"
      },
      "source": [
        "## Coordinate handling functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hu1wojzIuGR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def is_data_at_180(longitude_coors):\n",
        "  is_it = (longitude_coors.min()\u003c=-170) \u0026 (longitude_coors.max()\u003e=170) \u0026 (((longitude_coors\u003e=-100) \u0026 (longitude_coors\u003c=100)).sum()==0)\n",
        "  return is_it\n",
        "\n",
        "def longitude_to_theta(longitudes, norm_by_pi=True, convert_to_rad=True):\n",
        "  theta = longitudes.copy()\n",
        "  theta[longitudes\u003c0] = theta[longitudes\u003c0] + 360\n",
        "  if convert_to_rad:\n",
        "    if norm_by_pi:\n",
        "      return np.deg2rad(theta)/np.pi\n",
        "    return np.deg2rad(theta)\n",
        "  return theta\n",
        "\n",
        "\n",
        "def lon_lat_to_spherical(\n",
        "    lon_lat_array: np.ndarray, # needs to be a NX2 array, 1st column lon 2nd lat\n",
        "    norm_by_pi=True,\n",
        "    convert_to_rad=False,\n",
        "    ):\n",
        "  theta_phi = lon_lat_array.copy()\n",
        "  theta_phi[:, 0] = longitude_to_theta(lon_lat_array[:, 0], norm_by_pi, convert_to_rad=convert_to_rad)\n",
        "  if not convert_to_rad:\n",
        "    return theta_phi\n",
        "  theta_phi[:, 1] = np.deg2rad(lon_lat_array[:, 1])\n",
        "  if norm_by_pi:\n",
        "    theta_phi[:, 1] = theta_phi[:, 1] / np.pi\n",
        "  return theta_phi\n",
        "\n",
        "\n",
        "def lon_lat_for_map_plotting(longitude_coors, latitude_coors):\n",
        "  if is_data_at_180(longitude_coors):\n",
        "    coord_array = np.hstack((\n",
        "        longitude_coors.ravel()[:, None],\n",
        "        latitude_coors.ravel()[:, None]\n",
        "        ))\n",
        "    coord_array = lon_lat_to_spherical(coord_array, convert_to_rad=False)\n",
        "    longs = coord_array.T[0]\n",
        "    lats = coord_array.T[1]\n",
        "  else:\n",
        "    longs = longitude_coors\n",
        "    lats = latitude_coors\n",
        "  return longs, lats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRav_icTuPOX"
      },
      "source": [
        "## Set relevant probability density and other definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qXHtd1dduLK4"
      },
      "outputs": [],
      "source": [
        "# set the relevant probability density function\n",
        "probability_density_function = metrics.kumaraswamy_mixture_instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yAwSgPL500z"
      },
      "outputs": [],
      "source": [
        "BETA_OF_TRAIN_SET = catalog_analysis.estimate_beta(labels.train_labels, None, 'BPOS')\n",
        "MAG_THRESH = domain.magnitude_threshold\n",
        "DAY_TO_SECONDS = 60*60*24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flIqONWBIuGS"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    support_stretch = gin.query_parameter('train_and_evaluate_magnitude_prediction_model.pdf_support_stretch')\n",
        "except:\n",
        "    default_stretch = 7\n",
        "    message = f\"\u003cspan style='color:red; font-size:25px'\u003epdf_support_stretch not defined in gin, setting to default: {default_stretch}\u003c/span\u003e\"\n",
        "    display(Markdown(message))\n",
        "    support_stretch = default_stretch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-UL2CraofCo"
      },
      "outputs": [],
      "source": [
        "# Create a shift function for labels\n",
        "\n",
        "random_var_shift = MAG_THRESH\n",
        "random_var_stretch = support_stretch\n",
        "\n",
        "costum_shift_stretch = lambda x, random_var_shift=random_var_shift, random_var_stretch=random_var_stretch: np.minimum((x - random_var_shift) / random_var_stretch, 1)\n",
        "shift_strech_input = costum_shift_stretch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og97zyM5tvbC"
      },
      "outputs": [],
      "source": [
        "timestamps_dict = calculate_benchmark_gr_properties.create_timestamps_dict(domain)\n",
        "test_timestamps = timestamps_dict['test']\n",
        "validation_timestamps = timestamps_dict['validation']\n",
        "train_timestamps = timestamps_dict['train']\n",
        "all_timestamps = np.concatenate([train_timestamps, validation_timestamps, test_timestamps])\n",
        "\n",
        "coordinates_dict = calculate_benchmark_gr_properties.create_coordinates_dict(domain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xej2uP02YOa"
      },
      "source": [
        "## Functions for computing likelihoods and baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiXCGIktYQ5E"
      },
      "outputs": [],
      "source": [
        "def likelihood_probability_func(\n",
        "      labels,\n",
        "      forecasts,\n",
        "      shift = random_var_shift,\n",
        "      stretch = random_var_stretch,\n",
        "      ):\n",
        "  # Create a tfp.distributions.Distribution instance:\n",
        "  random_variable = probability_density_function(\n",
        "      tf.convert_to_tensor(forecasts))\n",
        "  labels_tensor = tf.reshape(tf.convert_to_tensor(labels, dtype=forecasts.dtype), (-1,))\n",
        "  likelihood = random_variable.prob(shift_strech_input(labels_tensor))/stretch\n",
        "  return likelihood\n",
        "\n",
        "def number_to_vector(num, set_name):\n",
        "  if isinstance(num, numbers.Number):\n",
        "    return np.full_like(getattr(labels, f'{set_name}_labels'), num)\n",
        "  return num\n",
        "\n",
        "def p_of_m_model_above_cutoff(m_tilde, set_name, forecasts_i):\n",
        "  model_likelihood_above_cutoff = likelihood_probability_func(\n",
        "      labels=getattr(labels, f'{set_name}_labels'),\n",
        "      forecasts=forecasts_i[set_name],\n",
        "      shift=random_var_shift,\n",
        "      stretch=random_var_stretch,\n",
        "      )[getattr(labels, f'{set_name}_labels') \u003e= number_to_vector(m_tilde, set_name)]\n",
        "  return model_likelihood_above_cutoff\n",
        "\n",
        "def model_survival_at_cutoff(m_tilde, set_name, forecasts_i):\n",
        "  # Create a tfp.distributions.Distribution instance:\n",
        "  random_variable = probability_density_function(tf.convert_to_tensor(forecasts_i[set_name]))\n",
        "  return random_variable.survival_function(shift_strech_input(np.maximum(m_tilde, MAG_THRESH)))\n",
        "\n",
        "\n",
        "def conditioned_likelihood_model(m_tilde, set_name, forecasts_i):\n",
        "  m_tilde = number_to_vector(m_tilde, set_name)\n",
        "  return p_of_m_model_above_cutoff(m_tilde, set_name, forecasts_i) / model_survival_at_cutoff(m_tilde, set_name, forecasts_i)[getattr(labels, f'{set_name}_labels')\u003e=number_to_vector(m_tilde, set_name)]\n",
        "\n",
        "\n",
        "# split to sets dict\n",
        "def split_to_sets_dicts(main_dict):\n",
        "  train_dict = {k:v for k, v in main_dict.items() if k.endswith('_train')}\n",
        "  validation_dict = {k:v for k, v in main_dict.items() if k.endswith('_validation')}\n",
        "  test_dict = {k:v for k, v in main_dict.items() if k.endswith('_test')}\n",
        "  return train_dict, validation_dict, test_dict\n",
        "\n",
        "\n",
        "def split_name_to_model_and_set(name):\n",
        "  under_score_idx = name[::-1].find('_')\n",
        "  current_model = name[:-(under_score_idx+1)]\n",
        "  set_name = name[-(under_score_idx):]\n",
        "  return (current_model, set_name)\n",
        "\n",
        "def split_name_to_model_and_set(name):\n",
        "  under_score_idx = name[::-1].find('_')\n",
        "  current_model = name[:-(under_score_idx+1)]\n",
        "  set_name = name[-(under_score_idx):]\n",
        "  return (current_model, set_name)\n",
        "\n",
        "def sort_strings_w_constraint(list_of_strings, start_with_constraint):\n",
        "  sorted_list = []\n",
        "  for cons in start_with_constraint:\n",
        "    cons_list = [l for l in list_of_strings if l.startswith(cons)]\n",
        "    cons_list.sort()\n",
        "    sorted_list += cons_list\n",
        "  remains_list = list(set(list_of_strings) - set(sorted_list))\n",
        "  remains_list.sort()\n",
        "  sorted_list += remains_list\n",
        "  return sorted_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zqJy47k6Vp_"
      },
      "source": [
        "# Compute model's results and baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9RIFEdPCrzH"
      },
      "outputs": [],
      "source": [
        "#@title set cache path\n",
        "GR_PROPERTIES_CACHE = os.path.join(\n",
        "    os.getcwd(), '..', 'results/cached_benchmarks'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQbPRREP0xpo"
      },
      "source": [
        "### collect beta and mc for gr variations models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC-ujK5bIuGT"
      },
      "outputs": [],
      "source": [
        "# an ugly workaround for parsing calculate_benchmark_gr_properties flags manually\n",
        "custom_args = [\n",
        "    f\"--{calculate_benchmark_gr_properties._CACHE_DIR.name}=GR_PROPERTIES_CACHE\",\n",
        "    f\"--{calculate_benchmark_gr_properties._FORCE_RECALCULATE.name}=False\",\n",
        "]\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS(custom_args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQSYjQpomr_O"
      },
      "outputs": [],
      "source": [
        "# show logging info while running\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "LOAD_KDE = False\n",
        "gr_models_beta, gr_models_mc = calculate_benchmark_gr_properties.compute_and_assign_benchmarks_all_sets(\n",
        "    domain,\n",
        "    timestamps_dict,\n",
        "    coordinates_dict,\n",
        "    BETA_OF_TRAIN_SET,\n",
        "    MAG_THRESH,\n",
        "    # compute_benchmark={'spatial_gr':False},\n",
        "    compute_benchmark={'n_past_events_kde':LOAD_KDE},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjMJlv7eIpyR"
      },
      "outputs": [],
      "source": [
        "for k in iter(list(gr_models_beta.keys())):\n",
        "  if not k.startswith('gr_spatial'):\n",
        "    continue\n",
        "  k_new = k.replace('gr_spatial', 'spatial_gr')\n",
        "  gr_models_beta[k_new] = gr_models_beta.pop(k)\n",
        "  gr_models_mc[k_new] = gr_models_mc.pop(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2M9ghLDFIN"
      },
      "source": [
        "## Compute likelihoods of models and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxe951tIuGT"
      },
      "source": [
        "### GR and other baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s_FQT7rDKV3"
      },
      "outputs": [],
      "source": [
        "gr_likelihoods_and_baselines = {}\n",
        "for k in gr_models_beta:\n",
        "  set_name = k.split('_')[-1]\n",
        "  if 'events_kde' in k:\n",
        "    gr_likelihoods_and_baselines[k] = np.array(\n",
        "        [kde(l) for kde,l in zip(gr_models_beta[k], getattr(labels, f'{set_name}_labels'))]\n",
        "        ).ravel()\n",
        "  else:\n",
        "    gr_likelihoods_and_baselines[k] = metrics.gr_likelihood(\n",
        "        getattr(labels, f'{set_name}_labels'),\n",
        "        gr_models_beta[k],\n",
        "        gr_models_mc[k],\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsWHZg8hIuGU"
      },
      "source": [
        "### Model's scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_s4AdQDiJK9E"
      },
      "outputs": [],
      "source": [
        "likelihoods_and_baselines = {}\n",
        "\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "  likelihoods_and_baselines[f'model_{MODEL_NAME}_likelihood_{set_name}'] = np.array(\n",
        "      likelihood_probability_func(\n",
        "          getattr(labels, f'{set_name}_labels'),\n",
        "          forecasts[set_name],\n",
        "          MAG_THRESH,\n",
        "          )\n",
        "      )\n",
        "\n",
        "likelihoods_and_baselines.update(gr_likelihoods_and_baselines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Wxu2G0vjMj"
      },
      "source": [
        "## Display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMcQ4mrR3Vsn"
      },
      "outputs": [],
      "source": [
        "#@title Baselines to display\n",
        "\n",
        "MODELS_TO_PLOT = [split_name_to_model_and_set(k)[0] for k in likelihoods_and_baselines.keys() if k.startswith('model_') \u0026 k.endswith('_test')]\n",
        "MODELS_TO_PLOT += [\n",
        "    'train_gr_likelihood',\n",
        "    'test_gr_likelihood',\n",
        "    # 'gr_last_10_days_constant_mc_likelihood',\n",
        "    'gr_last_100_days_constant_mc_likelihood',\n",
        "    # 'gr_last_1000_days_constant_mc_likelihood',\n",
        "    # 'gr_last_10_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_100_days_fitted_mc_likelihood',\n",
        "    # 'gr_last_1000_days_fitted_mc_likelihood',\n",
        "    'n300_past_events_constant_mc',\n",
        "    # 'n300_present_events_constant_mc',\n",
        "    # 'n300_past_events_fitted_mc',\n",
        "    # 'n300_present_events_fitted_mc',\n",
        "    # 'spatial_gr_on_all_likelihood',\n",
        "    # 'spatial_gr_on_train_likelihood',\n",
        "    # 'gr_spatial_on_train_likelihood',\n",
        "    # 'spatial_gr_on_test_likelihood',\n",
        "    # 'n300_past_events_kde_constant_mc'\n",
        "]\n",
        "MODELS_TO_PLOT = sort_strings_w_constraint(MODELS_TO_PLOT, ['model', 'train', 'test', 'gr', 'n', 'saptial'])\n",
        "\n",
        "COLOR_PER_MODEL = {m:listed_colors_discrete[i] for i,m in enumerate(MODELS_TO_PLOT)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfnGTQHiIuGU"
      },
      "source": [
        "#### display helper-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0STopfJl7Zb"
      },
      "outputs": [],
      "source": [
        "def create_scores_summary_df(\n",
        "    likelihoods_and_baselines_dictionary,\n",
        "    per_set_boolean_filter=None,\n",
        "    exclude_zeros=False,\n",
        "    drop_nans=True\n",
        "    ):\n",
        "  model_names = set()\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    under_score_idx = k[::-1].find('_')\n",
        "    model_name = k[:-(under_score_idx+1)]\n",
        "    model_names.add(model_name)\n",
        "\n",
        "  summary_df = pd.DataFrame(\n",
        "      index=sort_strings_w_constraint(\n",
        "          list(model_names),\n",
        "           ['model_', 'train', 'test', 'gr_', 'n_'],\n",
        "          ),\n",
        "      columns=['train', 'validation', 'test'],\n",
        "      )\n",
        "\n",
        "  for k in likelihoods_and_baselines_dictionary.keys():\n",
        "    current_model, set_name = split_name_to_model_and_set(k)\n",
        "\n",
        "    total_logical = np.full_like(likelihoods_and_baselines_dictionary[k].ravel(), True).astype(bool)\n",
        "    if per_set_boolean_filter is not None:\n",
        "      total_logical = total_logical \u0026 per_set_boolean_filter[set_name]\n",
        "    if exclude_zeros:\n",
        "      total_logical = total_logical \u0026 (likelihoods_and_baselines_dictionary[k]!=0)\n",
        "    if drop_nans:\n",
        "      total_logical = total_logical \u0026 (~np.isnan(likelihoods_and_baselines_dictionary[k]))\n",
        "\n",
        "    summary_df.loc[current_model, set_name] = float(-np.log(likelihoods_and_baselines_dictionary[k][total_logical]).mean())\n",
        "  return summary_df.apply(pd.to_numeric)\n",
        "\n",
        "\n",
        "\n",
        "def get_grad_colormap(original_color):\n",
        "  listed_colors_discrete = [\n",
        "      list(original_color),\n",
        "      (1, 1, 1, 1),\n",
        "      ]\n",
        "  return mpl_colors.LinearSegmentedColormap.from_list('grad_colormap', np.array(listed_colors_discrete))\n",
        "\n",
        "\n",
        "def barplot_scores(scores_summary_df, models_to_plot_list, colors=None, set_name='test'):\n",
        "  data_column = scores_summary_df[set_name].loc[MODELS_TO_PLOT]\n",
        "  are_infs = np.isinf(data_column)\n",
        "  non_inf_max = data_column[~are_infs].max()\n",
        "  margin = (non_inf_max - data_column[~are_infs].min())/4\n",
        "  replace_inf_val = np.max(data_column[~are_infs]) + 2*margin\n",
        "  data_column[are_infs] = replace_inf_val\n",
        "  infs_bars = np.where(are_infs)[0]\n",
        "\n",
        "\n",
        "  f, ax = plt.subplots(1, 1)\n",
        "  bars_handle = ax.bar(\n",
        "      models_to_plot_list,\n",
        "      data_column,\n",
        "      color=colors\n",
        "      )\n",
        "  #-- account for infs:\n",
        "  if infs_bars.size \u003e 0:\n",
        "    bar_ax = bars_handle[0].axes\n",
        "    lim = bar_ax.get_xlim()+bar_ax.get_ylim()\n",
        "    for inf_idx in infs_bars:\n",
        "      bar = bars_handle[inf_idx]\n",
        "      bar.set_zorder(1)\n",
        "      original_color = bar.get_facecolor()\n",
        "      grad_colormap = get_grad_colormap(original_color)\n",
        "      bar.set_facecolor(\"none\")\n",
        "      x,y = bar.get_xy()\n",
        "      w, h = bar.get_width(), bar.get_height()\n",
        "      grad = np.atleast_2d(np.linspace(replace_inf_val, 0, 1000)).T\n",
        "      normalizer = mpl.colors.PowerNorm(0.8, vmin=replace_inf_val-margin, vmax=replace_inf_val)\n",
        "      ax.imshow(grad, extent=[x,x+w,y,y+h], aspect=\"auto\", zorder=0, cmap=grad_colormap, norm=normalizer)\n",
        "      ax.text(x+w/2, replace_inf_val, '$\\infty$', ha='center', color=original_color)\n",
        "    bar_ax.axis(lim)\n",
        "\n",
        "  max_y = data_column.max() + margin\n",
        "  min_y = data_column.min() - margin\n",
        "  ax.set_ylim(min_y, max_y)\n",
        "  for label in ax.get_xticklabels():\n",
        "    label.set(rotation=-30, horizontalalignment='left')\n",
        "  ax.set_ylabel(r'$-\\langle \\log \\leftparen \\mathtt{likelihood} \\rightparen \\rangle$')\n",
        "  return f, ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ukhMYaBIuGV"
      },
      "source": [
        "### Minus mean log-likelihood   $-\u003c\\mathcal{L}\u003e$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCz1tb4ZJ1fh"
      },
      "outputs": [],
      "source": [
        "#@title Minus mean log likelihood\n",
        "\n",
        "summary_df_mean_ll = create_scores_summary_df(likelihoods_and_baselines, drop_nans=True, exclude_zeros=True)\n",
        "summary_df_mean_ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLzxmylZrNKn"
      },
      "outputs": [],
      "source": [
        "f_meanLL_barplot, ax_meanLL_barplot = barplot_scores(summary_df_mean_ll, MODELS_TO_PLOT, [COLOR_PER_MODEL[m] for m in MODELS_TO_PLOT])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5A8Z859Lfx0"
      },
      "source": [
        "## Results conditioned above a threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBhrxHo-DL97"
      },
      "outputs": [],
      "source": [
        "#@title computation of conditioned likelihood\n",
        "NUMERICAL_THRESH = 1e-10\n",
        "def compute_conditioned_gr_variations(\n",
        "    gr_models_beta_dict,\n",
        "    gr_models_mc_dict,\n",
        "    labels_inst,\n",
        "    m_condition,\n",
        "    numerical_thresh=NUMERICAL_THRESH,\n",
        "    ):\n",
        "  conditioned_gr_variations = {}\n",
        "  for k in gr_models_beta_dict:\n",
        "    set_name = k.split('_')[-1]\n",
        "    if 'events_kde' in k:\n",
        "      survivals = np.array([kde.integrate_box_1d(mt, 20) for kde, mt in zip(gr_models_beta_dict[k], m_condition)]).ravel()\n",
        "      above_mc_logical = getattr(labels, f'{set_name}_labels')\u003e=m_condition\n",
        "      kde_likelihoods = np.array([kde(l) for kde,l in zip(gr_models_beta_dict[k], getattr(labels, f'{set_name}_labels'))]).ravel()\n",
        "      conditioned_gr_variations[k] = kde_likelihoods[above_mc_logical]/survivals[above_mc_logical]\n",
        "      conditioned_gr_variations[k][kde_likelihoods[above_mc_logical] \u003c numerical_thresh] = np.nan\n",
        "    else:\n",
        "      conditioned_gr_variations[k] = np.array(\n",
        "          metrics.gr_conditioned_likelihood(\n",
        "              getattr(labels_inst, f'{set_name}_labels'),\n",
        "              gr_models_beta_dict[k],\n",
        "              gr_models_mc_dict[k],\n",
        "              m_condition\n",
        "              )\n",
        "      )\n",
        "  return conditioned_gr_variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnuFtbeM6_M"
      },
      "source": [
        "## Likelihoods conditioned above temporal incompleteness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9CTsDtUM2AE"
      },
      "outputs": [],
      "source": [
        "gr_models_beta_train, gr_models_beta_validation, gr_models_beta_test = split_to_sets_dicts(gr_models_beta)\n",
        "gr_models_mc_train, gr_models_mc_validation, gr_models_mc_test = split_to_sets_dicts(gr_models_mc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B6QzdK6SpCm"
      },
      "outputs": [],
      "source": [
        "#@title mean LL conditioned on PRESENT incompleteness:  $m\\geq \\tilde{m}=m_c(t_{present})$\n",
        "\n",
        "\n",
        "# --- set dictionary\n",
        "likelihoods_and_baselines_cond_present_temp_incompleteness = {}\n",
        "\n",
        "# --- set model conditioned likelihoods\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "  likelihoods_and_baselines_cond_present_temp_incompleteness[f'model_{MODEL_NAME}_likelihood_{set_name}'] = np.array(\n",
        "    conditioned_likelihood_model(\n",
        "      gr_models_mc[f'n300_present_events_fitted_mc_{set_name}'],\n",
        "      set_name,\n",
        "      forecasts\n",
        "      )\n",
        "    )\n",
        "\n",
        "# --- set GR like conditioned likelihoods\n",
        "conditioned_present_temporal_incompleteness_train = compute_conditioned_gr_variations(\n",
        "    gr_models_beta_train,\n",
        "    gr_models_mc_train,\n",
        "    labels,\n",
        "    gr_models_mc_train['n300_present_events_fitted_mc_train']\n",
        ")\n",
        "\n",
        "conditioned_present_temporal_incompleteness_validation = compute_conditioned_gr_variations(\n",
        "    gr_models_beta_validation,\n",
        "    gr_models_mc_validation,\n",
        "    labels,\n",
        "    gr_models_mc_validation['n300_present_events_fitted_mc_validation']\n",
        ")\n",
        "\n",
        "conditioned_present_temporal_incompleteness_test = compute_conditioned_gr_variations(\n",
        "    gr_models_beta_test,\n",
        "    gr_models_mc_test,\n",
        "    labels,\n",
        "    gr_models_mc_test['n300_present_events_fitted_mc_test']\n",
        ")\n",
        "\n",
        "likelihoods_and_baselines_cond_present_temp_incompleteness.update(conditioned_present_temporal_incompleteness_train)\n",
        "likelihoods_and_baselines_cond_present_temp_incompleteness.update(conditioned_present_temporal_incompleteness_validation)\n",
        "likelihoods_and_baselines_cond_present_temp_incompleteness.update(conditioned_present_temporal_incompleteness_test)\n",
        "\n",
        "\n",
        "# --- display all\n",
        "summary_df_mean_ll_cond_mc_present = create_scores_summary_df(likelihoods_and_baselines_cond_present_temp_incompleteness, drop_nans=True)\n",
        "summary_df_mean_ll_cond_mc_present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n89NIgz7cDR_"
      },
      "outputs": [],
      "source": [
        "f_thresh_t_present_barplot, ax_thresh_t_present_barplot = barplot_scores(summary_df_mean_ll_cond_mc_present, MODELS_TO_PLOT, [COLOR_PER_MODEL[m] for m in MODELS_TO_PLOT])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwNjGqYguHbm"
      },
      "source": [
        "### Plot $m_c(t_{present})$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am_O2zt9IuGW"
      },
      "outputs": [],
      "source": [
        "f_completeness, ax_completeness = plt.subplots(1, 1, figsize=(7, 3))\n",
        "\n",
        "y_scatter = labels.test_labels\n",
        "index = np.arange(y_scatter.size)\n",
        "\n",
        "ax_completeness.scatter(\n",
        "    index,\n",
        "    y_scatter,\n",
        "    s=2.3**y_scatter,\n",
        "    alpha=0.4,\n",
        "    c='k'\n",
        "    )\n",
        "\n",
        "#---- Plot under Mc\n",
        "below_mc_bool = domain.earthquakes_catalog.magnitude \u003c MAG_THRESH\n",
        "test_events_bool = ((domain.earthquakes_catalog.time\u003e=test_timestamps.min()) \u0026\n",
        "                    (domain.earthquakes_catalog.time\u003ctest_timestamps.max()))\n",
        "interp_index = np.interp(\n",
        "    domain.earthquakes_catalog['time'].values[test_events_bool \u0026 below_mc_bool],\n",
        "    test_timestamps,\n",
        "    index,\n",
        ")\n",
        "interp_magnitudes = domain.earthquakes_catalog['magnitude'].values[test_events_bool \u0026 below_mc_bool]\n",
        "\n",
        "ax_completeness.scatter(\n",
        "    interp_index,\n",
        "    interp_magnitudes,\n",
        "    c=None,\n",
        "    facecolor='silver',\n",
        "    s=2.3**interp_magnitudes,\n",
        ")\n",
        "\n",
        "#--- Plot Mc(t)\n",
        "ax_completeness.plot(\n",
        "    index,\n",
        "    gr_models_mc_test['n300_present_events_fitted_mc_test'],\n",
        "    )\n",
        "ax_completeness.set_ylabel('Magnitude')\n",
        "ax_completeness.set_xlabel('Index')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx1aQgLke6_B"
      },
      "source": [
        "## Spatial beta metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHMkaEVjzSlh"
      },
      "source": [
        "# Probability density per example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eciiEzuWhgO6"
      },
      "outputs": [],
      "source": [
        "# -- Plot only a sub group in specific order\n",
        "models_to_plot_by_order = sort_strings_w_constraint(MODELS_TO_PLOT, ['model', 'n', 'gr', 'train', 'test'])\n",
        "set_to_plot = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpdtkLoZ26Xf"
      },
      "outputs": [],
      "source": [
        "f_likelihood_per_example, ax_likelihood_per_example = plt.subplots(1,1,)\n",
        "mag_check = np.linspace(MAG_THRESH, 8, 1000)\n",
        "window_size = 0.3\n",
        "models_to_plot = [\n",
        "    [m for m in models_to_plot_by_order if m.startswith('model_')][0],\n",
        "    'n300_past_events_constant_mc',\n",
        "]\n",
        "for i_model in models_to_plot:\n",
        "  if i_model not in models_to_plot_by_order:\n",
        "    continue\n",
        "  else:\n",
        "    zorder = models_to_plot_by_order.index(i_model)\n",
        "  sc = ax_likelihood_per_example.scatter(\n",
        "      labels.test_labels,\n",
        "      likelihoods_and_baselines[f'{i_model}_{set_to_plot}'],\n",
        "      c=COLOR_PER_MODEL[i_model],\n",
        "      alpha=0.4,\n",
        "      label=i_model,\n",
        "      zorder=zorder\n",
        "      )\n",
        "\n",
        "train_gr_curve = metrics.gr_likelihood(mag_check, BETA_OF_TRAIN_SET, MAG_THRESH)\n",
        "gr_handle = ax_likelihood_per_example.plot(\n",
        "    mag_check,\n",
        "    train_gr_curve,\n",
        "    '--',\n",
        "    linewidth=3,\n",
        "    color=COLOR_PER_MODEL['train_gr_likelihood'],\n",
        "    label='train_gr_likelihood',\n",
        "    )\n",
        "leg = ax_likelihood_per_example.legend()\n",
        "for lh in leg.legendHandles:\n",
        "    lh.set_alpha(1)\n",
        "ax_likelihood_per_example.set_xlabel('magnitude', labelpad=10)\n",
        "ax_likelihood_per_example.set_ylabel('label\\'s likelihood', labelpad=10)\n",
        "ax_likelihood_per_example.set_yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAYAPDr_X9y2"
      },
      "source": [
        "# Organize likelihoods data in df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfo5r0FwigWt"
      },
      "outputs": [],
      "source": [
        "#--- create catalog for comparisons\n",
        "rows_to_keep = np.isin(domain.earthquakes_catalog.time.values, all_timestamps)\n",
        "comparison_catalog = domain.earthquakes_catalog.copy().iloc[rows_to_keep, :]\n",
        "\n",
        "#-- add set name indicator\n",
        "train_indicator = ['train']*len(labels.train_labels)\n",
        "validation_indicator = ['validation']*len(labels.validation_labels)\n",
        "test_indicator = ['test']*len(labels.test_labels)\n",
        "set_indicator = np.concatenate([train_indicator, validation_indicator, test_indicator])\n",
        "comparison_catalog['set_name'] = set_indicator\n",
        "\n",
        "\n",
        "baselines_names = []\n",
        "set_names = ['train', 'validation', 'test']\n",
        "for k in likelihoods_and_baselines.keys():\n",
        "  for s in set_names:\n",
        "    if k.endswith(s):\n",
        "      baselines_names.append(k[:-(len(s)+1)])\n",
        "baselines_names = list(set(baselines_names))\n",
        "\n",
        "for base_name in baselines_names:\n",
        "  baseline_vector = np.empty((0))\n",
        "  for s in set_names:\n",
        "    k = base_name + '_' + s\n",
        "    if k not in likelihoods_and_baselines.keys():\n",
        "      baseline_vector = np.concatenate([baseline_vector, np.full_like(getattr(labels, f'{s}_labels'), np.nan)])\n",
        "    else:\n",
        "      baseline_vector = np.concatenate([baseline_vector, likelihoods_and_baselines[k]])\n",
        "  comparison_catalog[base_name] = baseline_vector\n",
        "\n",
        "\n",
        "  #--- add conditioned scores\n",
        "  baseline_vector_conditioned = np.empty((0))\n",
        "  for s in set_names:\n",
        "    k = base_name + '_' + s\n",
        "\n",
        "    baseline_addition = np.full_like(getattr(labels, f'{s}_labels'), np.nan)\n",
        "\n",
        "    above_thresh_logical = getattr(labels, f'{s}_labels') \u003e= locals()[f'gr_models_mc_{s}'][f'n300_present_events_fitted_mc_{s}']\n",
        "    if k in likelihoods_and_baselines_cond_present_temp_incompleteness.keys():\n",
        "      baseline_addition[above_thresh_logical] = likelihoods_and_baselines_cond_present_temp_incompleteness[k]\n",
        "    baseline_vector_conditioned = np.concatenate([baseline_vector_conditioned, baseline_addition])\n",
        "  comparison_catalog[base_name+'_conditioned'] = baseline_vector_conditioned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrWuXZP7YQmd"
      },
      "source": [
        "# Comparisons to benchmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv5yOIIpY7aI"
      },
      "source": [
        "### Select data to present\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5n1YScXIuGY"
      },
      "outputs": [],
      "source": [
        "\n",
        "scores_name = f'model_{MODEL_NAME}_likelihood'\n",
        "baseline_name = 'train_gr_likelihood'\n",
        "\n",
        "scores_name += '_conditioned'\n",
        "baseline_name += '_conditioned'\n",
        "\n",
        "start_time = domain.test_start_time + 0\n",
        "end_time = domain.test_end_time + 0\n",
        "longs = comparison_catalog[comparison_catalog.set_name == 'test'].longitude\n",
        "lats = comparison_catalog[comparison_catalog.set_name == 'test'].latitude\n",
        "min_longitude = longs.min() - (longs.max() - longs.min()) / 10\n",
        "max_longitude = longs.max() + (longs.max() - longs.min()) / 10\n",
        "min_latitude = lats.min() - (lats.max() - lats.min()) / 10\n",
        "max_latitude = lats.max() + (lats.max() - lats.min()) / 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiiyAx8MCUQ6"
      },
      "source": [
        "### Fucntions for organizing data for plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy013p6hIuGY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def logical_for_cropped_comparison_cat():\n",
        "  latitude_logical = (comparison_catalog['latitude'].values \u003e= min_latitude) \u0026 (\n",
        "      comparison_catalog['latitude'].values \u003c= max_latitude\n",
        "  )\n",
        "  longitude_logical = (\n",
        "      comparison_catalog['longitude'].values \u003e= min_longitude\n",
        "  ) \u0026 (comparison_catalog['longitude'].values \u003c= max_longitude)\n",
        "  time_logical = (comparison_catalog['time'].values \u003e= start_time) \u0026 (\n",
        "      comparison_catalog['time'].values \u003c end_time\n",
        "  )\n",
        "  total_logical = latitude_logical \u0026 longitude_logical \u0026 time_logical\n",
        "  return total_logical\n",
        "\n",
        "\n",
        "def create_cropped_comparison_catalog(scores_name, baseline_name):\n",
        "  total_logical = logical_for_cropped_comparison_cat()\n",
        "  cropped_comparison_catalog = comparison_catalog[total_logical]\n",
        "\n",
        "  # Non condtioned information gain\n",
        "  baseline_name_no_suffix, scores_name_no_suffix = (\n",
        "      s.removesuffix('_conditioned') for s in [baseline_name, scores_name]\n",
        "  )\n",
        "  add_log_difference = np.log(\n",
        "      cropped_comparison_catalog[scores_name_no_suffix]\n",
        "  ) - np.log(cropped_comparison_catalog[baseline_name_no_suffix])\n",
        "\n",
        "  finite_difference = np.copy(add_log_difference)\n",
        "  finite_difference[~np.isfinite(finite_difference)] = 0\n",
        "  add_information_gain = np.nancumsum(finite_difference)\n",
        "\n",
        "\n",
        "  # Condtioned information gain:\n",
        "  add_log_difference_conditioned = np.log(cropped_comparison_catalog[scores_name_no_suffix + '_conditioned']) - np.log(\n",
        "      cropped_comparison_catalog[baseline_name_no_suffix + '_conditioned']\n",
        "  )\n",
        "  finite_difference_conditioned = np.copy(add_log_difference_conditioned)\n",
        "  finite_difference_conditioned[~np.isfinite(finite_difference_conditioned)] = 0\n",
        "  add_information_gain_conditioned = np.nancumsum(finite_difference_conditioned)\n",
        "\n",
        "  add_actual_time = [datetime.datetime.fromtimestamp(raw_t) for raw_t in cropped_comparison_catalog['time'].values]\n",
        "\n",
        "\n",
        "  cropped_comparison_catalog = cropped_comparison_catalog.assign(\n",
        "      log_difference= add_log_difference,\n",
        "      information_gain= add_information_gain,\n",
        "      log_difference_conditioned= add_log_difference_conditioned,\n",
        "      information_gain_conditioned= add_information_gain_conditioned,\n",
        "      actual_time= add_actual_time,\n",
        "  )\n",
        "\n",
        "  cropped_comparison_catalog = cropped_comparison_catalog.assign()\n",
        "  return cropped_comparison_catalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U56fmVvU4R9B"
      },
      "source": [
        "## Temporal comparisons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1YFB5A61y-l"
      },
      "outputs": [],
      "source": [
        "cropped_comparison_catalog = create_cropped_comparison_catalog(\n",
        "    scores_name, baseline_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvaQpiK6be-X"
      },
      "outputs": [],
      "source": [
        "#@title plot temporal gain\n",
        "\n",
        "#------ SCATTER INFORMATION GAIN -----\n",
        "\n",
        "base_factor=2.3\n",
        "def _forward_scatter_size_legend(x):\n",
        "  return base_factor**x\n",
        "def _backward_scatter_size_legend(x):\n",
        "  return np.log(x)/np.log(base_factor)\n",
        "\n",
        "f_likelihood_overtime, ax_likelihood_overtime = plt.subplots(1,1, figsize=(7, 4))\n",
        "\n",
        "x_scatter = np.arange(len(cropped_comparison_catalog['actual_time'].values))\n",
        "sc = ax_likelihood_overtime.scatter(\n",
        "    x_scatter,\n",
        "    cropped_comparison_catalog['magnitude'].values,\n",
        "    c=cropped_comparison_catalog['log_difference'].values,\n",
        "    s=_forward_scatter_size_legend(cropped_comparison_catalog['magnitude']),\n",
        "    alpha=0.8,\n",
        "    cmap='coolwarm',\n",
        "    norm=mpl.colors.TwoSlopeNorm(vmin=-2, vcenter=0, vmax=4),\n",
        "    )\n",
        "\n",
        "\n",
        "_ = ax_likelihood_overtime.set_xlabel('Event index')\n",
        "_ = ax_likelihood_overtime.set_ylabel('Magnitude')\n",
        "cb = f_likelihood_overtime.colorbar(sc, ax=ax_likelihood_overtime, location='left', extend='both', aspect=28, label='Log-lokelihood difference')\n",
        "cb.ax.set_yscale('linear')\n",
        "\n",
        "\n",
        "#----- SECOND X AXIS -----\n",
        "\n",
        "def forward_2nd_xaxis(x):\n",
        "  return np.interp(x, x_scatter, test_timestamps)\n",
        "def inverse_2nd_xaxis(x):\n",
        "  return np.interp(x, test_timestamps, x_scatter)\n",
        "\n",
        "\n",
        "\n",
        "# ----- list of first day in  each month:\n",
        "min_datetime = datetime.datetime.fromtimestamp(test_timestamps.min())\n",
        "min_year = min_datetime.year\n",
        "\n",
        "max_datetime = datetime.datetime.fromtimestamp(test_timestamps.max())\n",
        "max_year = max_datetime.year\n",
        "\n",
        "first_of_months = []\n",
        "for y in range(min_year, max_year+1):\n",
        "  for m in range(1, 13):\n",
        "    first_of_months.append(datetime.datetime(year=y, month=m, day=1))\n",
        "first_of_months = [t for t in first_of_months if ((t\u003emin_datetime) \u0026 (t\u003cmax_datetime))][::6]\n",
        "first_of_months_epoch_time = [t.timestamp() for t in first_of_months]\n",
        "first_of_months_string = [t.strftime('%b-%y') for t in first_of_months]\n",
        "\n",
        "secax = ax_likelihood_overtime.secondary_xaxis(-0.1, functions=(forward_2nd_xaxis, inverse_2nd_xaxis))\n",
        "secax.spines['bottom'].set_color('dimgrey')\n",
        "secax.tick_params(axis='x', labelcolor='dimgrey')\n",
        "_ = secax.xaxis.set_major_locator(FixedLocator(first_of_months_epoch_time))\n",
        "_ = secax.xaxis.set_minor_locator(FixedLocator([]))\n",
        "_ = secax.set_xticklabels(first_of_months_string)\n",
        "for label in secax.get_xticklabels(which='major'):\n",
        "  _ = label.set(rotation=-60, horizontalalignment='left')\n",
        "_ = secax.set_xlabel('Date', color='dimgrey')\n",
        "\n",
        "\n",
        "#----- PLOT CUM INFORMATION ON 2ND Y AXIS -----\n",
        "\n",
        "ax_cum_info_gain = ax_likelihood_overtime.twinx()\n",
        "x_info_gain = np.arange(len(cropped_comparison_catalog['actual_time'].values))\n",
        "_ = ax_cum_info_gain.plot(\n",
        "    x_info_gain,\n",
        "    cropped_comparison_catalog['information_gain'].values,\n",
        "    '--',\n",
        "    color='k',\n",
        "    linewidth=2,\n",
        "    label='cumulative information gain')\n",
        "_ = ax_cum_info_gain.set_ylabel('cumulative information gain', color='dimgrey')\n",
        "ax_cum_info_gain.tick_params(axis='y', labelcolor='dimgrey')\n",
        "\n",
        "_ = ax_cum_info_gain.plot(\n",
        "    x_info_gain,\n",
        "    cropped_comparison_catalog['information_gain_conditioned'].values,\n",
        "    '-.',\n",
        "    color='dimgrey',\n",
        "    linewidth=2,\n",
        "    label='cumulative information gain - conditioned')\n",
        "# _ = ax_cum_info_gain.set_ylim(-10, 290)\n",
        "_ = ax_cum_info_gain.legend(loc='upper right')\n",
        "\n",
        "# f_likelihood_overtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWO6Oix8OWsN"
      },
      "source": [
        "## Spatial comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6DtrJF0IuGZ"
      },
      "source": [
        "### Plot LL difference in space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehLHmeAWZuP1"
      },
      "outputs": [],
      "source": [
        "f_map, ax_map = plt.subplots()\n",
        "\n",
        "comparison_catalog_test = comparison_catalog[comparison_catalog['set_name'] == 'test']\n",
        "time_logical = (comparison_catalog_test['time'].values \u003e= start_time) \u0026 (comparison_catalog_test['time'].values \u003c end_time)\n",
        "\n",
        "\n",
        "longs, lats = lon_lat_for_map_plotting(\n",
        "    cropped_comparison_catalog['longitude'].values,\n",
        "    cropped_comparison_catalog['latitude'].values\n",
        "    )\n",
        "\n",
        "sc = ax_map.scatter(\n",
        "    longs,\n",
        "    lats,\n",
        "    c=cropped_comparison_catalog['log_difference'].values,\n",
        "    s=2.3**cropped_comparison_catalog['magnitude'],\n",
        "    alpha=0.3,\n",
        "    cmap='coolwarm',\n",
        "    norm=mpl.colors.TwoSlopeNorm(vmin=-2, vcenter=0, vmax=4),\n",
        "    )\n",
        "\n",
        "cb = f_map.colorbar(sc, ax=ax_map, shrink=0.5)\n",
        "cb.ax.set_yscale('linear')\n",
        "\n",
        "\n",
        "ax_map.set_xlim(longs.min(), longs.max())\n",
        "ax_map.set_ylim(lats.min(), lats.max())\n",
        "ax_map.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPZ6XOyWue3-"
      },
      "source": [
        "### Spatial distribution compared to seismicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0r1-a0PUSuh"
      },
      "outputs": [],
      "source": [
        "examples_array = np.array([(v[0][0].lng, v[0][0].lat, k) for k,v in domain.test_examples.items()])\n",
        "examples_array[:, 0], examples_array[:, 1] = lon_lat_for_map_plotting(\n",
        "    examples_array[:, 0],\n",
        "    examples_array[:, 1],\n",
        "    )\n",
        "\n",
        "mod_test_examples = {row[2]:[[geometry.Point(row[0], row[1])]] for row in examples_array}\n",
        "\n",
        "longitude_bins = np.arange(examples_array[:, 0].min(), examples_array[:, 0].max(), 0.2)\n",
        "latitude_bins = np.arange(examples_array[:, 1].min(), examples_array[:, 1].max(), 0.2)\n",
        "temporal_bins = np.linspace(examples_array[:, 2].min(), examples_array[:, 2].max(), 2)\n",
        "\n",
        "\n",
        "counts_in_bin, _ = np.histogramdd(examples_array, bins=(longitude_bins, latitude_bins, temporal_bins),\n",
        "               density=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-3qvgpvXmfY"
      },
      "outputs": [],
      "source": [
        "#--- Gaussian blur with nans\n",
        "\n",
        "def gauss_blur_w_nans(U, sigma=0.5, truncate=4.0):\n",
        "  V=U.copy()\n",
        "  V[np.isnan(U)]=0\n",
        "  VV=sp.ndimage.gaussian_filter(V, sigma=sigma, truncate=truncate)\n",
        "\n",
        "  W=np.ones_like(U)\n",
        "  W[np.isnan(U)]=0\n",
        "  WW=sp.ndimage.gaussian_filter(W, sigma=sigma, truncate=truncate)\n",
        "\n",
        "  return VV/WW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZuFmdY6zmSS"
      },
      "source": [
        "## Relation between spatial advantage and $m_c$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDzi8KaMGSeF"
      },
      "source": [
        "### Compute $m_c(x,y)$ map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f69Wg29JIuGa"
      },
      "source": [
        "#### function to create $m_c$ map of constant calculation radii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YTXKsIDeJCjt"
      },
      "outputs": [],
      "source": [
        "def map_mc_beta(\n",
        "    sub_catalog,\n",
        "    grid_spacing=0.1,\n",
        "    grid_side_degrees=None,\n",
        "    method = 'MAXC',\n",
        "    lon_vec=None,\n",
        "    lat_vec=None,\n",
        "    ):\n",
        "\n",
        "  lon_mod, lat_mod = lon_lat_for_map_plotting(sub_catalog.longitude.values, sub_catalog.latitude.values)\n",
        "  sub_catalog = sub_catalog.copy()\n",
        "  sub_catalog.longitude = lon_mod\n",
        "  sub_catalog.latitude = lat_mod\n",
        "  if lon_vec is None:\n",
        "    lon_vec = np.arange(sub_catalog.longitude.min(), sub_catalog.longitude.max(), grid_spacing)\n",
        "  if lat_vec is None:\n",
        "    lat_vec = np.arange(sub_catalog.latitude.min(), sub_catalog.latitude.max(), grid_spacing)\n",
        "  longs, lats = np.meshgrid(lon_vec, lat_vec)\n",
        "  centers = [[geometry.Point(ln, lt) for (ln, lt) in zip(longs.ravel(), lats.ravel())]]\n",
        "  if grid_side_degrees is None:\n",
        "    grid_side_degrees = grid_spacing\n",
        "  mc_beta = catalog_analysis.completeness_and_beta_in_square(\n",
        "      catalog = sub_catalog,\n",
        "      time_slice=slice(0, len(sub_catalog)),\n",
        "      centers=centers,\n",
        "      grid_side_degrees=grid_side_degrees,\n",
        "      method = method,\n",
        "  )\n",
        "\n",
        "  counts_in_bin = catalog_analysis.counts_in_square(\n",
        "      catalog = sub_catalog,\n",
        "      time_slice=slice(0, len(sub_catalog)),\n",
        "      centers=centers,\n",
        "      grid_side_degrees=grid_side_degrees,\n",
        "  )\n",
        "\n",
        "  mc, beta = mc_beta[0,:, 0], mc_beta[0,:, 1]\n",
        "  mc = mc.reshape(lats.shape)\n",
        "  beta = beta.reshape(lats.shape)\n",
        "  counts_in_bin = counts_in_bin.reshape(lats.shape)\n",
        "  mc_xr = xr.DataArray(mc.reshape(lats.shape), dims=['latitude', 'longitude'], coords={'latitude':lat_vec, 'longitude':lon_vec})\n",
        "  beta_xr = xr.DataArray(beta.reshape(lats.shape), dims=['latitude', 'longitude'], coords={'latitude':lat_vec, 'longitude':lon_vec})\n",
        "  counts_in_bin_xr = xr.DataArray(counts_in_bin.reshape(lats.shape), dims=['latitude', 'longitude'], coords={'latitude':lat_vec, 'longitude':lon_vec})\n",
        "  return mc_xr, beta_xr, counts_in_bin_xr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usJQ11s6GlOb"
      },
      "outputs": [],
      "source": [
        "MC_BY_MINIMAL_N_EVENTS = True\n",
        "MIN_EVENTS_IN_BIN = 100\n",
        "\n",
        "lon_centers = longitude_bins[:-1] + (longitude_bins[1:] - longitude_bins[:-1])/2\n",
        "lat_centers = latitude_bins[:-1] + (latitude_bins[1:] - latitude_bins[:-1])/2\n",
        "\n",
        "time_slice = slice(\n",
        "    np.where(domain.earthquakes_catalog.time==train_timestamps.min())[0][0],\n",
        "    np.where(domain.earthquakes_catalog.time==train_timestamps.max())[0][0],\n",
        "    )\n",
        "catalog_for_mc = domain.earthquakes_catalog[time_slice]\n",
        "new_lon, new_lat = lon_lat_for_map_plotting(catalog_for_mc.longitude.values, catalog_for_mc.latitude.values)\n",
        "catalog_for_mc['longitude'] = new_lon\n",
        "catalog_for_mc['latitude'] = new_lat\n",
        "\n",
        "if MC_BY_MINIMAL_N_EVENTS:\n",
        "  ddeg = 0.1 if MODEL_NAME=='Hauksson' else 0.5\n",
        "  mc_xr, nevents_xr, radius_xr = catalog_analysis.compute_grid_of_local_completeness(\n",
        "      catalog_for_mc,\n",
        "      grid_spacing=ddeg,\n",
        "      minimal_radius=ddeg,\n",
        "      minimal_events=MIN_EVENTS_IN_BIN,\n",
        "  )\n",
        "\n",
        "else:\n",
        "  mc_xr, beta_xr, counts_in_bin_xr = map_mc_beta(\n",
        "      catalog_for_mc,\n",
        "      grid_spacing=0.1,\n",
        "      grid_side_degrees=0.2,\n",
        "      lon_vec=lon_centers,\n",
        "      lat_vec=lat_centers,\n",
        "      )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBIbGct1AX0m"
      },
      "outputs": [],
      "source": [
        "example_lons, example_lats = lon_lat_for_map_plotting(examples_array[:, 0], examples_array[:, 1])\n",
        "\n",
        "if MC_BY_MINIMAL_N_EVENTS:\n",
        "  x_inds = np.searchsorted(mc_xr.longitude, example_lons)\n",
        "  x_inds = np.minimum(x_inds, len(mc_xr.longitude)-1)\n",
        "  y_inds = np.searchsorted(mc_xr.latitude, example_lats)\n",
        "  y_inds = np.minimum(y_inds, len(mc_xr.latitude)-1)\n",
        "\n",
        "  local_mc = mc_xr.values[y_inds, x_inds]\n",
        "  local_nevents = nevents_xr.values[y_inds, x_inds]\n",
        "  local_radius = radius_xr.values[y_inds, x_inds]\n",
        "\n",
        "else:\n",
        "  x_inds = np.searchsorted(longitude_bins, example_lons)\n",
        "  x_inds -= 1\n",
        "  x_inds = np.maximum(0, x_inds)\n",
        "  x_inds = np.minimum(len(mc_xr.longitude)-1, x_inds)\n",
        "  y_inds = np.searchsorted(latitude_bins , example_lats)\n",
        "  y_inds -= 1\n",
        "  y_inds = np.maximum(0, y_inds)\n",
        "  y_inds = np.minimum(len(mc_xr.latitude)-1, y_inds)\n",
        "\n",
        "  local_mc = mc_xr.values[y_inds, x_inds]\n",
        "  local_bin_counts = counts_in_bin_xr.values[y_inds, x_inds]\n",
        "  local_mc[local_bin_counts \u003c MIN_EVENTS_IN_BIN] = np.nan\n",
        "\n",
        "\n",
        "mc_spatial_total_bool = (local_mc \u003c= labels.test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D9UIxbcBsFZ"
      },
      "outputs": [],
      "source": [
        "#@title Plot all events with their m_c\n",
        "\n",
        "f_map_local_mc, ax_map_local_mc = plt.subplots()\n",
        "\n",
        "sc = ax_map_local_mc.scatter(\n",
        "    example_lons[mc_spatial_total_bool],\n",
        "    example_lats[mc_spatial_total_bool],\n",
        "    c=local_mc[mc_spatial_total_bool],\n",
        "    alpha=0.3,\n",
        "    cmap='coolwarm',\n",
        "    )\n",
        "\n",
        "cb = f_map_local_mc.colorbar(sc, ax=ax_map_local_mc, shrink=0.5)\n",
        "cb.ax.set_yscale('linear')\n",
        "\n",
        "\n",
        "ax_map_local_mc.set_xlim(example_lons.min(), example_lons.max())\n",
        "ax_map_local_mc.set_ylim(example_lats.min(), example_lats.max())\n",
        "ax_map_local_mc.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iqTM1FREhrx"
      },
      "outputs": [],
      "source": [
        "#@title plot $m_c$ and other relevant maps\n",
        "f_maps, ax_maps = plt.subplots(1, 3, figsize=(27,9))\n",
        "\n",
        "\n",
        "if MC_BY_MINIMAL_N_EVENTS:\n",
        "  _ = mc_xr.plot(ax=ax_maps[0], )\n",
        "  ax_maps[0].set_title('$m_c$')\n",
        "  _ = nevents_xr.plot(ax=ax_maps[1])\n",
        "  ax_maps[1].set_title('$n\\ events$')\n",
        "  _ = radius_xr.plot(ax=ax_maps[2])\n",
        "  ax_maps[2].set_title('$R$')\n",
        "else:\n",
        "  _ = mc_xr.plot(ax=ax_maps[0], )\n",
        "  ax_maps[0].set_title('$m_c$')\n",
        "  _ = beta_xr.plot(ax=ax_maps[1], vmax=4)\n",
        "  ax_maps[1].set_title('$\\\\beta$')\n",
        "  _ = counts_in_bin_xr.plot(ax=ax_maps[2], vmax=150)\n",
        "  ax_maps[2].set_title('$counts$')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd37q29fiXVb"
      },
      "source": [
        "## Condition on spatial $m_c(x,y)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtPLkEr-xWG3"
      },
      "outputs": [],
      "source": [
        "#@title mean LL conditioned on LOCAL incompleteness:  $m\\geq \\tilde{m}=m_c(x,y)$\n",
        "\n",
        "# --- set dictionary\n",
        "likelihoods_and_baselines_cond_local_incompleteness = {}\n",
        "\n",
        "# --- set model conditioned likelihoods\n",
        "set_name = 'test'\n",
        "\n",
        "for set_name in ['test']:\n",
        "  mll_local_completeness = np.full_like(labels.test_labels, np.nan)\n",
        "  spatial_result = np.array(\n",
        "      conditioned_likelihood_model(\n",
        "          local_mc,\n",
        "          set_name,\n",
        "          forecasts\n",
        "          )\n",
        "      )\n",
        "  mll_local_completeness[mc_spatial_total_bool] = spatial_result\n",
        "  likelihoods_and_baselines_cond_local_incompleteness[f'model_{MODEL_NAME}_likelihood_{set_name}'] = mll_local_completeness\n",
        "\n",
        "conditioned_local_incompleteness_test = compute_conditioned_gr_variations(\n",
        "    gr_models_beta_test,\n",
        "    gr_models_mc_test,\n",
        "    labels,\n",
        "    local_mc\n",
        ")\n",
        "for k in conditioned_local_incompleteness_test.keys():\n",
        "\n",
        "  mll_local_completeness = np.full_like(labels.test_labels, np.nan)\n",
        "  mll_local_completeness[mc_spatial_total_bool] = conditioned_local_incompleteness_test[k]\n",
        "  conditioned_local_incompleteness_test[k] = mll_local_completeness\n",
        "\n",
        "likelihoods_and_baselines_cond_local_incompleteness.update(conditioned_local_incompleteness_test)\n",
        "\n",
        "\n",
        "# --- display all\n",
        "summary_df_mean_ll_cond_mc_local = create_scores_summary_df(likelihoods_and_baselines_cond_local_incompleteness, drop_nans=True, exclude_zeros=False)\n",
        "summary_df_mean_ll_cond_mc_local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFU5H0rxCZ55"
      },
      "outputs": [],
      "source": [
        "f_thresh_t_local_barplot, ax_thresh_t_local_barplot = barplot_scores(summary_df_mean_ll_cond_mc_local, MODELS_TO_PLOT, [COLOR_PER_MODEL[m] for m in MODELS_TO_PLOT])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sqtVPHxIuGc"
      },
      "source": [
        "### Add local conditioning to cropped catalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRl6kcQgauK8"
      },
      "outputs": [],
      "source": [
        "model_name_likelihood_test = [k for k in likelihoods_and_baselines_cond_local_incompleteness.keys() if k.startswith('model')][0]\n",
        "add_log_difference_spatial_conditioned = np.log(likelihoods_and_baselines_cond_local_incompleteness[model_name_likelihood_test]) - np.log(\n",
        "    likelihoods_and_baselines_cond_local_incompleteness['train_gr_likelihood_test']\n",
        ")\n",
        "finite_difference_spatial_conditioned = np.copy(add_log_difference_spatial_conditioned)\n",
        "finite_difference_spatial_conditioned[~np.isfinite(finite_difference_spatial_conditioned)] = 0\n",
        "add_information_gain_spatial_conditioned = np.nancumsum(finite_difference_spatial_conditioned)\n",
        "\n",
        "\n",
        "cropped_comparison_catalog = cropped_comparison_catalog.assign(\n",
        "    log_difference_spatial_conditioned=add_log_difference_spatial_conditioned,\n",
        "    information_gain_spatial_conditioned=add_information_gain_spatial_conditioned,\n",
        "  )\n",
        "\n",
        "\n",
        "assign_dict = {split_name_to_model_and_set(k)[0]+'_local_condition':v for k, v in likelihoods_and_baselines_cond_local_incompleteness.items()}\n",
        "cropped_comparison_catalog = cropped_comparison_catalog.assign(**assign_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aORFJ0IxIuGc"
      },
      "source": [
        "### Add spatially conditioned curve to cumulative info plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx0CIbUybYqu"
      },
      "outputs": [],
      "source": [
        "_ = ax_cum_info_gain.plot(\n",
        "    x_info_gain,\n",
        "    add_information_gain_spatial_conditioned,\n",
        "    '-.',\n",
        "    color='red',\n",
        "    linewidth=2,\n",
        "    label='cumulative information gain - spatially conditioned')\n",
        "_ = ax_cum_info_gain.legend(loc='upper right')\n",
        "\n",
        "f_likelihood_overtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpisbiIiIuGc"
      },
      "source": [
        "## Show spatial distribution of information gain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBqH3omOYejW"
      },
      "outputs": [],
      "source": [
        "#--- Comute LL spatial distributions\n",
        "longitude_bins = mc_xr.longitude.values\n",
        "longitude_half_diff = (longitude_bins[1] - longitude_bins[0])/2\n",
        "longitude_bins = np.append(longitude_bins - longitude_half_diff, longitude_bins[-1] + longitude_half_diff)\n",
        "latitude_bins = mc_xr.latitude.values\n",
        "latitude_half_diff = (latitude_bins[1] - latitude_bins[0])/2\n",
        "latitude_bins = np.append(latitude_bins - latitude_half_diff, latitude_bins[-1] + latitude_half_diff)\n",
        "\n",
        "test_likelihood_keys = [k for k in likelihoods_and_baselines_cond_local_incompleteness.keys() if k.endswith('_test')]\n",
        "H_meanLL_dict_cond_local = {}\n",
        "for k in test_likelihood_keys:\n",
        "  values = likelihoods_and_baselines_cond_local_incompleteness[k]\n",
        "  statistic, x_edge, y_edge, binnumber = stats.binned_statistic_2d(\n",
        "      example_lons,\n",
        "      example_lats,\n",
        "      values=np.log(values),\n",
        "      statistic=np.nanmean,\n",
        "      bins=[longitude_bins, latitude_bins],\n",
        "      )\n",
        "\n",
        "  H_meanLL_dict_cond_local[k] = statistic\n",
        "\n",
        "\n",
        "set_to_plot = 'test'\n",
        "H_to_plot = [k+'_'+set_to_plot for k in MODELS_TO_PLOT]\n",
        "model_full_name = [h_name for h_name in H_to_plot if h_name.startswith('model_')][0]\n",
        "\n",
        "\n",
        "\n",
        "spatial_advantage_cond_local = {}\n",
        "for k in H_to_plot:\n",
        "  if k.startswith('model_'):\n",
        "    continue\n",
        "  spatial_advantage_cond_local[k] = H_meanLL_dict_cond_local[model_full_name].T - H_meanLL_dict_cond_local[k].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDc6eFuc9N_T"
      },
      "outputs": [],
      "source": [
        "# --- Plot differences in space\n",
        "\n",
        "longitude_diff = longitude_bins[1] - longitude_bins[0]\n",
        "latitude_diff = latitude_bins[1] - latitude_bins[0]\n",
        "extent = (\n",
        "    longitude_bins[0] - longitude_diff/2,\n",
        "    longitude_bins[-1] + longitude_diff/2,\n",
        "    latitude_bins[0] - latitude_diff/2,\n",
        "    latitude_bins[-1] + latitude_diff/2,\n",
        ")\n",
        "\n",
        "\n",
        "vmin = -2\n",
        "vmax = 3\n",
        "gamma = 0.3\n",
        "\n",
        "\n",
        "spatial_diff_figs = {}\n",
        "for k in spatial_advantage_cond_local:\n",
        "  f, ax = plt.subplots(1, 1,)\n",
        "  ii0 = ax.imshow(\n",
        "      spatial_advantage_cond_local[k],\n",
        "      origin='lower',\n",
        "      extent=extent,\n",
        "      cmap='coolwarm',\n",
        "      norm=mpl.colors.SymLogNorm(0.01, vmin=vmin, vmax=vmax, clip=True),\n",
        "      )\n",
        "  ax.set_title(f'Difference to {k}')\n",
        "  cb = f.colorbar(ii0, ax=ax, extend='both')\n",
        "  ax.set_aspect('equal', 'box')\n",
        "  ax.set_xlim(extent[0], extent[1])\n",
        "  ax.set_ylim(extent[2], extent[3])\n",
        "  spatial_diff_figs[k] = f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwBjUpFv3dxo"
      },
      "source": [
        "# Convert to a regression problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHeUc7Ux9-fh"
      },
      "outputs": [],
      "source": [
        "plot_kde = False\n",
        "if plot_kde:\n",
        "  sets_to_plot = ['train', 'validation', 'test']\n",
        "  f_regression, ax_regression = plt.subplots(1, 1, figsize=(7, 7))\n",
        "  alpha = 0.8\n",
        "  for k in sets_to_plot:\n",
        "    ax_regression.scatter(\n",
        "        getattr(labels, f'{k}_labels'),\n",
        "        probability_density_function(forecasts[k]).mean()*random_var_stretch + random_var_shift,\n",
        "        alpha=0.2,\n",
        "        label=k,\n",
        "        )\n",
        "  ax_regression.plot([MAG_THRESH, 5], [MAG_THRESH, 5], linewidth=3, color='k')\n",
        "  ax_regression.set_xlabel('label')\n",
        "  ax_regression.set_ylabel('mean of prediction')\n",
        "  leg = ax_regression.legend()\n",
        "  f_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I0eRg-zTK5E"
      },
      "source": [
        "# Plot resulting distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xZtYqhZIuGd"
      },
      "source": [
        "## Distribution for random queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb6kyykLjYO-"
      },
      "outputs": [],
      "source": [
        "#---- setup data\n",
        "plot_above_thresh = MAG_THRESH\n",
        "m_vec = np.linspace(MAG_THRESH, 7, 500)\n",
        "prob_density_inst = probability_density_function(forecasts['test'])\n",
        "prob_vecs = prob_density_inst.prob((m_vec[:, None] - random_var_shift)/random_var_stretch)/random_var_stretch\n",
        "\n",
        "test_labels_to_plot_from = labels.test_labels[labels.test_labels\u003e=plot_above_thresh]\n",
        "prob_vecs_to_plot_from = prob_vecs.numpy()[:, labels.test_labels\u003e=plot_above_thresh]\n",
        "\n",
        "\n",
        "p_for_mags = np.exp(BETA_OF_TRAIN_SET*test_labels_to_plot_from)\n",
        "p_for_mags /= p_for_mags.sum()\n",
        "rnd_seed = np.random.RandomState(seed=1000)\n",
        "label_idxs_to_plot = np.sort(rnd_seed.choice(prob_vecs_to_plot_from.shape[1],100, replace=False, p=p_for_mags))\n",
        "labels_to_plot = test_labels_to_plot_from[label_idxs_to_plot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWl4UY2kz0G5"
      },
      "outputs": [],
      "source": [
        "#--- setup figure\n",
        "num_mags = 25\n",
        "min_mag = 2\n",
        "max_mag = 6.5\n",
        "m_scale = np.linspace(min_mag-0.01, max_mag, num_mags)\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "\n",
        "chosen_colormap = warn_cold_cmap\n",
        "colors = chosen_colormap(np.linspace(0,1,num_mags))\n",
        "colors2plot = colors[np.argmin(np.abs(test_labels_to_plot_from[label_idxs_to_plot][:,None] - m_scale[None,:]), axis=1)]\n",
        "\n",
        "\n",
        "f_dist_fig, ax_dist_fig = plt.subplots(1,1,)\n",
        "\n",
        "for idx, lbl_index in enumerate(label_idxs_to_plot):\n",
        "  p = ax_dist_fig.plot(m_vec, prob_vecs_to_plot_from[:, lbl_index], alpha=0.4, color=colors2plot[idx], linewidth=4);\n",
        "\n",
        "  add_text = False\n",
        "  if add_text:\n",
        "    # add text\n",
        "    y_peak = prob_vecs_to_plot_from[:, lbl_index].max()\n",
        "    x_peak = m_vec[np.argmax(prob_vecs_to_plot_from[:, lbl_index])]\n",
        "    text = str(labels_to_plot[idx])\n",
        "    txt = ax_dist_fig.text(x_peak, y_peak, text);\n",
        "\n",
        "# plot GR train set\n",
        "train_gr_curve = metrics.gr_likelihood(m_vec, BETA_OF_TRAIN_SET, MAG_THRESH)\n",
        "gr_handle = ax_dist_fig.plot(m_vec, train_gr_curve, 'k--', label='train_gr_likelihood', linewidth=3)\n",
        "ax_dist_fig.legend(handles=gr_handle, frameon=False)\n",
        "\n",
        "norm_inst = plt.Normalize(min_mag, max_mag);\n",
        "sm = plt.cm.ScalarMappable(cmap=chosen_colormap, norm=norm_inst);\n",
        "\n",
        "cb = plt.colorbar(sm, ax=ax_dist_fig, label='True magnitude (label)')\n",
        "ax_dist_fig.set_xlabel('magnitude')\n",
        "ax_dist_fig.set_ylabel('p(magnitude)')\n",
        "ax_dist_fig.set_xscale('linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFcZ9I5Tygo"
      },
      "source": [
        "## Marginal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q2CvND7IuGe"
      },
      "outputs": [],
      "source": [
        "#--- Helper function\n",
        "def num_to_vec(num, data):\n",
        "  if isinstance(num, numbers.Number):\n",
        "    return np.full_like(data, num)\n",
        "  return num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv17IsROcfyq"
      },
      "outputs": [],
      "source": [
        "#--- data setup\n",
        "\n",
        "set_to_plot = 'test'\n",
        "m_vec = np.linspace(MAG_THRESH, 7, 500)\n",
        "marginal_norm = {}\n",
        "prob_density_inst = probability_density_function(forecasts[set_to_plot])\n",
        "prob_vecs = prob_density_inst.prob((m_vec[:, None] - random_var_shift)/random_var_stretch)/random_var_stretch\n",
        "marginal = prob_vecs.numpy().sum(axis=1)\n",
        "marginal_norm[f'model_{MODEL_NAME}_likelihood'] = marginal/np.trapz(marginal[1:], m_vec[1:])\n",
        "\n",
        "all_benchmarks_names = [split_name_to_model_and_set(k)[0] for k in gr_models_beta.keys() if k.endswith(f'_{set_to_plot}')]\n",
        "for name in all_benchmarks_names:\n",
        "  if 'events_kde' in name:\n",
        "    kde_pdf = np.array([kde_inst(m_vec) for kde_inst in gr_models_beta[f'{name}_{set_to_plot}']])\n",
        "    marginal = kde_pdf.sum(axis=0)\n",
        "  else:\n",
        "    beta_name =num_to_vec(\n",
        "      gr_models_beta[f'{name}_{set_to_plot}'], getattr(labels, f'{set_name}_labels')\n",
        "      ).ravel()\n",
        "    sampling_points_name = m_vec[:, None] - num_to_vec(\n",
        "      gr_models_mc[f'{name}_{set_to_plot}'], getattr(labels, f'{set_name}_labels')\n",
        "      )[None, :]\n",
        "    marginal_unraveled = tfp.distributions.Exponential(\n",
        "    beta_name,\n",
        "    force_probs_to_zero_outside_support=True\n",
        "    ).prob(sampling_points_name).numpy()\n",
        "    marginal = np.nansum(marginal_unraveled, axis=1)\n",
        "  marginal_norm[name] = marginal/np.trapz(marginal[1:], m_vec[1:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLfnfO5nSP79"
      },
      "outputs": [],
      "source": [
        "#--- plot\n",
        "\n",
        "bins = np.arange(MAG_THRESH, 10, 0.25)\n",
        "\n",
        "marginal_fig, marginal_ax = plt.subplots(1,1, figsize=(7,4))\n",
        "h = marginal_ax.hist(labels.test_labels, bins, alpha=0.3, density=True, label='test', color='royalblue')\n",
        "h = marginal_ax.hist(labels.train_labels, bins, alpha=0.3, density=True, label='train', color='darkorange')\n",
        "\n",
        "for model_name in MODELS_TO_PLOT:\n",
        "  marginal_ax.plot(\n",
        "      m_vec,\n",
        "      marginal_norm[model_name],\n",
        "      label=model_name,\n",
        "      linewidth=3,\n",
        "      color=COLOR_PER_MODEL[model_name],\n",
        "      )\n",
        "marginal_fig.legend(loc='outside upper right')\n",
        "marginal_ax.set_xlabel('magnitude')\n",
        "marginal_ax.set_ylabel('p(magnitude)')\n",
        "marginal_ax.set_yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfuy7I-oOq0S"
      },
      "source": [
        "# Convert to a binary classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66JgGIXhiv-Z"
      },
      "outputs": [],
      "source": [
        "# Set parameters for display\n",
        "m_chosen = 4\n",
        "m_thresh_vec = np.array([m_chosen])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URvAl7GDIuGf"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qjMtaD_Tmq5"
      },
      "outputs": [],
      "source": [
        "def auc_p_at_r(recall, precision, tp_ratio):\n",
        "  sort_idx = np.argsort(recall)\n",
        "  recall_sorted = recall[sort_idx]\n",
        "  precision_sorted = precision[sort_idx]\n",
        "  # widths = np.diff(precision)\n",
        "  # heights = recall[1:]\n",
        "  heights = precision_sorted[1:]\n",
        "  widths = np.diff(recall_sorted)\n",
        "  return (widths * heights).sum()- tp_ratio*(widths.sum())\n",
        "\n",
        "def boolean_metrics(random_variable_instance, test_labels, shift=0, m_thresh_vec=None):\n",
        "  if m_thresh_vec is None:\n",
        "    m_thresh_vec = np.arange(MAG_THRESH, 8, 0.33)\n",
        "\n",
        "  support = [0, np.inf]\n",
        "  tp_fp_results = {}\n",
        "  pr_results = {}\n",
        "  roc_auc = {}\n",
        "  tp_ratio = {}\n",
        "  for (i, m_thresh) in enumerate(m_thresh_vec):\n",
        "    m_thresh = int(m_thresh)\n",
        "    boolean_test = test_labels \u003e= m_thresh\n",
        "    tp_ratio[m_thresh] = boolean_test.sum()/boolean_test.size\n",
        "\n",
        "    p_val = random_variable_instance.survival_function((m_thresh - shift)/random_var_stretch).numpy()/random_var_stretch\n",
        "    fpr, tpr, _ = skl_metrics.roc_curve(boolean_test, p_val);\n",
        "    tp_fp_results[m_thresh] = (fpr, tpr)\n",
        "    try:\n",
        "      roc_auc[m_thresh] = skl_metrics.roc_auc_score(boolean_test, p_val);\n",
        "    except:\n",
        "      roc_auc[m_thresh] = 0\n",
        "    precision, recall, _ = skl_metrics.precision_recall_curve(boolean_test, p_val);\n",
        "    pr_results[m_thresh] = (precision, recall)\n",
        "\n",
        "\n",
        "  return {\n",
        "      'tp_fp_results': tp_fp_results,\n",
        "      'pr_results': pr_results,\n",
        "      'ap': {k:np.mean(pr_results[k][0][pr_results[k][1]!=0]) for k in pr_results.keys()},\n",
        "      'auc_pr': {k:skl_metrics.auc(pr_results[k][1], pr_results[k][0]) for k in pr_results.keys()},\n",
        "      'auc_p_at_r': {k:auc_p_at_r(pr_results[k][1], pr_results[k][0], tp_ratio[k]) for k in pr_results.keys()},\n",
        "      'roc_auc': roc_auc,\n",
        "      'tp_ratio': tp_ratio,\n",
        "  }\n",
        "\n",
        "def is_numeric(var):\n",
        "  is_it = not hasattr(var, 'shape')\n",
        "  if is_it:\n",
        "    return True\n",
        "  if len(var.shape)==0:\n",
        "    return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jdKI4ItIuGg"
      },
      "source": [
        "## Aggregate all classification data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9opYOWnX631"
      },
      "outputs": [],
      "source": [
        "random_variables_and_labels_and_shifts = {}\n",
        "for set_name in ['train', 'validation', 'test']:\n",
        "  random_variables_and_labels_and_shifts[f'model_{MODEL_NAME}_likelihood_{set_name}'] = (\n",
        "    probability_density_function(forecasts[set_name]),\n",
        "    getattr(labels, f'{set_name}_labels'),\n",
        "    MAG_THRESH\n",
        "    )\n",
        "\n",
        "all_benchmarks_names = [split_name_to_model_and_set(k)[0] for k in gr_models_beta.keys() if k.endswith(f'_{set_name}')]\n",
        "for name in all_benchmarks_names:\n",
        "  for set_name in ['train', 'validation', 'test']:\n",
        "    this_beta = gr_models_beta[f'{name}_{set_name}']\n",
        "    this_mc = gr_models_mc[f'{name}_{set_name}']\n",
        "    if 'events_kde' in name:\n",
        "      # random_var = kde_random_var(this_beta, samp_points)\n",
        "      pass\n",
        "    elif is_numeric(this_beta):\n",
        "      random_var = tfp.distributions.Exponential(\n",
        "          num_to_vec(\n",
        "              this_beta, getattr(labels, f'{set_name}_labels')\n",
        "              ).ravel(), force_probs_to_zero_outside_support=True\n",
        "          )\n",
        "\n",
        "      random_variables_and_labels_and_shifts[f'{name}_{set_name}'] = (\n",
        "          random_var,\n",
        "          getattr(labels, f'{set_name}_labels'),\n",
        "          gr_models_mc[f'{name}_{set_name}']\n",
        "          )\n",
        "    else:\n",
        "      is_finite = np.isfinite(this_beta.ravel()) \u0026 np.isfinite(this_mc.ravel())\n",
        "      random_var = tfp.distributions.Exponential(\n",
        "          num_to_vec(\n",
        "              this_beta[is_finite], getattr(labels, f'{set_name}_labels')[is_finite]\n",
        "              ).ravel(), force_probs_to_zero_outside_support=True\n",
        "          )\n",
        "\n",
        "      random_variables_and_labels_and_shifts[f'{name}_{set_name}'] = (\n",
        "          random_var,\n",
        "          getattr(labels, f'{set_name}_labels')[is_finite],\n",
        "          gr_models_mc[f'{name}_{set_name}'][is_finite]\n",
        "          )\n",
        "\n",
        "boolean_metrics_dict = {k: boolean_metrics(v[0], v[1], shift=v[2], m_thresh_vec=m_thresh_vec) for k, v in random_variables_and_labels_and_shifts.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZqtcZyAIuGg"
      },
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXAa58QSIuGg"
      },
      "outputs": [],
      "source": [
        "def plot_ROC(all_booleans_dict, models_to_plot, plot_colors_dict, ax, display_names_list, m_thresh=4, set_name='test', is_first=False):\n",
        "  plot_colors_set_dict = {}\n",
        "  models_to_plot_set = []\n",
        "  for m in models_to_plot:\n",
        "    model_name = [k for k in all_booleans_dict.keys() if k.startswith(m) and k.endswith(set_name)][0]\n",
        "    models_to_plot_set.append(model_name)\n",
        "    plot_colors_set_dict[model_name] = plot_colors_dict[m]\n",
        "\n",
        "  assert (m_thresh in all_booleans_dict[models_to_plot_set[0]]['tp_fp_results'].keys()), 'm_thresh not found in keys'\n",
        "\n",
        "  #--- iterate on models and benchmarks\n",
        "  for model_benchmark, v in all_booleans_dict.items():\n",
        "    if model_benchmark not in models_to_plot_set:\n",
        "      continue\n",
        "    print(f'model_benchmark: {model_benchmark}')\n",
        "\n",
        "    roc_auc = v['roc_auc']\n",
        "    p = ax.plot(\n",
        "        v['tp_fp_results'][m_thresh][0], v['tp_fp_results'][m_thresh][1],\n",
        "        label=f'{model_benchmark} (auc={roc_auc[m_thresh]:.2f})',\n",
        "        color=plot_colors_set_dict[model_benchmark],\n",
        "        )\n",
        "    p = ax.plot([0, 1], [0, 1], 'k--', linewidth=3);\n",
        "    _ = ax.set_xticks([0, 1], [0, 1])\n",
        "    _ = ax.set_yticks([0, 1], [0, 1])\n",
        "\n",
        "    #--- AUC\n",
        "    order_index = dict(zip(models_to_plot_set, range(len(models_to_plot_set))))\n",
        "    axins = ax.inset_axes(\n",
        "        [0.85, 0.05, 0.1, 0.5],\n",
        "        xlim=(-1, 1), ylim=(-0.5, len(MODELS_TO_PLOT)+0.5), xticks=[], yticks=[])\n",
        "    axins.axis('off')\n",
        "\n",
        "    counter = 0\n",
        "    for model_benchmark, v in all_booleans_dict.items():\n",
        "      if model_benchmark not in models_to_plot_set:\n",
        "        continue\n",
        "      roc_auc = v['roc_auc'][m_thresh]\n",
        "      y0 = len(models_to_plot_set) - 1*order_index[model_benchmark] -1.2\n",
        "      print_string = display_names_list[counter] + ' ' + f'{roc_auc:.2f}'\n",
        "      ha = 'right'\n",
        "      x0 = 1\n",
        "      axins.text(x0, y0, print_string, fontsize=6, color=plot_colors_set_dict[model_benchmark], ha=ha, va='center')\n",
        "      counter += 1\n",
        "    axins.text(x0, len(models_to_plot_set), 'AUC', fontsize=6, weight='heavy', ha=ha, va='center')\n",
        "  ax.set_ylabel('Recall ' + r'$( \\frac{tp}{tp + fn} )$',)\n",
        "  ax.set_xlabel(' False positive rate ' + r'$( \\frac{fp}{fp + tn} )$',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID0_3pwtIuGh"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1,1)\n",
        "plot_ROC(boolean_metrics_dict, MODELS_TO_PLOT, COLOR_PER_MODEL, ax, MODELS_TO_PLOT, m_thresh=4, set_name='test', is_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPHBCXgBIuGh"
      },
      "source": [
        "## P@R curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y28RrWZMIuGh"
      },
      "outputs": [],
      "source": [
        "DELTA = 1e-2  # 3e-3\n",
        "\n",
        "def precision_at_recall(precision, recall, delta):\n",
        "  thresholds = np.arange(0, 1, delta)\n",
        "  p_at_r = []\n",
        "  for t in thresholds:\n",
        "     p_at_r.append(np.max(precision[np.where(recall \u003e t)]))\n",
        "  p_at_r = np.array(p_at_r)\n",
        "  return p_at_r\n",
        "\n",
        "def plot_PR(all_booleans_dict, models_to_plot, plot_colors_dict, ax, m_thresh=4, set_name='test'):\n",
        "  plot_colors_set_dict = {}\n",
        "  models_to_plot_set = []\n",
        "  for m in models_to_plot:\n",
        "    model_name = [k for k in all_booleans_dict.keys() if k.startswith(m) and k.endswith(set_name)][0]\n",
        "    models_to_plot_set.append(model_name)\n",
        "    plot_colors_set_dict[model_name] = plot_colors_dict[m]\n",
        "\n",
        "  assert (m_thresh in all_booleans_dict[models_to_plot_set[0]]['tp_fp_results'].keys()), 'm_thresh not found in keys'\n",
        "\n",
        "  #--- iterate on models and benchmarks\n",
        "  for model_benchmark, v in all_booleans_dict.items():\n",
        "    if model_benchmark not in models_to_plot_set:\n",
        "      continue\n",
        "    print(f'model_benchmark: {model_benchmark}')\n",
        "\n",
        "\n",
        "    recall = v['pr_results'][m_thresh][1]\n",
        "    precision = v['pr_results'][m_thresh][0]\n",
        "    delta = DELTA\n",
        "    prec_at_recall = precision_at_recall(precision, recall, delta)\n",
        "    p = ax.plot(\n",
        "        np.arange(0, 1, delta),\n",
        "        prec_at_recall,\n",
        "        color=plot_colors_set_dict[model_benchmark],\n",
        "        )\n",
        "    _ = ax.set_xticks([0, 1], [0, 1])\n",
        "    _ = ax.set_yticks([0, 1], [0, 1])\n",
        "\n",
        "    #--- AUC\n",
        "    order_index = dict(zip(models_to_plot_set, range(len(models_to_plot_set))))\n",
        "    axins = ax.inset_axes(\n",
        "        [0.85, 0.42, 0.1, 0.5],\n",
        "        xlim=(-1, 1), ylim=(-0.5, len(MODELS_TO_PLOT)+0.5), xticks=[], yticks=[])\n",
        "    axins.axis('off')\n",
        "\n",
        "    for model_benchmark, v in all_booleans_dict.items():\n",
        "      if model_benchmark not in models_to_plot_set:\n",
        "        continue\n",
        "      ap = v['ap'][m_thresh]\n",
        "      auc_par = v['auc_p_at_r'][m_thresh]\n",
        "      y0 = len(models_to_plot_set) - 1*order_index[model_benchmark] -1.2\n",
        "      print_string = model_benchmark + ' ' + f'{auc_par:.2f}'\n",
        "      axins.text(1, y0, print_string, fontsize=6, color=plot_colors_set_dict[model_benchmark], ha='right', va='center',)\n",
        "    axins.text(1, len(models_to_plot_set), 'AUC', fontsize=6, weight='heavy', ha='right', va='center')\n",
        "\n",
        "\n",
        "  ax.set_ylabel('Precision ' + r'$( \\frac{tp}{tp + fp} )$',)\n",
        "  ax.set_xlabel('Recall  ' + r'$( \\frac{tp}{tp + fn} )$',)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArY8bAnqIuGh"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(1,1)\n",
        "plot_PR(boolean_metrics_dict, MODELS_TO_PLOT, COLOR_PER_MODEL, ax, m_thresh=4, set_name='test')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//intelligence/earthquakes/colab:notebook",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "142GRBMltYO8FTYzxJba0Nsuc2K6I3rU8",
          "timestamp": 1719071116469
        },
        {
          "file_id": "1x-ci7axx8_HPy-VThOywdPRnL9RCIZ73",
          "timestamp": 1707386996321
        },
        {
          "file_id": "1Ol2MByyPj9rv_dEMpqQWjXfVbrKY2R77",
          "timestamp": 1699277925468
        },
        {
          "file_id": "1X0uCXEsHaG6qH9nZBPo4yVFfjJ9bJySH",
          "timestamp": 1696314810048
        },
        {
          "file_id": "1Pel6FQL10BrAMuX44uk7E8YBtsJgErqA",
          "timestamp": 1691663081634
        },
        {
          "file_id": "1Rdt5eMiL31MblVNFT_GCF25qNGsooh0s",
          "timestamp": 1678092594120
        },
        {
          "file_id": "1cKMZ5nhX_tyW19rw3n1vonhRkLyukGg9",
          "timestamp": 1673957299492
        },
        {
          "file_id": "1Cda53khxHslAUQno6Lw02Ye4q7AWezjm",
          "timestamp": 1673869854946
        },
        {
          "file_id": "1GyuN0CLKvEEb6bufw5LTgqlnSop37Q39",
          "timestamp": 1673786767072
        },
        {
          "file_id": "1f3zM6j4DhjkA0Axhq_zGWSqL7tVK-Ijx",
          "timestamp": 1673444962135
        },
        {
          "file_id": "1FV55Uz5BggBpjsaGszKuXv3sUkWwiujo",
          "timestamp": 1672903019087
        },
        {
          "file_id": "1T7WlP4i5_9xe3H4klPFuIO0a55IN_BMY",
          "timestamp": 1669812340393
        },
        {
          "file_id": "1w-4UtNzqu0Jq0pnZt4gDyQNOX1aMRh_K",
          "timestamp": 1662983276624
        },
        {
          "file_id": "1aqEOiuBdr-UKuymkaqC2XL6psjnInZeJ",
          "timestamp": 1660034359535
        },
        {
          "file_id": "1qT62S_OaBOUQHlKcFnJQGrL9LK_aEPmz",
          "timestamp": 1658839391585
        },
        {
          "file_id": "1S4YbtcFlTECFwhSYu3REOT2D6gzkxJ_O",
          "timestamp": 1655717124037
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
