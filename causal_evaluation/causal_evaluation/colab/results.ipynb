{
  "cells": [
    {
      "metadata": {
        "id": "YSLkWrP_ZFyy"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2025 The Google Research Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "```\n",
        " http://www.apache.org/licenses/LICENSE-2.0\n",
        "```\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "metadata": {
        "id": "C7d41E0Rp2Tg"
      },
      "cell_type": "markdown",
      "source": [
        "# Visualize results and export figures"
      ]
    },
    {
      "metadata": {
        "id": "ijf85jeulwRW"
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import matplotlib.ticker as ticker\n",
        "import textwrap\n",
        "\n",
        "from causal_evaluation import utils"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "G1hMDfWStrXO"
      },
      "cell_type": "code",
      "source": [
        "# Flags\n",
        "DATA_PATH = './../../data/simulation' # @param\n",
        "N_SAMPLES_TRAIN = 50000 # @param\n",
        "N_SAMPLES_EVAL = 20000 # @param\n",
        "model_type = 'gradient_boosting' # @param\n",
        "group_model_type = 'gradient_boosting' # @param\n",
        "FIGURE_PATH = './../../figures'"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "9kYVyxUbNTrA"
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(FIGURE_PATH, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "BoNQ2b1knLbX"
      },
      "cell_type": "code",
      "source": [
        "settings = [\n",
        "    'covariate_shift',\n",
        "    'outcome_shift',\n",
        "    'complex_causal_shift',\n",
        "    'low_overlap_causal',\n",
        "    'anticausal_label_shift',\n",
        "    'anticausal_presentation_shift',\n",
        "    'complex_anticausal_shift',\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "lK45I1joqiQg"
      },
      "cell_type": "code",
      "source": [
        "# Read the predictions\n",
        "pred_eval_dict = {}\n",
        "\n",
        "for setting in settings:\n",
        "  filename = f'sim_samples_eval_{setting}_{N_SAMPLES_TRAIN}_{N_SAMPLES_EVAL}_{model_type}_{group_model_type}.parquet'\n",
        "  pred_eval_dict[setting] = pd.read_parquet(\n",
        "      os.path.join(DATA_PATH, filename)\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "BlOlN4nV1NMT"
      },
      "cell_type": "code",
      "source": [
        "# Read the eval results\n",
        "result_df = pd.concat([\n",
        "    pd.read_parquet(\n",
        "        os.path.join(\n",
        "            DATA_PATH,\n",
        "            f'metrics_{setting}_{N_SAMPLES_TRAIN}_{N_SAMPLES_EVAL}_{model_type}_{group_model_type}.parquet',\n",
        "        )\n",
        "    )\n",
        "    for setting in settings\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "oBLGAhEg0Xwf"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting functions"
      ]
    },
    {
      "metadata": {
        "id": "8xPt5l9L0XSo"
      },
      "cell_type": "code",
      "source": [
        "def calibration_plot(\n",
        "    y_true,\n",
        "    y_prob,\n",
        "    group=None,\n",
        "    ax=None,\n",
        "    plot_overall=True,\n",
        "    palette=None,\n",
        "    legend=False,\n",
        "    xlabel='Score',\n",
        "    ylabel='Fraction positive',\n",
        "    **kwargs,\n",
        "):\n",
        "\n",
        "  if ax is None:\n",
        "    plt.figure()\n",
        "    ax = plt.gca()\n",
        "\n",
        "  if kwargs.get('n_bins') is None:\n",
        "    kwargs['n_bins'] = 10\n",
        "\n",
        "  if palette is None:\n",
        "    palette = sns.color_palette('Set2')\n",
        "\n",
        "  palette_count = 0\n",
        "  if plot_overall:\n",
        "    calibration_curve_result = utils.calibration_curve_ci(\n",
        "        y_true, y_prob, **kwargs\n",
        "    )\n",
        "    ax.plot(\n",
        "        calibration_curve_result[1],\n",
        "        calibration_curve_result[0],\n",
        "        label='Overall',\n",
        "        color=palette[0],\n",
        "    )\n",
        "    ax.fill_between(\n",
        "        calibration_curve_result[1],\n",
        "        calibration_curve_result[2],\n",
        "        calibration_curve_result[3],\n",
        "        alpha=0.3,\n",
        "        color=palette[0],\n",
        "    )\n",
        "    palette_count = 1\n",
        "\n",
        "  if group is not None:\n",
        "    df = pd.DataFrame({'y_true': y_true, 'y_prob': y_prob, 'group': group})\n",
        "    for i, (the_group, group_df) in enumerate(df.groupby('group')):\n",
        "      if group_df.shape[0] \u003e 0:\n",
        "        calibration_curve_result = utils.calibration_curve_ci(\n",
        "            group_df['y_true'],\n",
        "            group_df['y_prob'],\n",
        "        )\n",
        "        ax.plot(\n",
        "            calibration_curve_result[1],\n",
        "            calibration_curve_result[0],\n",
        "            label=f'{the_group}',\n",
        "            linewidth=2,\n",
        "            color=palette[i + palette_count],\n",
        "        )\n",
        "        ax.fill_between(\n",
        "            calibration_curve_result[1],\n",
        "            calibration_curve_result[2],\n",
        "            calibration_curve_result[3],\n",
        "            alpha=0.3,\n",
        "            color=palette[i + palette_count],\n",
        "        )\n",
        "\n",
        "  ax.plot(\n",
        "      np.linspace(0, 1, 100),\n",
        "      np.linspace(0, 1, 100),\n",
        "      linestyle='-.',\n",
        "      color='gray',\n",
        "  )\n",
        "\n",
        "  ax.set_xlim(0, 1)\n",
        "  ax.set_ylim(0, 1)\n",
        "\n",
        "  if xlabel is not None:\n",
        "    ax.set_xlabel(xlabel, size=14)\n",
        "  if ylabel is not None:\n",
        "    ax.set_ylabel(ylabel, size=14)\n",
        "\n",
        "  if legend:\n",
        "    ax.legend()\n",
        "\n",
        "  sns.despine()\n",
        "\n",
        "\n",
        "def pointplot_with_errorbars(\n",
        "    x, y, hue, ci_low, ci_high, vertical=True, pairwise=False, **kwargs\n",
        "):\n",
        "  ax = plt.gca()\n",
        "\n",
        "  # Set the palette\n",
        "  palette = sns.color_palette('Set2')\n",
        "\n",
        "  point_scale = kwargs.get('point_scale', 0.75)\n",
        "\n",
        "  # Create the pointplot\n",
        "  points = sns.pointplot(\n",
        "      x=x,\n",
        "      y=y,\n",
        "      ax=ax,\n",
        "      hue=hue,\n",
        "      dodge=0.4,\n",
        "      linestyles='none',\n",
        "      palette=palette,\n",
        "      scale=point_scale,\n",
        "      hue_order=kwargs.get('hue_order'),\n",
        "  )\n",
        "\n",
        "  # Get the positions of the points\n",
        "  point_pos = []\n",
        "  point_colors = []\n",
        "  for collection in points.collections:\n",
        "    point_pos.extend(\n",
        "        collection.get_offsets()[:, (1 - vertical)]\n",
        "    )  # Get coordinates from offsets\n",
        "    point_colors.extend(\n",
        "        [collection.get_facecolor()] * len(collection.get_offsets())\n",
        "    )  # Repeat color for each point\n",
        "  # Add error bars with matching colors\n",
        "  for i, pos in enumerate(point_pos):\n",
        "    if vertical:\n",
        "      ax.vlines(\n",
        "          x=pos,\n",
        "          ymin=ci_low.values[i],\n",
        "          ymax=ci_high.values[i],\n",
        "          color=point_colors[i],\n",
        "      )\n",
        "    else:\n",
        "      ax.hlines(\n",
        "          y=pos,\n",
        "          xmin=ci_low.values[i],\n",
        "          xmax=ci_high.values[i],\n",
        "          color=point_colors[i],\n",
        "      )\n",
        "\n",
        "  if pairwise:\n",
        "    if vertical:\n",
        "      ax.axhline(y=0, color='gray', linestyle='--')\n",
        "    else:\n",
        "      ax.axvline(x=0, color='gray', linestyle='--')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cg2INHfvwOQt"
      },
      "cell_type": "code",
      "source": [
        "def format_zero(value, tick_number, num_digits=2):\n",
        "    if value == 0.0:\n",
        "        return \"0\"\n",
        "    else:\n",
        "        return f\"{value:.{num_digits}f}\" #Default format\n",
        "\n",
        "def wrap_titles(g, width=20):\n",
        "  \"\"\"Wraps the titles of a seaborn FacetGrid.\"\"\"\n",
        "  for ax in g.axes.flat:\n",
        "    title = ax.get_title()\n",
        "    if title:\n",
        "      wrapped_title = textwrap.fill(title, width=width, break_long_words=False)\n",
        "      ax.set_title(wrapped_title)\n",
        "  plt.tight_layout()\n",
        "  return g"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8QDM44D8o4NM"
      },
      "cell_type": "markdown",
      "source": [
        "# Simluation study results"
      ]
    },
    {
      "metadata": {
        "id": "z5tx2eiS4Ggu"
      },
      "cell_type": "code",
      "source": [
        "# Map population_on_group_comparison_weights to a weight_type\n",
        "the_filter = result_df.weights.map(lambda x: 'population_on_group_comparison' in x).values\n",
        "result_df.loc[the_filter, 'weight_type'] = \"population_on_group_comparison\"\n",
        "the_filter_normalized = result_df.weights.map(lambda x: 'population_on_group_comparison_weights_normalized' in x).values\n",
        "result_df.loc[the_filter_normalized, 'weight_type'] = \"population_on_group_comparison_normalized\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "C1mweCelpAWx"
      },
      "cell_type": "code",
      "source": [
        "# Create a dataframe for plotting\n",
        "plot_df = result_df.copy()\n",
        "\n",
        "# Map the weights\n",
        "weight_mapping_dict = {\n",
        "    'weights_none': 'None',\n",
        "    'weights_none_overall': 'None',\n",
        "    'weights_population_x': 'X',\n",
        "    'weights_population_y': 'Y',\n",
        "    'weights_population_r_x': 'R',\n",
        "    'weights_population_r_xa': 'R',\n",
        "    'weights_population_r_xa_stratified': 'R',\n",
        "    'weights_stable_x': 'X',\n",
        "    'weights_stable_y': 'Y',\n",
        "    'weights_stable_r_x': 'R',\n",
        "    'weights_stable_r_xa': 'R',\n",
        "    'weights_stable_r_xa_stratified': 'R',\n",
        "    'weights_cross_group_x': 'X',\n",
        "    'weights_cross_group_y': 'Y',\n",
        "    'weights_cross_group_r_x': 'R',\n",
        "    'weights_cross_group_r_xa': 'R',\n",
        "    'weights_cross_group_r_xa_stratified': 'R',\n",
        "    'population_on_group_comparison_weights_none': 'None',\n",
        "    'population_on_group_comparison_weights_x': 'X',\n",
        "    'population_on_group_comparison_weights_y': 'Y',\n",
        "    'population_on_group_comparison_weights_r_x': 'R',\n",
        "    'population_on_group_comparison_weights_r_xa': 'R',\n",
        "    'population_on_group_comparison_weights_r_xa_stratified': 'R',\n",
        "    'population_on_group_comparison_weights_normalized_x': 'X',\n",
        "    'population_on_group_comparison_weights_normalized_y': 'Y',\n",
        "    'population_on_group_comparison_weights_normalized_r_x': 'R',\n",
        "    'population_on_group_comparison_weights_normalized_r_xa': 'R',\n",
        "    'population_on_group_comparison_weights_normalized_r_xa_stratified': 'R',\n",
        "}\n",
        "plot_df['weights'] = result_df['weights'].replace(weight_mapping_dict)\n",
        "\n",
        "plot_df['weights'] = pd.Categorical(\n",
        "    plot_df['weights'], ['None', 'X', 'Y', 'R']\n",
        ")\n",
        "\n",
        "setting_title_dict = {\n",
        "    'covariate_shift': 'Covariate Shift',\n",
        "    'outcome_shift': 'Outcome Shift',\n",
        "    'complex_causal_shift': 'Complex Causal',\n",
        "    'low_overlap_causal': 'Separable',\n",
        "    'anticausal_label_shift': 'Label Shift',\n",
        "    'anticausal_presentation_shift': 'Presentation Shift',\n",
        "    'complex_anticausal_shift': 'Complex Anticausal',\n",
        "}\n",
        "plot_df['setting'] = plot_df['setting'].replace(setting_title_dict)\n",
        "\n",
        "plot_df['setting'] = pd.Categorical(\n",
        "    plot_df['setting'],\n",
        "    list(setting_title_dict.values())\n",
        ")\n",
        "\n",
        "plot_df['features'] = plot_df['features'].replace(\n",
        "    {'features_x': 'X', 'features_xa': 'XA', 'features_xa_stratified': 'X_strat'}\n",
        ")\n",
        "\n",
        "metric_dict = {'log_loss': 'log loss',\n",
        "        'roc_auc': 'AUC-ROC',\n",
        "        'label_rate': 'cls rate',\n",
        "        'recall_0.5': 'sensitivity',\n",
        "        'specificity_0.5': 'specificity',\n",
        "        'precision_0.5': 'precision',\n",
        "        'net_benefit_0.5_0.5': 'net benefit'}\n",
        "plot_df['metric'] = plot_df['metric'].replace(\n",
        "metric_dict\n",
        ")\n",
        "\n",
        "plot_df['metric'] = pd.Categorical(\n",
        "    plot_df['metric'],\n",
        "    list(metric_dict.values())\n",
        ")\n",
        "\n",
        "plot_df['group'] = plot_df['group'].replace(\n",
        "    {\"overall\": \"Population\"}\n",
        ")\n",
        "plot_df = plot_df.query('~weights.isna()')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Db9bdaGxIs11"
      },
      "cell_type": "code",
      "source": [
        "relative_comparison_features = [\"relative_comparison\", \"relative_comparison_stratified\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "r4GEXBrh0QEO"
      },
      "cell_type": "code",
      "source": [
        "metric='log loss'\n",
        "weight_types = ['None']\n",
        "settings_to_plot = setting_title_dict.values()\n",
        "\n",
        "feature_set = ['X', 'XA']\n",
        "\n",
        "g = sns.FacetGrid(\n",
        "  (\n",
        "      plot_df.query(\n",
        "          'weight_type == \"population_on_group_comparison\" \u0026'\n",
        "          ' metric == @metric \u0026 setting in @settings_to_plot \u0026'\n",
        "          ' features in @feature_set'\n",
        "      )\n",
        "      .sort_values(['group', 'setting'])\n",
        "      .assign(setting=lambda x: x.setting.values.remove_unused_categories(),\n",
        "              weights=lambda x: x.weights.values.remove_unused_categories())\n",
        "  ),\n",
        "  col='weights',\n",
        "  row='features',\n",
        "  margin_titles=True,\n",
        "  sharex=True\n",
        ")\n",
        "\n",
        "g.map(\n",
        "  pointplot_with_errorbars,\n",
        "  'performance',\n",
        "  'setting',\n",
        "  'group',\n",
        "  'ci_low',\n",
        "  'ci_high',\n",
        "  vertical=False,\n",
        "  pairwise=True,\n",
        "  point_scale=0.5\n",
        ")\n",
        "\n",
        "g.set_axis_labels('', '')\n",
        "g.fig.supylabel(f'Setting', fontsize=16, x=-0.06, y=0.57)\n",
        "g.fig.supxlabel(f'Subgroup {metric} - weighted population estimate', fontsize=16, x=0.55, y=-0.075)\n",
        "\n",
        "g.set_titles(\n",
        "  row_template='Covariates: {row_name}', col_template='Weights: {col_name}', size=12\n",
        ")\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "  ax.tick_params(axis='x', labelsize=12)  # Set x-axis label size to 12\n",
        "\n",
        "# Legend\n",
        "g.add_legend(fontsize=12)\n",
        "g.legend.set_title('Group')\n",
        "sns.move_legend(g, 'center right', bbox_to_anchor=(1.03, 0.57))\n",
        "plt.setp(g._legend.get_title(), fontsize=14)\n",
        "plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "g.figure.set_size_inches(8.5, 3)\n",
        "for filetype in ['png', 'pdf']:\n",
        "  g.figure.savefig(\n",
        "      os.path.join(FIGURE_PATH, f'adjustment_weights_xyr_{metric}_main.{filetype}'), format=filetype, bbox_inches='tight'\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d6SL2qrBFVfG"
      },
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  for metric in metric_dict.values():\n",
        "\n",
        "    weight_types = ['None']\n",
        "    settings_to_plot = setting_title_dict.values()\n",
        "\n",
        "    feature_set = ['X', 'XA', 'X_strat']\n",
        "\n",
        "    g = sns.FacetGrid(\n",
        "        (\n",
        "            plot_df.query(\n",
        "                'weight_type == \"population_on_group_comparison\" \u0026'\n",
        "                ' metric == @metric \u0026 setting in @settings_to_plot \u0026'\n",
        "                ' features in @feature_set'\n",
        "            )\n",
        "            .sort_values(['group', 'setting'])\n",
        "            .assign(setting=lambda x: x.setting.values.remove_unused_categories(),\n",
        "                    weights=lambda x: x.weights.values.remove_unused_categories())\n",
        "        ),\n",
        "        col='weights',\n",
        "        row='features',\n",
        "        margin_titles=True,\n",
        "        sharex=True\n",
        "    )\n",
        "\n",
        "    g.map(\n",
        "        pointplot_with_errorbars,\n",
        "        'performance',\n",
        "        'setting',\n",
        "        'group',\n",
        "        'ci_low',\n",
        "        'ci_high',\n",
        "        vertical=False,\n",
        "        pairwise=True,\n",
        "        point_scale=0.5\n",
        "    )\n",
        "\n",
        "    g.set_axis_labels('', '')\n",
        "    g.fig.supylabel(f'Setting', fontsize=16, x=-0.06, y=0.57)\n",
        "    g.fig.supxlabel(f'Subgroup {metric} - weighted population estimate', fontsize=16, x=0.55, y=-0.075)\n",
        "\n",
        "    g.set_titles(\n",
        "        row_template='Cov: {row_name}', col_template='Weights: {col_name}', size=12\n",
        "    )\n",
        "\n",
        "    for ax in g.axes.flat:\n",
        "      ax.tick_params(axis='x', labelsize=12)  # Set x-axis label size to 12\n",
        "\n",
        "    # Legend\n",
        "    g.add_legend(fontsize=12)\n",
        "    g.legend.set_title('Group')\n",
        "    sns.move_legend(g, 'center right', bbox_to_anchor=(1.03, 0.57))\n",
        "    plt.setp(g._legend.get_title(), fontsize=14)\n",
        "    plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "    g.figure.set_size_inches(8.5, 5)\n",
        "    for filetype in ['png', 'pdf']:\n",
        "      g.figure.savefig(\n",
        "          os.path.join(FIGURE_PATH, f'adjustment_weights_xyr_{metric}.{filetype}'), format=filetype, bbox_inches='tight'\n",
        "      )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ETa1BUwUpIKL"
      },
      "cell_type": "code",
      "source": [
        "# Calibration plots\n",
        "figsize = (8.5, 3.5)\n",
        "fig, axes = plt.subplots(3, len(settings), sharex=True, sharey=True, figsize=figsize)\n",
        "\n",
        "for i, (setting, feature_set) in enumerate(\n",
        "    itertools.product(settings, ['x', 'xa', 'xa_stratified'])\n",
        "):\n",
        "\n",
        "  calibration_plot(\n",
        "      pred_eval_dict[setting]['y'],\n",
        "      pred_eval_dict[setting][f'pred_probs_y1_{feature_set}'],\n",
        "      group=pred_eval_dict[setting]['a'],\n",
        "      plot_overall=False,\n",
        "      ax=axes[i % 3][i // 3],\n",
        "      legend=False,\n",
        "      xlabel=None,\n",
        "      ylabel=None,\n",
        "  )\n",
        "\n",
        "for i, setting in enumerate(settings):\n",
        "  axes[0][i].set_title(setting_title_dict[setting], size=8)\n",
        "\n",
        "axes[0][-1].text(x=1.02, y=0.3, s='Cov.: X', rotation=-90, size=8)\n",
        "axes[1][-1].text(x=1.02, y=0.3, s='Cov.: XA', rotation=-90, size=8)\n",
        "axes[2][-1].text(x=1.02, y=0.1, s='Cov.: X_strat', rotation=-90, size=8)\n",
        "\n",
        "fig.supxlabel('Score', size=14, y=0.005)\n",
        "fig.supylabel('Fraction positive', size=14, x=0.03)\n",
        "plt.tight_layout()\n",
        "fig.set_size_inches(*figsize)\n",
        "axes[1][-1].legend(frameon=False, bbox_to_anchor=(1.25, 1.2), title='Group')\n",
        "for filetype in ['png', 'pdf']:\n",
        "  fig.savefig(\n",
        "      os.path.join(FIGURE_PATH, f'calibration.{filetype}'), format=filetype, bbox_inches='tight'\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "tQao-wPzygMb"
      },
      "cell_type": "code",
      "source": [
        "weight_types = ['None']\n",
        "metrics = ['log loss', 'AUC-ROC', 'net benefit', 'sensitivity', 'specificity']\n",
        "settings_to_plot = setting_title_dict.values()\n",
        "\n",
        "g = sns.FacetGrid(\n",
        "    (\n",
        "        plot_df.query(\n",
        "            'weight_type in @weight_types \u0026 features == \"relative_comparison\" \u0026'\n",
        "            ' metric.isin(@metrics) \u0026 setting in @settings_to_plot'\n",
        "        )\n",
        "        .sort_values(['group', 'setting'])\n",
        "        .assign(\n",
        "            setting=lambda x: x.setting.values.remove_unused_categories(),\n",
        "            metric=lambda x: x.metric.values.remove_unused_categories(),\n",
        "            )\n",
        "    ),\n",
        "    col='metric',\n",
        "    margin_titles=True,\n",
        "    sharex=False\n",
        ")\n",
        "\n",
        "g.map(\n",
        "    pointplot_with_errorbars,\n",
        "    'performance',\n",
        "    'setting',\n",
        "    'group',\n",
        "    'ci_low',\n",
        "    'ci_high',\n",
        "    vertical=False,\n",
        "    pairwise=True,\n",
        "    point_scale=0.5\n",
        ")\n",
        "\n",
        "g.set_axis_labels('', '')\n",
        "g.fig.supylabel(f'Setting', fontsize=16, x=-0.1, y=0.6)\n",
        "g.fig.supxlabel(f'Difference in performance (subgroup-aware vs. unaware model)', fontsize=16, x=0.5, y=-0.02)\n",
        "\n",
        "g.set_titles(\n",
        "    row_template='', col_template='{col_name}', size=12\n",
        ")\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "  ax.tick_params(axis='x', labelsize=10)\n",
        "  ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_zero))\n",
        "\n",
        "# Legend\n",
        "g.add_legend(fontsize=10)\n",
        "g.legend.set_title('Group')\n",
        "sns.move_legend(g, 'center right', bbox_to_anchor=(1.07, 0.57))\n",
        "plt.setp(g._legend.get_title(), fontsize=14)\n",
        "plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "g.figure.set_size_inches(8.5, 2.5)\n",
        "for filetype in ['png', 'pdf']:\n",
        "  g.figure.savefig(\n",
        "      os.path.join(FIGURE_PATH, f'relative_performance.{filetype}'), format=filetype, bbox_inches=\"tight\"\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "EQz79p8SgAiT"
      },
      "cell_type": "code",
      "source": [
        "# Population mapping results\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  for metric in metric_dict.values():\n",
        "    weight_types = ['population', 'None']\n",
        "    settings_to_plot = setting_title_dict.values()\n",
        "    the_plot_df = (plot_df.query(\n",
        "        'weight_type in @weight_types \u0026 ~features.isin(@relative_comparison_features) \u0026'\n",
        "        ' metric == @metric \u0026 setting in @settings_to_plot'\n",
        "    ).query('group != \"Population\"')\n",
        "    .sort_values(['group', 'setting', 'weights'])\n",
        "    .assign(setting=lambda x: x.setting.values.remove_unused_categories(),\n",
        "            weights=lambda x: x.weights.replace('None', 'Subgroup')\n",
        "            )\n",
        "    )\n",
        "\n",
        "    g = sns.FacetGrid(\n",
        "        the_plot_df,\n",
        "        row='setting',\n",
        "        col='features',\n",
        "        margin_titles=True,\n",
        "        sharex='row',\n",
        "    )\n",
        "\n",
        "    g.map(\n",
        "        pointplot_with_errorbars,\n",
        "        'performance',\n",
        "        'weights',\n",
        "        'group',\n",
        "        'ci_low',\n",
        "        'ci_high',\n",
        "        vertical=False,\n",
        "        point_scale=0.5\n",
        "    )\n",
        "\n",
        "    g.set_axis_labels('', '')\n",
        "    g.fig.supylabel(f'Control variable', fontsize=16, x=-0.02)\n",
        "    g.fig.supxlabel(f'Weighted model performance ({metric})', fontsize=16, x=0.5, y=-0.02)\n",
        "\n",
        "    g.set_titles(\n",
        "        row_template='{row_name}', col_template='Features: {col_name}', size=10\n",
        "    )\n",
        "    g = wrap_titles(g)\n",
        "\n",
        "    for ax in g.axes.flat:\n",
        "      ax.tick_params(axis='x', labelsize=10)\n",
        "      ax.tick_params(axis='y', labelsize=10)\n",
        "      if metric == \"net benefit\":\n",
        "        num_digits=3\n",
        "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda *args: format_zero(*args, num_digits=num_digits)))\n",
        "\n",
        "    # Legend\n",
        "    g.add_legend(fontsize=12)\n",
        "    g.legend.set_title('Group')\n",
        "    sns.move_legend(g, 'center right', bbox_to_anchor=(1.03, 0.50))\n",
        "    plt.setp(g._legend.get_title(), fontsize=14)\n",
        "    plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "    g.fig.subplots_adjust(hspace=0.2, wspace=0.1)\n",
        "    g.figure.set_size_inches(8.5, 11)\n",
        "    for filetype in ['png', 'pdf']:\n",
        "      g.figure.savefig(\n",
        "          os.path.join(FIGURE_PATH, f'adjustment_weights_absolute_{metric}.{filetype}'), format=filetype, bbox_inches=\"tight\"\n",
        "      )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "jzkBI7Q6pq_4"
      },
      "cell_type": "code",
      "source": [
        "# Plot absolute performance across settings using shared space weights\n",
        "weight_types = ['stable', 'None']\n",
        "\n",
        "for metric in metric_dict.values():\n",
        "\n",
        "  g = sns.FacetGrid(\n",
        "      (\n",
        "          plot_df.query(\n",
        "              'weight_type in @weight_types \u0026 ~features.isin(@relative_comparison_features) \u0026'\n",
        "              ' metric == @metric'\n",
        "          )\n",
        "          .sort_values(['weights', 'setting', 'group'])\n",
        "          .assign(setting=lambda x: x.setting.values.remove_unused_categories())\n",
        "      ),\n",
        "      row='setting',\n",
        "      col='weights',\n",
        "      margin_titles=True,\n",
        "      sharey='row',\n",
        "  )\n",
        "\n",
        "  g.map(\n",
        "      pointplot_with_errorbars,\n",
        "      'features',\n",
        "      'performance',\n",
        "      'group',\n",
        "      'ci_low',\n",
        "      'ci_high',\n",
        "      vertical=True,\n",
        "      point_scale=0.5\n",
        "  )\n",
        "\n",
        "  g.set_axis_labels('', '')\n",
        "  g.fig.supylabel(f'Shared space performance ({metric})', fontsize=16, x=-0.01)\n",
        "  g.fig.supxlabel(f'Covariate set', fontsize=16, x=0.45, y=-0.03)\n",
        "\n",
        "  g.set_titles(\n",
        "      row_template='{row_name}', col_template='Weights: {col_name}', size=8\n",
        "  )\n",
        "  g = wrap_titles(g)\n",
        "\n",
        "  for ax in g.axes.flat:\n",
        "    ax.tick_params(axis='x', labelsize=10)  # Set x-axis label size to 12\n",
        "\n",
        "  # Legend\n",
        "  g.add_legend(fontsize=12)\n",
        "  g.legend.set_title('Group')\n",
        "  sns.move_legend(g, 'center right', bbox_to_anchor=(1.05, 0.57))\n",
        "  plt.setp(g._legend.get_title(), fontsize=14)\n",
        "  plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "\n",
        "  g.figure.set_size_inches(8.5, 9)\n",
        "  for filetype in ['png', 'pdf']:\n",
        "    g.figure.savefig(\n",
        "        os.path.join(FIGURE_PATH, f'shared_space_weights_xyr_{metric}.{filetype}'), format=filetype, bbox_inches=\"tight\"\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "sRXNxfYEYgcx"
      },
      "cell_type": "markdown",
      "source": [
        "# ACS PUMS Results"
      ]
    },
    {
      "metadata": {
        "id": "fHb39rH6Yi79"
      },
      "cell_type": "code",
      "source": [
        "# Flags\n",
        "DATA_PATH_ACS = '.../../data/acs_pums/' # @param"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "SZkZbvChYzHW"
      },
      "cell_type": "code",
      "source": [
        "tasks = [\n",
        "    'ACSIncome',\n",
        "    'ACSPublicCoverage'\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "q8gfAlSMY5Oq"
      },
      "cell_type": "code",
      "source": [
        "# Read the predictions\n",
        "pred_eval_dict_acs = {}\n",
        "\n",
        "for task in tasks:\n",
        "  filename = f'preds_{task}_5-Year_2018_gradient_boosting.parquet'\n",
        "  pred_eval_dict_acs[task] = pd.read_parquet(\n",
        "      os.path.join(DATA_PATH_ACS, filename)\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c01_Jlt8ZJlP"
      },
      "cell_type": "code",
      "source": [
        "# Read the eval results\n",
        "result_df_acs = pd.concat([\n",
        "    pd.read_parquet(\n",
        "        os.path.join(\n",
        "            DATA_PATH_ACS,\n",
        "            f'metrics_{task}_5-Year_2018_gradient_boosting.parquet',\n",
        "        )\n",
        "    )\n",
        "    for task in tasks\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "bQ2hDd1CZYii"
      },
      "cell_type": "code",
      "source": [
        "# Map population_on_group_comparison_weights to a weight_type\n",
        "the_filter = result_df_acs.weights.map(lambda x: 'population_on_group_comparison' in x).values\n",
        "result_df_acs.loc[the_filter, 'weight_type'] = \"population_on_group_comparison\"\n",
        "the_filter_normalized = result_df_acs.weights.map(lambda x: 'population_on_group_comparison_weights_normalized' in x).values\n",
        "result_df_acs.loc[the_filter_normalized, 'weight_type'] = \"population_on_group_comparison_normalized\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "oBVcN8aEZnG2"
      },
      "cell_type": "code",
      "source": [
        "group_name_map_df = pred_eval_dict_acs[tasks[0]][['group', 'group_name']].drop_duplicates()\n",
        "group_name_map_df['group'] = group_name_map_df['group'].astype(str)\n",
        "group_name_map_df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8gSva-RlZdf3"
      },
      "cell_type": "code",
      "source": [
        "plot_df_acs = result_df_acs.copy()\n",
        "\n",
        "plot_df_acs = plot_df_acs.merge(group_name_map_df, how='left')\n",
        "\n",
        "plot_df_acs['weights'] = plot_df_acs['weights'].replace(weight_mapping_dict)\n",
        "\n",
        "plot_df_acs['weights'] = pd.Categorical(\n",
        "    plot_df_acs['weights'], ['None', 'X', 'Y', 'R']\n",
        ")\n",
        "\n",
        "plot_df_acs['task'] = pd.Categorical(\n",
        "    plot_df_acs['task'],\n",
        "    list(['ACSIncome', 'ACSPublicCoverage'])\n",
        ")\n",
        "\n",
        "plot_df_acs['features'] = plot_df_acs['features'].replace(\n",
        "    {'features_x': 'X', 'features_xa': 'XA', 'features_xa_stratified': 'X_strat'}\n",
        ")\n",
        "\n",
        "plot_df_acs['metric'] = plot_df_acs['metric'].replace(\n",
        "  metric_dict\n",
        ")\n",
        "\n",
        "plot_df_acs['metric'] = pd.Categorical(\n",
        "    plot_df_acs['metric'],\n",
        "    list(metric_dict.values())\n",
        ")\n",
        "\n",
        "plot_df_acs['group'] = plot_df_acs['group'].replace(\n",
        "    {\"overall\": \"Population\"}\n",
        ")\n",
        "plot_df_acs = plot_df_acs.query('~weights.isna()')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "b3q6TbFlchWC"
      },
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  for metric in metric_dict.values():\n",
        "    weight_types = ['None']\n",
        "    tasks_to_plot = ['ACSIncome', 'ACSPublicCoverage']\n",
        "\n",
        "    feature_set = ['X', 'XA', 'X_strat']\n",
        "\n",
        "    g = sns.FacetGrid(\n",
        "      (\n",
        "          plot_df_acs.query(\n",
        "              'weight_type == \"population_on_group_comparison\" \u0026'\n",
        "              ' metric == @metric \u0026 task in @tasks_to_plot \u0026'\n",
        "              ' features in @feature_set'\n",
        "          )\n",
        "          .sort_values(['group_name', 'task'])\n",
        "          .assign(task=lambda x: x.task.values.remove_unused_categories(),\n",
        "                  weights=lambda x: x.weights.values.remove_unused_categories())\n",
        "      ),\n",
        "      col='weights',\n",
        "      row='features',\n",
        "      margin_titles=True,\n",
        "      sharex=True\n",
        "    )\n",
        "\n",
        "    g.map(\n",
        "      pointplot_with_errorbars,\n",
        "      'performance',\n",
        "      'task',\n",
        "      'group_name',\n",
        "      'ci_low',\n",
        "      'ci_high',\n",
        "      vertical=False,\n",
        "      pairwise=True,\n",
        "      point_scale=0.5\n",
        "    )\n",
        "\n",
        "    g.set_axis_labels('', '')\n",
        "    g.fig.supylabel(f'Task', fontsize=14, x=-0.06, y=0.57)\n",
        "    g.fig.supxlabel(f'Subgroup {metric} - weighted population estimate', fontsize=14, x=0.5, y=-0.075)\n",
        "\n",
        "    g.set_titles(\n",
        "      row_template='Cov.: {row_name}', col_template='Weights: {col_name}', size=12\n",
        "    )\n",
        "\n",
        "    for ax in g.axes.flat:\n",
        "      ax.tick_params(axis='x', labelsize=12)  # Set x-axis label size to 12\n",
        "\n",
        "    # Legend\n",
        "    g.add_legend(fontsize=12)\n",
        "    g.legend.set_title('Group')\n",
        "    sns.move_legend(g, 'center right', bbox_to_anchor=(1.08, 0.5))\n",
        "    plt.setp(g._legend.get_title(), fontsize=14)\n",
        "    plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "    g.figure.set_size_inches(8.5, 4)\n",
        "    for filetype in ['png', 'pdf']:\n",
        "      g.figure.savefig(\n",
        "          os.path.join(FIGURE_PATH, f'adjustment_weights_xyr_{metric}_acs.{filetype}'), format=filetype, bbox_inches='tight'\n",
        "      )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Q2G4bdkfeH1Y"
      },
      "cell_type": "code",
      "source": [
        "# Calibration plots\n",
        "figsize = (4, 3.5)\n",
        "\n",
        "fig, axes = plt.subplots(3, len(tasks), sharex=True, sharey=True, figsize=figsize)\n",
        "\n",
        "for i, (task, feature_set) in enumerate(\n",
        "    itertools.product(tasks, ['x', 'xa', 'xa_stratified'])\n",
        "):\n",
        "\n",
        "  calibration_plot(\n",
        "      pred_eval_dict_acs[task]['labels'],\n",
        "      pred_eval_dict_acs[task][f'pred_probs_y1_{feature_set}'],\n",
        "      group=pred_eval_dict_acs[task]['group_name'],\n",
        "      plot_overall=False,\n",
        "      ax=axes[i % 3][i // 3],\n",
        "      legend=False,\n",
        "      xlabel=None,\n",
        "      ylabel=None,\n",
        "  )\n",
        "\n",
        "for i, task in enumerate(tasks):\n",
        "  axes[0][i].set_title(task, size=8)\n",
        "\n",
        "axes[0][-1].text(x=1.02, y=0.3, s='Cov.: X', rotation=-90, size=8)\n",
        "axes[1][-1].text(x=1.02, y=0.3, s='Cov.: XA', rotation=-90, size=8)\n",
        "axes[2][-1].text(x=1.02, y=0.1, s='Cov.: X_strat', rotation=-90, size=8)\n",
        "\n",
        "fig.supxlabel('Score', size=14, x=0.55, y=0.05)\n",
        "fig.supylabel('Fraction positive', size=14, x=0.03, y=0.55)\n",
        "plt.tight_layout()\n",
        "fig.set_size_inches(*figsize)\n",
        "axes[1][-1].legend(frameon=False, bbox_to_anchor=(1.25, 1.8), title='Group')\n",
        "for filetype in ['png', 'pdf']:\n",
        "  fig.savefig(\n",
        "      os.path.join(FIGURE_PATH, f'calibration_acs.{filetype}'), format=filetype, bbox_inches='tight'\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "_qnikHh9N7QA"
      },
      "cell_type": "code",
      "source": [
        "weight_types = ['None']\n",
        "metrics = ['log loss', 'AUC-ROC', 'net benefit', 'sensitivity', 'specificity']\n",
        "tasks_to_plot = ['ACSIncome', 'ACSPublicCoverage']\n",
        "\n",
        "g = sns.FacetGrid(\n",
        "    (\n",
        "        plot_df_acs.query(\n",
        "            'weight_type in @weight_types \u0026 features == \"relative_comparison\" \u0026'\n",
        "            ' metric.isin(@metrics) \u0026 task in @tasks_to_plot'\n",
        "        )\n",
        "        .sort_values(['group_name', 'task'])\n",
        "        .assign(\n",
        "            task=lambda x: x.task.values.remove_unused_categories(),\n",
        "            metric=lambda x: x.metric.values.remove_unused_categories(),\n",
        "            )\n",
        "    ),\n",
        "    col='metric',\n",
        "    margin_titles=True,\n",
        "    sharex=False\n",
        ")\n",
        "\n",
        "g.map(\n",
        "    pointplot_with_errorbars,\n",
        "    'performance',\n",
        "    'task',\n",
        "    'group_name',\n",
        "    'ci_low',\n",
        "    'ci_high',\n",
        "    vertical=False,\n",
        "    pairwise=True,\n",
        "    point_scale=0.5\n",
        ")\n",
        "\n",
        "g.set_axis_labels('', '')\n",
        "g.fig.supylabel(f'Task', fontsize=14, x=-0.1, y=0.6)\n",
        "g.fig.supxlabel(f'Difference in performance (subgroup-aware vs. unaware model)', fontsize=14, x=0.5, y=-0.02)\n",
        "\n",
        "g.set_titles(\n",
        "    row_template='', col_template='{col_name}', size=12\n",
        ")\n",
        "\n",
        "for ax in g.axes.flat:\n",
        "  ax.tick_params(axis='x', labelsize=10)\n",
        "  ax.xaxis.set_major_formatter(ticker.FuncFormatter(format_zero))\n",
        "\n",
        "# Legend\n",
        "g.add_legend(fontsize=10)\n",
        "g.legend.set_title('Group')\n",
        "sns.move_legend(g, 'center right', bbox_to_anchor=(1.07, 0.57))\n",
        "plt.setp(g._legend.get_title(), fontsize=14)\n",
        "plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "g.figure.set_size_inches(8.5, 2.5)\n",
        "for filetype in ['png', 'pdf']:\n",
        "  g.figure.savefig(\n",
        "      os.path.join(FIGURE_PATH, f'relative_performance_acs.{filetype}'), format=filetype, bbox_inches=\"tight\"\n",
        "  )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "kNyVExBg1G4p"
      },
      "cell_type": "code",
      "source": [
        "the_plot_df = (plot_df_acs.query(\n",
        "        'weight_type in @weight_types \u0026 ~features.isin(@relative_comparison_features) \u0026'\n",
        "        ' metric == @metric \u0026 task in @tasks_to_plot'\n",
        "    ).query('group != \"Population\"')\n",
        "    .sort_values(['group', 'task', 'weights'])\n",
        "    .assign(task=lambda x: x.task.values.remove_unused_categories(),\n",
        "            weights=lambda x: x.weights.replace('None', 'Subgroup')\n",
        "            )\n",
        "    )\n",
        "the_plot_df.groupby(['task', 'features', 'weights', 'group_name']).agg(lambda x: x.shape[0]).head(20)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "zPu1cGQQPLJn"
      },
      "cell_type": "code",
      "source": [
        "# Population mapping results\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  for metric in metric_dict.values():\n",
        "    weight_types = ['population', 'None']\n",
        "\n",
        "    the_plot_df = (plot_df_acs.query(\n",
        "        'weight_type in @weight_types \u0026 ~features.isin(@relative_comparison_features) \u0026'\n",
        "        ' metric == @metric \u0026 task in @tasks_to_plot'\n",
        "    ).query('group != \"Population\"')\n",
        "    .sort_values(['group', 'task', 'weights'])\n",
        "    .assign(task=lambda x: x.task.values.remove_unused_categories(),\n",
        "            weights=lambda x: x.weights.replace('None', 'Subgroup')\n",
        "            )\n",
        "    )\n",
        "\n",
        "    g = sns.FacetGrid(\n",
        "        the_plot_df,\n",
        "        row='task',\n",
        "        col='features',\n",
        "        margin_titles=True,\n",
        "        sharex='row',\n",
        "    )\n",
        "\n",
        "    g.map(\n",
        "        pointplot_with_errorbars,\n",
        "        'performance',\n",
        "        'weights',\n",
        "        'group_name',\n",
        "        'ci_low',\n",
        "        'ci_high',\n",
        "        vertical=False,\n",
        "        point_scale=0.5\n",
        "    )\n",
        "\n",
        "    g.set_axis_labels('', '')\n",
        "    g.fig.supylabel(f'Control variable', fontsize=16, x=-0.02)\n",
        "    g.fig.supxlabel(f'Weighted model performance ({metric})', fontsize=16, x=0.5, y=-0.02)\n",
        "\n",
        "    g.set_titles(\n",
        "        row_template='{row_name}', col_template='Features: {col_name}', size=10\n",
        "    )\n",
        "    g = wrap_titles(g)\n",
        "\n",
        "    for ax in g.axes.flat:\n",
        "      ax.tick_params(axis='x', labelsize=10)\n",
        "      ax.tick_params(axis='y', labelsize=10)\n",
        "      if metric == \"net benefit\":\n",
        "        num_digits=3\n",
        "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda *args: format_zero(*args, num_digits=num_digits)))\n",
        "\n",
        "    # Legend\n",
        "    g.add_legend(fontsize=12)\n",
        "    g.legend.set_title('Group')\n",
        "    sns.move_legend(g, 'center right', bbox_to_anchor=(1.03, 0.50))\n",
        "    plt.setp(g._legend.get_title(), fontsize=14)\n",
        "    plt.setp(g._legend.get_texts(), fontsize=12)\n",
        "\n",
        "    g.fig.subplots_adjust(hspace=0.2, wspace=0.1)\n",
        "    g.figure.set_size_inches(8.5, 11)\n",
        "    for filetype in ['png', 'pdf']:\n",
        "      g.figure.savefig(\n",
        "          os.path.join(FIGURE_PATH, f'adjustment_weights_absolute_{metric}_acs.{filetype}'), format=filetype, bbox_inches=\"tight\"\n",
        "      )"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "name": "results.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
