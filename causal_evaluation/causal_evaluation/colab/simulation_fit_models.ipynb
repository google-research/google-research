{
  "cells": [
    {
      "metadata": {
        "id": "w_ynTm-wZG1z"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2025 The Google Research Authors\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "```\n",
        " http://www.apache.org/licenses/LICENSE-2.0\n",
        "```\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "metadata": {
        "id": "C7d41E0Rp2Tg"
      },
      "cell_type": "markdown",
      "source": [
        "# Simluation study -- model fitting"
      ]
    },
    {
      "metadata": {
        "id": "ijf85jeulwRW"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "\n",
        "from causal_evaluation import utils\n",
        "from causal_evaluation.experiments import simulator"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "G1hMDfWStrXO"
      },
      "cell_type": "code",
      "source": [
        "# Flags\n",
        "## Paths are relative to the directory of the ipynb file\n",
        "DATA_PATH = './../../data/simulation' # @param\n",
        "FIT_MODELS = True  # @param\n",
        "WRITE_PREDS = True  # @param\n",
        "\n",
        "N_SAMPLES_TRAIN = 50000\n",
        "N_SAMPLES_EVAL = 20000\n",
        "\n",
        "model_type = 'gradient_boosting' # @param\n",
        "group_model_type = 'gradient_boosting' # @param"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dmoP7HMMNirx"
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(DATA_PATH, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "yTw3kTRfCKT-"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(173)\n",
        "random.seed(100)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "z-Yy0HoiaxvB"
      },
      "cell_type": "code",
      "source": [
        "def get_sim_dict(**kwargs):\n",
        "\n",
        "  sim_dict = {\n",
        "      'covariate_shift': simulator.Simulator(**kwargs),\n",
        "      'no_shift': simulator.Simulator(beta_a=0, **kwargs),\n",
        "      'outcome_shift': simulator.Simulator(\n",
        "          a_to_y=True, beta_a=0, mu_y_a=np.array([0.1, 0]), **kwargs\n",
        "      ),\n",
        "      'complex_causal_shift': simulator.Simulator(\n",
        "          a_to_y=True, mu_y_a=np.array([0.1, 0]), **kwargs\n",
        "      ),\n",
        "      'low_overlap_causal': simulator.Simulator(\n",
        "          a_to_y=True,\n",
        "          mu_y_a=np.array([0.1, 0]),\n",
        "          mu_x_u=np.array([-2, 2]),\n",
        "          **kwargs,\n",
        "      ),\n",
        "      'anticausal_label_shift': simulator.SimulatorAnticausal(**kwargs),\n",
        "      'anticausal_presentation_shift': simulator.SimulatorAnticausal(\n",
        "          mu_x_ay=np.array([[1, 0], [-1, 1]]),\n",
        "          mu_y_u=np.array([[0.5, 0.5], [0.5, 0.5]]),\n",
        "          **kwargs,\n",
        "      ),\n",
        "      'complex_anticausal_shift': simulator.SimulatorAnticausal(\n",
        "          mu_x_ay=np.array([[1, 0], [-1, 1]]),\n",
        "          **kwargs,\n",
        "      ),\n",
        "  }\n",
        "  return sim_dict\n",
        "\n",
        "\n",
        "sim_samples_dict = {\n",
        "    key: utils.get_squeezed_df(value.get_samples(seed=i))\n",
        "    for i, (key, value) in enumerate(\n",
        "        get_sim_dict(num_samples=N_SAMPLES_TRAIN).items()\n",
        "    )\n",
        "}\n",
        "\n",
        "sim_samples_dict_eval = {\n",
        "    key: utils.get_squeezed_df(value.get_samples(seed=2 * i))\n",
        "    for i, (key, value) in enumerate(\n",
        "        get_sim_dict(num_samples=N_SAMPLES_EVAL).items()\n",
        "    )\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "5rTiPiK4p6oa"
      },
      "cell_type": "code",
      "source": [
        "sim_samples_df = (\n",
        "    pd.concat(sim_samples_dict)\n",
        "    .reset_index(level=-1, drop=True)\n",
        "    .rename_axis('setting')\n",
        "    .reset_index()\n",
        ")\n",
        "sim_samples_df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "Ymj7lQhOYwn-"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit models for all settings"
      ]
    },
    {
      "metadata": {
        "id": "cZ6dqiEYrchy"
      },
      "cell_type": "code",
      "source": [
        "settings = [\n",
        "    'covariate_shift',\n",
        "    'outcome_shift',\n",
        "    'complex_causal_shift',\n",
        "    'low_overlap_causal',\n",
        "    'anticausal_label_shift',\n",
        "    'anticausal_presentation_shift',\n",
        "    'complex_anticausal_shift',\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4zTMgg-AY0H-"
      },
      "cell_type": "code",
      "source": [
        "# Fit models using X as features\n",
        "if FIT_MODELS:\n",
        "\n",
        "  for setting in settings:\n",
        "    print(f'Setting: {setting}', flush=True)\n",
        "    # Fit model for E[Y | X]\n",
        "    model = utils.fit_model(\n",
        "        sim_samples_dict[setting]['x'].values.reshape(-1, 1),\n",
        "        sim_samples_dict[setting]['y'].values,\n",
        "        model_type=model_type,\n",
        "        model_cross_val=True,\n",
        "    )\n",
        "\n",
        "    # Predict y in the eval data\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y_x'] = utils.array_to_series(\n",
        "        model.predict_proba(\n",
        "            sim_samples_dict_eval[setting]['x'].values.reshape(-1, 1)\n",
        "        )\n",
        "    )\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y1_x'] = sim_samples_dict_eval[\n",
        "        setting\n",
        "    ]['pred_probs_y_x'].map(lambda x: x[-1])\n",
        "\n",
        "    # Fit model stratified\n",
        "    model_dict = utils.fit_model_stratified(\n",
        "        sim_samples_dict[setting]['x'].values.reshape(-1, 1),\n",
        "        sim_samples_dict[setting]['y'].values,\n",
        "        group=sim_samples_dict[setting]['a'].values,\n",
        "        model_type=model_type,\n",
        "        model_cross_val=True,\n",
        "    )\n",
        "\n",
        "    # Predict y in the eval data\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y_xa_stratified'] = (\n",
        "        utils.array_to_series(\n",
        "            utils.predict_proba_stratified(\n",
        "                sim_samples_dict_eval[setting]['x'].values.reshape(-1, 1),\n",
        "                model_dict,\n",
        "                group=sim_samples_dict_eval[setting]['a'].values,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y1_xa_stratified'] = (\n",
        "        sim_samples_dict_eval[setting]['pred_probs_y_xa_stratified'].map(\n",
        "            lambda x: x[-1]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Fit model with X and A\n",
        "    model_xa = utils.fit_model(\n",
        "        np.concatenate(\n",
        "            (\n",
        "                sim_samples_dict[setting]['x'].values.reshape(-1, 1),\n",
        "                sim_samples_dict[setting]['a'].values.reshape(-1, 1),\n",
        "            ),\n",
        "            axis=1,\n",
        "        ),\n",
        "        sim_samples_dict[setting]['y'].values,\n",
        "        model_type=model_type,\n",
        "        model_cross_val=True,\n",
        "    )\n",
        "\n",
        "    # Predict y in the eval data\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y_xa'] = utils.array_to_series(\n",
        "        model_xa.predict_proba(\n",
        "            np.concatenate(\n",
        "                (\n",
        "                    sim_samples_dict_eval[setting]['x'].values.reshape(-1, 1),\n",
        "                    sim_samples_dict_eval[setting]['a'].values.reshape(-1, 1),\n",
        "                ),\n",
        "                axis=1,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    sim_samples_dict_eval[setting]['pred_probs_y1_xa'] = sim_samples_dict_eval[\n",
        "        setting\n",
        "    ]['pred_probs_y_xa'].map(lambda x: x[-1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "MFz5hazLe3vZ"
      },
      "cell_type": "code",
      "source": [
        "# Fit models of group membership\n",
        "\n",
        "if FIT_MODELS:\n",
        "\n",
        "  for setting in settings:\n",
        "    print(f'Setting: {setting}', flush=True)\n",
        "    # Fit model to predict P(A | X)\n",
        "    model_group_x = utils.fit_model(\n",
        "        sim_samples_dict[setting]['x'].values.reshape(-1, 1),\n",
        "        sim_samples_dict[setting]['a'].values,\n",
        "        model_type=group_model_type,\n",
        "        model_cross_val=True,\n",
        "    )\n",
        "\n",
        "    # Apply P(A | X) model to the evaluation data\n",
        "    sim_samples_dict_eval[setting]['pred_probs_group_x'] = (\n",
        "        utils.array_to_series(\n",
        "            model_group_x.predict_proba(\n",
        "                sim_samples_dict_eval[setting]['x'].values.reshape(-1, 1)\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Fit model to predict P(A | Y)\n",
        "    model_group_y = utils.fit_model(\n",
        "        sim_samples_dict[setting]['y'].values.reshape(-1, 1),\n",
        "        sim_samples_dict[setting]['a'].values,\n",
        "        model_type=group_model_type,\n",
        "        model_cross_val=True,\n",
        "    )\n",
        "    # Apply P(A | Y) model to the evaluation data\n",
        "    sim_samples_dict_eval[setting]['pred_probs_group_y'] = (\n",
        "        utils.array_to_series(\n",
        "            model_group_y.predict_proba(\n",
        "                sim_samples_dict_eval[setting]['y'].values.reshape(-1, 1)\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Estimate P(A | R_x) out-of-sample in the eval data using nested cross-validation\n",
        "    sim_samples_dict_eval[setting]['pred_probs_group_r_x'] = (\n",
        "        utils.array_to_series(\n",
        "            utils.fit_cross_val_predict(\n",
        "                scipy.special.logit(\n",
        "                    sim_samples_dict_eval[setting][\n",
        "                        'pred_probs_y1_x'\n",
        "                    ].values.reshape(-1, 1)\n",
        "                ),\n",
        "                sim_samples_dict_eval[setting]['a'].values,\n",
        "                model_type=group_model_type,\n",
        "                model_cross_val=True,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Estimate P(A | R_xa) out-of-sample in the eval data using nested cross-validation, stratitfied\n",
        "    sim_samples_dict_eval[setting]['pred_probs_group_r_xa_stratified'] = (\n",
        "        utils.array_to_series(\n",
        "            utils.fit_cross_val_predict(\n",
        "                scipy.special.logit(\n",
        "                    sim_samples_dict_eval[setting][\n",
        "                        'pred_probs_y1_xa_stratified'\n",
        "                    ].values.reshape(-1, 1)\n",
        "                ),\n",
        "                sim_samples_dict_eval[setting]['a'].values,\n",
        "                model_type=group_model_type,\n",
        "                model_cross_val=True,\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Estimate P(A | R_xa) out-of-sample in the eval data using nested cross-validation, with A included in the feature set\n",
        "    sim_samples_dict_eval[setting]['pred_probs_group_r_xa'] = (\n",
        "        utils.array_to_series(\n",
        "            utils.fit_cross_val_predict(\n",
        "                scipy.special.logit(\n",
        "                    sim_samples_dict_eval[setting][\n",
        "                        'pred_probs_y1_xa'\n",
        "                    ].values.reshape(-1, 1)\n",
        "                ),\n",
        "                sim_samples_dict_eval[setting]['a'].values,\n",
        "                model_type=group_model_type,\n",
        "                model_cross_val=True,\n",
        "            )\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "AVcd1Bwdqf19"
      },
      "cell_type": "markdown",
      "source": [
        "## Write the predictions"
      ]
    },
    {
      "metadata": {
        "id": "lK45I1joqiQg"
      },
      "cell_type": "code",
      "source": [
        "for setting in settings:\n",
        "  filename = f'sim_samples_eval_{setting}_{N_SAMPLES_TRAIN}_{N_SAMPLES_EVAL}_{model_type}_{group_model_type}.parquet'\n",
        "  if WRITE_PREDS and FIT_MODELS:\n",
        "    sim_samples_dict_eval[setting].to_parquet(\n",
        "        os.path.join(DATA_PATH, filename), index=False)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "name": "simulation_fit_models.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
