{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2-E5VnCZtV5"
      },
      "source": [
        "Licensed under the Apache License, Version 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROwUTN5TAaDD"
      },
      "outputs": [],
      "source": [
        "# signs into Google Cloud so we can fetch the Google dataset\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "project_id = 'contrails-predictions-external'\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtO44UmJBBEa"
      },
      "outputs": [],
      "source": [
        "# copies dataset to local storage\n",
        "!gsutil cp gs://contrails_measurement_paper_data/contrail_bench_dataset.csv /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoJv2f6sEF_t"
      },
      "outputs": [],
      "source": [
        "import bisect\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'font.size': 20})\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEi93tshG6yX"
      },
      "outputs": [],
      "source": [
        "def get_metric(tdf, field, cutoff, roc=False):\n",
        "  # If roc=True, return hit rate and false alarm rate\n",
        "  # if False, return precision and hit rate\n",
        "\n",
        "  actual = tdf.match\n",
        "\n",
        "  predicted = tdf[field] \u003e cutoff\n",
        "  hr = np.sum(actual \u0026 predicted) / np.sum(actual)  # hit rate=true positives / all positives\n",
        "  far = np.sum(~actual \u0026 predicted) / np.sum(~actual) # FAR=false positives / all negatives\n",
        "  if roc:\n",
        "    return hr, far\n",
        "  else:\n",
        "    npos = np.sum(actual)\n",
        "    nneg = len(actual) - npos\n",
        "    p = npos * hr / (npos * hr + far * nneg) # with a little math we can extract precision from FAR\n",
        "    return p, hr\n",
        "\n",
        "def get_curve(tdf, field, cutoffs, roc=False):\n",
        "  # Run get_metric over all cutoffs and concatenate results\n",
        "  out = np.zeros((len(cutoffs), 2))\n",
        "  for i, cutoff in enumerate(cutoffs):\n",
        "    out[i, :] = get_metric(tdf, field, cutoff, roc=roc)\n",
        "  return out\n",
        "\n",
        "def plot_df(ax, tdf, field, roc, cutoffs, **kwargs):\n",
        "  # Make a Precision/Hit Rate or ROC plot\n",
        "  # ax: matplotlib axis to plot on\n",
        "  # tdf: dataframe to plot from. Should have a column called 'match', which\n",
        "  # is a boolean that says whether this flight segment matched a contrail. And\n",
        "  # a column called field, with a number which is higher for segments more\n",
        "  # likely to make a contrail\n",
        "  # field: see above\n",
        "  # if true, make an ROC curve instead of a PR curve\n",
        "  # cutoffs: plot a point on the PR curve for each of these values\n",
        "  data_to_plot= get_curve(tdf, field, roc=roc,cutoffs=cutoffs)\n",
        "  ax.plot(data_to_plot[:, 1], data_to_plot[:, 0], '.-', **kwargs)\n",
        "\n",
        "def compute_metrics(df, key, cutoffs, label):\n",
        "  # Compute the metrics that go in the ContrailBench table\n",
        "  rcs = get_curve(df, key, cutoffs=cutoffs, roc=True)\n",
        "  # Get hit rate at 20% precision\n",
        "  i = bisect.bisect_left(rcs[::-1, 0], 0.2)\n",
        "  print(f'Metrics for {label}')\n",
        "  print('FAR@HR=20%', rcs[::-1, 1][i])\n",
        "  prs = get_curve(df, key, cutoffs=cutoffs, roc=False)\n",
        "  print('1/(PxHR)', 1/np.nanmax(prs[:, 0] * prs[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PFm6aB8He32"
      },
      "outputs": [],
      "source": [
        "goes_df = pd.read_csv('/content/contrail_bench_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEZvj9coxGhf"
      },
      "outputs": [],
      "source": [
        "goes_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zzUnAa4HvA4"
      },
      "outputs": [],
      "source": [
        "def make_outputs(df, keys, all_cutoffs):\n",
        "  # Plot Precision/Hit Rate and ROC curves for all the predicition metrics in 'keys'\n",
        "  # Also print the ContrailBench metrics\n",
        "  plt.figure(figsize=(18, 6))\n",
        "  ax1 = plt.subplot(121)\n",
        "  ax2 = plt.subplot(122)\n",
        "\n",
        "  for key, cutoffs, label in zip(keys, all_cutoffs, labels):\n",
        "    plot_df(ax1, df, key, roc=False, cutoffs=cutoffs, label=label)\n",
        "    plot_df(ax2, df, key, roc=True, cutoffs=cutoffs, label=label)\n",
        "    compute_metrics(df, key, cutoffs, label)\n",
        "  ax1.set_xlabel('Hit Rate')\n",
        "  ax1.set_ylabel('Precision')\n",
        "  ax2.set_xlim([0, 0.15])\n",
        "  ax2.set_xlabel('False Alarm Rate')\n",
        "  ax2.set_ylabel('Hit Rate')\n",
        "  plt.legend()\n",
        "  ax1.grid()\n",
        "  ax2.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yztKEAG1LEY4"
      },
      "outputs": [],
      "source": [
        "# RH: relative humidity from ECMWF\n",
        "# cocip_ef_lw: integral of long-wave radiative forcing over the first 2 hours\n",
        "# of cocip predictions. This is most predictive of whether we will observe a\n",
        "# contrail (total ef, optical depth, contrail age are not as predictive, they give worse metrics)\n",
        "# ML_score: number output by ML model\n",
        "keys = ['rh', 'cocip_ef_lw', 'ML_score']\n",
        "cutoffs = [\n",
        "    np.arange(30, 120, 1),\n",
        "    np.concatenate([np.logspace(1, 8, 15), np.logspace(8, 10, 30)]),\n",
        "    np.arange(0, 1, 0.01)\n",
        "    ]\n",
        "labels = ['Baseline', 'CoCiP', 'ML model']\n",
        "make_outputs(goes_df, keys, cutoffs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erVTeveOJMkx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1DiFD9700J1c_LOc8XaCrTupT8pH-t4fI",
          "timestamp": 1717680339864
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
