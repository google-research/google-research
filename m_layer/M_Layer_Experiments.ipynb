{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nittfHfNvRoS"
      },
      "source": [
        "##### Copyright 2020 Google LLC.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4Ptc9JShvY9v"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 The Google Research Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sRywXbP2T-bX"
      },
      "source": [
        "# M-layer experiments\n",
        "This notebook trains M-layers on the problems discussed in \"Intelligent Matrix Exponentiation\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GDkojBVAeCQs"
      },
      "source": [
        "\n",
        "\n",
        "Running this locally, the  `m_layer` python module should come with the colab and should already be present.\n",
        "\n",
        "The code of the `m_layer` python module can be downloaded from the google-research github repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HeXHggYmO1Qh"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "if os.path.isfile('m_layer.py'):\n",
        "  from m_layer import MLayer\n",
        "else:\n",
        "  !if ! type \"svn\" \u003e /dev/null; then sudo apt-get install subversion; fi\n",
        "  !svn export https://github.com/google-research/google-research/trunk/m_layer\n",
        "  from m_layer.m_layer import MLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1hkfYu6rR6Wm"
      },
      "outputs": [],
      "source": [
        "GLOBAL_SEED = 1\n",
        "import numpy as np\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "import itertools\n",
        "import functools\n",
        "import operator\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pylab\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.experimental.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k1dKgIC1WBNQ"
      },
      "source": [
        "# Generate a spiral and show extrapolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OS_m1ZmqWF0I"
      },
      "outputs": [],
      "source": [
        "SPIRAL_DIM_REP = 10\n",
        "SPIRAL_DIM_MATRIX = 10\n",
        "SPIRAL_LR = 1e-3\n",
        "SPIRAL_EPOCHS = 200\n",
        "SPIRAL_BATCH_SIZE = 16\n",
        "\n",
        "def spiral_get_model():\n",
        "  return tf.keras.models.Sequential(\n",
        "      [tf.keras.layers.Dense(SPIRAL_DIM_REP,\n",
        "                          input_shape=(2,)),\n",
        "       MLayer(dim_m=SPIRAL_DIM_MATRIX, with_bias=True, matrix_squarings_exp=3),\n",
        "       tf.keras.layers.ActivityRegularization(l2=1e-3),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(1, activation='sigmoid')]\n",
        "  )\n",
        "\n",
        "\n",
        "def spiral_generate(n_points, noise=0.5, rng=None):\n",
        "  if rng is None:\n",
        "    rng = np.random.RandomState()\n",
        "  n = np.sqrt(0.001 + rng.rand(n_points,1)) * 1000 * (2 * np.pi) / 360.0\n",
        "  x = 0.5 * (np.cos(n) * n + (2 * rng.rand(n_points, 1) - 1) * noise)\n",
        "  y = 0.5 * (np.sin(n) * n + (2 * rng.rand(n_points, 1) - 1) * noise)\n",
        "  return (np.vstack((np.hstack((x, y)), np.hstack((-x, -y)))),\n",
        "          np.hstack((np.zeros(n_points), np.ones(n_points))))\n",
        "\n",
        "\n",
        "def spiral_run(fig=None):\n",
        "  if fig is None:\n",
        "    fig = pylab.figure()\n",
        "  x_train, y_train = spiral_generate(1000)\n",
        "\n",
        "  model = spiral_get_model()\n",
        "  model.summary()\n",
        "  opt = tf.keras.optimizers.RMSprop(lr=SPIRAL_LR)\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='loss', factor=0.2, patience=5, min_lr=1e-5)\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30,\n",
        "                                 restore_best_weights=True)\n",
        "  model.fit(x_train, y_train, epochs=SPIRAL_EPOCHS,\n",
        "            batch_size=SPIRAL_BATCH_SIZE, verbose=2,\n",
        "            callbacks=[reduce_lr, early_stopping])\n",
        "  delta = 0.5 ** 3\n",
        "  xs = np.arange(-10, 10.01, delta)\n",
        "  ys = np.arange(-10, 10.01, delta)\n",
        "  num_samples = len(xs)\n",
        "  a = []\n",
        "  for x in xs:\n",
        "    for y in ys:\n",
        "      a.append([x, y])\n",
        "  t_nn_gen = model.predict(np.array(a))\n",
        "  axes = fig.gca()\n",
        "  XX, YY = np.meshgrid(xs, ys)\n",
        "  axes.contourf(XX, YY, np.arcsinh(t_nn_gen.reshape(XX.shape)),\n",
        "             levels=[0.5, 1.0],\n",
        "             colors=[(0.89, 0.51, 0.41, 0.2), (0.41, 0.67, 0.81, 0.2)])\n",
        "  axes.contour(XX, YY, np.arcsinh(t_nn_gen.reshape(XX.shape)),\n",
        "             levels=[0.5])\n",
        "  axes.grid()\n",
        "  axes.plot(x_train[y_train==0, 1], x_train[y_train==0, 0], '.', \n",
        "            label='Class 1')\n",
        "  axes.plot(x_train[y_train==1, 1], x_train[y_train==1, 0], '.', \n",
        "            label='Class 2')\n",
        "  fig.show()\n",
        "\n",
        "spiral_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3A_iJ6_Abg74"
      },
      "source": [
        "# Train an M-layer on multivariate polynomials such as the determinant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I90YlGBDbojG"
      },
      "outputs": [],
      "source": [
        "POLY_BATCH_SIZE = 32\n",
        "POLY_DIM_MATRIX = 8\n",
        "POLY_DIM_INPUT_MATRIX = 3\n",
        "POLY_EPOCHS = 150\n",
        "POLY_SEED = 123\n",
        "POLY_LOW = -1\n",
        "POLY_HIGH = 1\n",
        "POLY_NUM_SAMPLES = 8192\n",
        "POLY_LR = 1e-3\n",
        "POLY_DECAY = 1e-6\n",
        "\n",
        "def poly_get_model():\n",
        "  return tf.keras.models.Sequential(\n",
        "      [tf.keras.layers.Flatten(input_shape=(POLY_DIM_INPUT_MATRIX,\n",
        "                                         POLY_DIM_INPUT_MATRIX)),\n",
        "       MLayer(dim_m=POLY_DIM_MATRIX, matrix_init='normal'),\n",
        "       tf.keras.layers.ActivityRegularization(l2=1e-4),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(1)]\n",
        "  )\n",
        "\n",
        "\n",
        "def poly_fun(x, permanent=False):\n",
        "  if permanent:\n",
        "    return sum(\n",
        "        functools.reduce(\n",
        "            operator.mul,\n",
        "            (x[i, pi] for i, pi in enumerate(perm)),\n",
        "            1)\n",
        "        for perm in itertools.permutations(range(x.shape[0])))\n",
        "  return np.linalg.det(x)\n",
        "\n",
        "\n",
        "def poly_run(permanent=False):\n",
        "  rng = np.random.RandomState(seed=POLY_SEED)\n",
        "  num_train = POLY_NUM_SAMPLES * 5 // 4\n",
        "  x_train = rng.uniform(size=(num_train, POLY_DIM_INPUT_MATRIX,\n",
        "                              POLY_DIM_INPUT_MATRIX), low=POLY_LOW,\n",
        "                         high=POLY_HIGH)\n",
        "  x_test = rng.uniform(size=(100000, POLY_DIM_INPUT_MATRIX,\n",
        "                             POLY_DIM_INPUT_MATRIX), low=POLY_LOW,\n",
        "                       high=POLY_HIGH)\n",
        "  y_train = np.array([poly_fun(x, permanent=permanent) for x in x_train])\n",
        "  y_test = np.array([poly_fun(x, permanent=permanent) for x in x_test])\n",
        "  model = poly_get_model()\n",
        "  model.summary()\n",
        "  opt = tf.keras.optimizers.RMSprop(lr=POLY_LR, decay=POLY_DECAY)\n",
        "\n",
        "  model.compile(loss='mse', optimizer=opt)\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                                    patience=30,\n",
        "                                                    restore_best_weights=True)\n",
        "  model.fit(x_train, y_train, batch_size=POLY_BATCH_SIZE,\n",
        "            epochs=POLY_EPOCHS,\n",
        "            validation_split=0.2,\n",
        "            shuffle=True,\n",
        "            verbose=2,\n",
        "            callbacks=[reduce_lr, early_stopping])\n",
        "  score_train = model.evaluate(x=x_train, y=y_train)\n",
        "  score_test = model.evaluate(x=x_test, y=y_test)\n",
        "\n",
        "  print('Train, range %s - %s: %s' % (POLY_LOW, POLY_HIGH, score_train))\n",
        "  print('Test, range %s - %s: %s' % (POLY_LOW, POLY_HIGH, score_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N3tpvQ5Jb4wN"
      },
      "source": [
        "Permanents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uhfD0LE4b8CG"
      },
      "outputs": [],
      "source": [
        "poly_run(permanent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aKxPzc9pb-OJ"
      },
      "source": [
        "Determinants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gYSMrS3xcAO9"
      },
      "outputs": [],
      "source": [
        "poly_run(permanent=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6ePoKdpWxiC"
      },
      "source": [
        "# Train an M-layer on CIFAR-10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "eZMU20rKW5IY"
      },
      "outputs": [],
      "source": [
        "CIFAR_DIM_REP = 35\n",
        "CIFAR_DIM_MAT = 30\n",
        "CIFAR_LR = 1e-3\n",
        "CIFAR_DECAY = 1e-6\n",
        "CIFAR_MOMENTUM = 0.9\n",
        "CIFAR_BATCH_SIZE = 32\n",
        "CIFAR_EPOCHS = 150\n",
        "CIFAR_NAME = 'cifar10'\n",
        "CIFAR_NUM_CLASSES = 10\n",
        "\n",
        "def cifar_load_dataset():\n",
        "  train = tfds.load(CIFAR_NAME, split='train', with_info=False, batch_size=-1)\n",
        "  test = tfds.load(CIFAR_NAME, split='test', with_info=False, batch_size=-1)\n",
        "  train_np = tfds.as_numpy(train)\n",
        "  test_np = tfds.as_numpy(test)\n",
        "\n",
        "  x_train, y_train = train_np['image'], train_np['label']\n",
        "  x_test, y_test = test_np['image'], test_np['label']\n",
        "  print('x_train shape:', x_train.shape)\n",
        "  print(x_train.shape[0], 'train samples')\n",
        "  print(x_test.shape[0], 'test samples')\n",
        "\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, CIFAR_NUM_CLASSES)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, CIFAR_NUM_CLASSES)\n",
        "  x_train_range01 = x_train.astype('float32') / 255\n",
        "  x_test_range01 = x_test.astype('float32') / 255\n",
        "\n",
        "  return (x_train_range01, y_train), (x_test_range01, y_test)\n",
        "\n",
        "def cifar_get_model():\n",
        "  return tf.keras.models.Sequential(\n",
        "      [\n",
        "       tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
        "       tf.keras.layers.Dense(CIFAR_DIM_REP),\n",
        "       MLayer(dim_m=CIFAR_DIM_MAT, with_bias=True),\n",
        "       tf.keras.layers.ActivityRegularization(1e-4),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(CIFAR_NUM_CLASSES, activation='softmax')\n",
        "       ])\n",
        "\n",
        "def cifar_run():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar_load_dataset()\n",
        "  model = cifar_get_model()\n",
        "  model.summary()\n",
        "  opt = tf.keras.optimizers.SGD(lr=CIFAR_LR, momentum=CIFAR_MOMENTUM,\n",
        "                                   decay=CIFAR_DECAY)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_acc', factor=0.2, patience=5, min_lr=1e-5)\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', \n",
        "                                                    patience=15,\n",
        "                                                    restore_best_weights=True)\n",
        "\n",
        "  history = model.fit(\n",
        "      x_train,\n",
        "      y_train,\n",
        "      batch_size=CIFAR_BATCH_SIZE,\n",
        "      epochs=CIFAR_EPOCHS,\n",
        "      validation_split=0.1,\n",
        "      shuffle=True,\n",
        "      verbose=2,\n",
        "      callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('Test loss:', scores[0])\n",
        "  print('Test accuracy:', scores[1])\n",
        "\n",
        "cifar_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5RyUMrZtcPxk"
      },
      "source": [
        "# Train an M-layer on periodic functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bOSM0W14cUzF"
      },
      "outputs": [],
      "source": [
        "PERIODIC_BATCH_SIZE = 128\n",
        "PERIODIC_DIM_MATRIX = 6\n",
        "PERIODIC_EPOCHS = 300\n",
        "PERIODIC_SEED = 123\n",
        "PERIODIC_LR = 5e-3\n",
        "PERIODIC_DECAY = 5e-6\n",
        "\n",
        "def periodic_matrix_init(shape, rng=None, **kwargs):\n",
        "  if rng is None:\n",
        "    rng = np.random.RandomState()\n",
        "  data = np.float32(rng.normal(loc=0.0, scale=0.01, size=shape))\n",
        "  for i in range(shape[1]):\n",
        "    data[:, i, i] -= 10.0\n",
        "  return data\n",
        "\n",
        "def periodic_get_model(rng=None):\n",
        "  if rng is None:\n",
        "    rng = np.random.RandomState()\n",
        "  return tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(\n",
        "          2,\n",
        "          input_shape=(2,),\n",
        "          kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.1)),\n",
        "      MLayer(PERIODIC_DIM_MATRIX, with_bias=False,\n",
        "             matrix_init=lambda shape, **kwargs: \n",
        "             periodic_matrix_init(shape, rng=rng, **kwargs)),\n",
        "      tf.keras.layers.ActivityRegularization(l2=1e-4),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "def periodic_dist2(y_true, y_pred):\n",
        "  return tf.nn.l2_loss(y_true - y_pred)\n",
        "\n",
        "def periodic_run(get_model, basename, load_objects, epochs, batch_size, lr,\n",
        "                 decay):\n",
        "  rng = np.random.RandomState(seed=PERIODIC_SEED)\n",
        "  for freq1 in range(3, 10):\n",
        "    for freq2 in range(freq1 + 1, 10):\n",
        "      phase1 = rng.uniform(high=np.pi / 3)\n",
        "      phase2 = rng.uniform(high=np.pi / 3)\n",
        "      coeff1 = rng.uniform(low=1.0, high=2.0)\n",
        "      coeff2 = rng.uniform(low=5.0, high=10.0)\n",
        "      num_samples = 2 * 10**5\n",
        "      x_train = np.stack([\n",
        "          np.ones(num_samples + 1),\n",
        "          np.linspace(start=0.0, stop=2.0, num=num_samples + 1)\n",
        "      ],\n",
        "                            axis=1)\n",
        "      x_test = np.stack([\n",
        "          np.ones(10 * num_samples + 1),\n",
        "          np.linspace(start=0.0, stop=20.0, num=10 * num_samples + 1)\n",
        "      ],\n",
        "                           axis=1)\n",
        "      y_train = (\n",
        "          coeff1 * np.cos(2 * freq1 * np.pi * x_train[:, 1] + phase1) +\n",
        "          coeff2 * np.cos(2 * freq2 * np.pi * x_train[:, 1] + phase2) +\n",
        "          rng.normal(scale=1e-4, size=num_samples + 1))\n",
        "\n",
        "      predictions_test = []\n",
        "      for rep in range(3):\n",
        "          model_to_train = get_model(rng=rng)\n",
        "\n",
        "          input1 = tf.keras.layers.Input(shape=(2,))\n",
        "          output1 = model_to_train(input1)\n",
        "          input_plus_6 = tf.keras.layers.Lambda(\n",
        "              lambda x: 2 * x + [-1, 6])(input1)\n",
        "          output2_premult = model_to_train(input_plus_6)\n",
        "          output2 = tf.keras.layers.Lambda(lambda x: tf.math.maximum(\n",
        "              tf.constant(0, dtype=tf.dtypes.float32),\n",
        "              tf.math.abs(x) - 100))(\n",
        "                  output2_premult)\n",
        "          output = tf.keras.layers.Concatenate(axis=1)([output1, output2])\n",
        "          model = tf.keras.models.Model(inputs=[input1], outputs=output)\n",
        "\n",
        "          opt = tf.keras.optimizers.RMSprop(lr=lr, decay=decay)\n",
        "\n",
        "          model.compile(\n",
        "              loss='mean_squared_error', optimizer=opt,\n",
        "               metrics=[periodic_dist2])\n",
        "\n",
        "          model.fit(\n",
        "              x_train,\n",
        "              np.pad([y_train], [(0, 1), (0, 0)], mode='constant').T,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              shuffle=True,\n",
        "              verbose=2)\n",
        "\n",
        "          predictions_test.append(model.predict(x_test)[:, 0])\n",
        "          print('Run %d done' % rep)\n",
        "      fig = plt.figure()\n",
        "      axes = fig.gca()\n",
        "      axes.set_title('%.2f cos (%dx+%.2f) + %.2f cos (%dx+%.2f) (%s)' %\n",
        "                (coeff1, freq1, phase1, coeff2, freq2, phase2, basename))\n",
        "\n",
        "\n",
        "      axes.set_ylim([-15, 15])\n",
        "      axes.set_xlim([0, 7])\n",
        "      y_test = (\n",
        "          coeff1 * np.cos(2 * freq1 * np.pi * x_test[:, 1] + phase1) +\n",
        "          coeff2 * np.cos(2 * freq2 * np.pi * x_test[:, 1] + phase2))\n",
        "      axes.plot(x_test[:, 1], y_test, 'g', label='Target')\n",
        "      styles = ['k:', 'k-', 'k--']\n",
        "      for pred, style in zip(predictions_test, styles):\n",
        "        plt.plot(x_test[:, 1], pred, style)\n",
        "      axes.grid()\n",
        "      axes.axvspan(0, 2, facecolor='b', alpha=0.2)\n",
        "      axes.set_xlabel('input')\n",
        "      axes.set_ylabel('output')\n",
        "      plt.show()\n",
        "      fig.show()\n",
        "\n",
        "periodic_run(periodic_get_model,\n",
        "      'M-Layer', {'MLayer': MLayer},\n",
        "      PERIODIC_EPOCHS,\n",
        "      PERIODIC_BATCH_SIZE,\n",
        "      lr=PERIODIC_LR,\n",
        "      decay=PERIODIC_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fd8gF_M_KOw3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nittfHfNvRoS"
      ],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "M-Layer Experiments",
      "provenance": [
        {
          "file_id": "1Gn-ScBfylFcW9ZskuXhlz5Rf3UR7fQVL",
          "timestamp": 1581696694023
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
