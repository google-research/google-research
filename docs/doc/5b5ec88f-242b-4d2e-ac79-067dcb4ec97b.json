{
    "summary": "The code tests the \"video_structure.datasets\" module, creates a Keras model for image classification with Conv2D and L2 loss, trains and tests it on two datasets, and checks data order determinism. The test is flaky but has low failure probability by comparing 'frame_ind' arrays in repeats[0] and repeats[1].",
    "details": [
        {
            "comment": "This code is for testing the \"video_structure.datasets\" module in the google-research/video_structure repository. It imports necessary packages, defines a class GetSequenceDatasetTest with setUp method, and sets up variables to be used in the tests. The TESTDATA_DIR provides the path to test data directories.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/datasets_test.py\":0-33",
            "content": "# coding=utf-8\n# Copyright 2023 The Google Research Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"Tests for video_structure.datasets.\"\"\"\nimport os\nfrom absl import flags\nfrom absl.testing import absltest\nimport numpy as np\nimport tensorflow.compat.v1 as tf\nfrom video_structure import datasets\nFLAGS = flags.FLAGS\nTESTDATA_DIR = 'video_structure/testdata'\nclass GetSequenceDatasetTest(tf.test.TestCase):\n  def setUp(self):\n    super(GetSequenceDatasetTest, self).setUp()\n    self.data_dir = os.path.join(FLAGS.test_srcdir, TESTDATA_DIR)"
        },
        {
            "comment": "This code defines a class with methods for getting a dataset, testing output shapes, and testing image range. The class uses the \"get_sequence_dataset\" function to retrieve data from specified files (glob pattern 'acrobot*.npz') in the specified directory. It also checks that expected keys ('image' and 'true_object_pos') are present in the dataset and validates the shape of the 'image' key. Finally, it tests if the image values fall within a certain range.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/datasets_test.py\":34-65",
            "content": "    self.file_glob = 'acrobot*.npz'\n    self.batch_size = 4\n    self.num_timesteps = 2\n    self.num_channels = 3\n  def get_dataset(self, batch_size=None, random_offset=True, seed=0):\n    return datasets.get_sequence_dataset(\n        data_dir=self.data_dir,\n        file_glob=self.file_glob,\n        batch_size=batch_size or self.batch_size,\n        num_timesteps=self.num_timesteps,\n        random_offset=random_offset,\n        seed=seed)\n  def testOutputShapes(self):\n    dataset, _ = self.get_dataset()\n    expected_keys = {'image', 'true_object_pos'}\n    self.assertEqual(\n        expected_keys,\n        set(dataset.output_shapes.keys()).intersection(expected_keys))\n    self.assertEqual(\n        dataset.output_shapes['image'],\n        [self.batch_size, self.num_timesteps, 64, 64, self.num_channels])\n    self.assertEqual(dataset.output_shapes['true_object_pos'],\n                     [self.batch_size, self.num_timesteps, 0, 2])\n  def testImageRange(self):\n    dataset, _ = self.get_dataset()\n    dataset_iterator = dataset.make_one_shot_iterator()"
        },
        {
            "comment": "The code defines a test for checking if the image range is not suspiciously small, and then builds a simple Keras model that trains with the datasets. The model has a Conv2D layer and adds an L2 loss between inputs and outputs to the model's losses. It compiles the model using Adam optimizer with a learning rate of 1e-2 and clips norm at 1. Finally, it fits the model with the dataset for 1 epoch and 10 steps per epoch.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/datasets_test.py\":66-91",
            "content": "    with self.session() as sess:\n      batch = sess.run(dataset_iterator.get_next())\n    max_val = np.max(batch['image'])\n    min_val = np.min(batch['image'])\n    self.assertLessEqual(max_val, 0.5)\n    self.assertGreaterEqual(min_val, -0.5)\n    self.assertGreater(max_val - min_val, 0.25,\n                       'Image range is suspiciously small.')\n  def testFeedingToModel(self):\n    \"\"\"Build a simple Keras model and test that it trains with the datasets.\"\"\"\n    dataset, _ = self.get_dataset()\n    inputs = tf.keras.Input(shape=(self.num_timesteps, 64, 64, 3), name='image')\n    conv_layer = tf.keras.layers.Conv2D(\n        3, 2, padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))\n    outputs = tf.keras.layers.TimeDistributed(conv_layer)(inputs)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    model.add_loss(tf.nn.l2_loss(inputs - outputs))\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-2, clipnorm=1.))\n    model.fit(dataset, steps_per_epoch=10, epochs=1)\n  def testOrderIsDeterministic(self):"
        },
        {
            "comment": "The code tests the determinism of data order when random_offset is False, and checks if data orders are different when random_offset is True. The function get_new_dataset() returns an iterable dataset, and repeats variable stores two runs of the dataset pipeline to compare their results. The np.testing.assert_array_equal() function is used for comparison.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/datasets_test.py\":92-118",
            "content": "    \"\"\"Tests that data order is deterministic if random_offset is False.\"\"\"\n    def get_new_dataset():\n      dataset = self.get_dataset(batch_size=32, random_offset=False)[0]\n      return dataset.make_one_shot_iterator()\n    with self.session() as sess:\n      repeats = [sess.run(get_new_dataset().get_next()) for _ in range(2)]\n    # Check that order is reproducible:\n    np.testing.assert_array_equal(repeats[0]['filename'],\n                                  repeats[1]['filename'])\n    np.testing.assert_array_equal(repeats[0]['frame_ind'],\n                                  repeats[1]['frame_ind'])\n  def testRandomOffset(self):\n    \"\"\"Tests that data order is random if random_offset is True.\"\"\"\n    def get_new_dataset(seed):\n      dataset = self.get_dataset(\n          batch_size=32, random_offset=True, seed=seed)[0]\n      return dataset.make_one_shot_iterator()\n    with self.session() as sess:\n      repeats = [sess.run(get_new_dataset(seed).get_next()) for seed in [0, 1]]\n    # Check that two calls to a fresh dataset pipeline return different orders"
        },
        {
            "comment": "The code is testing for assertion errors between 'frame_ind' arrays in repeats[0] and repeats[1]. The test is considered flaky but with a low probability of failure.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/datasets_test.py\":119-126",
            "content": "    # (this test is technically flaky, but at a very low probability):\n    with self.assertRaises(AssertionError):\n      np.testing.assert_array_equal(repeats[0]['frame_ind'],\n                                    repeats[1]['frame_ind'])\nif __name__ == '__main__':\n  absltest.main()"
        }
    ]
}