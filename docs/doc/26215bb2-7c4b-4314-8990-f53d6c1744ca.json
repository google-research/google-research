{
    "summary": "This code defines TensorFlow operations for a video representation model, extracting keypoints from heatmaps and generating 2-D maps. It scales the map, adds pixel indices as channels for data augmentation, and returns a tensor representing the heatmaps.",
    "details": [
        {
            "comment": "This code defines TensorFlow operations for a structured video representation model. It includes a constant EPSILON and an enum class Axis that maps axes to image indices. The function maps_to_keypoints takes heatmaps as input, normalizes them, and transforms the feature-detector heatmaps into (x, y, scale) keypoints.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":0-32",
            "content": "# coding=utf-8\n# Copyright 2023 The Google Research Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\"\"\"TensorFlow ops for the structured video representation model.\"\"\"\nimport enum\nimport tensorflow.compat.v1 as tf\nEPSILON = 1e-6  # Constant for numerical stability.\nclass Axis(enum.Enum):\n  \"\"\"Maps axes to image indices, assuming that 0th dimension is the batch.\"\"\"\n  y = 1\n  x = 2\ndef maps_to_keypoints(heatmaps):\n  \"\"\"Turns feature-detector heatmaps into (x, y, scale) keypoints.\n  This function takes a tensor of feature maps as input. Each map is normalized"
        },
        {
            "comment": "This code extracts keypoints from heatmaps by computing the mean intensity and coordinates for each feature map, representing each keypoint as an (x, y, scale) triplet in [-1, 1], [0, 1] range. The code also ensures that heatmap values are non-negative before processing.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":33-58",
            "content": "  to a probability distribution and the location of the mean of the distribution\n  (in image coordinates) is computed. This location is used as a low-dimensional\n  representation of the heatmap (i.e. a keypoint).\n  To model keypoint presence/absence, the mean intensity of each feature map is\n  also computed, so that each keypoint is represented by an (x, y, scale)\n  triplet.\n  Args:\n    heatmaps: [batch_size, H, W, num_keypoints] tensors.\n  Returns:\n    A [batch_size, num_keypoints, 3] tensor with (x, y, scale)-triplets for each\n    keypoint. Coordinate range is [-1, 1] for x and y, and [0, 1] for scale.\n  \"\"\"\n  # Check that maps are non-negative:\n  map_min = tf.reduce_min(heatmaps)\n  assert_nonneg = tf.Assert(tf.greater_equal(map_min, 0.0), [map_min])\n  with tf.control_dependencies([assert_nonneg]):\n    heatmaps = tf.identity(heatmaps)\n  x_coordinates = _maps_to_coordinates(heatmaps, Axis.x)\n  y_coordinates = _maps_to_coordinates(heatmaps, Axis.y)\n  map_scales = tf.reduce_mean(heatmaps, axis=[1, 2])\n  # Normalize map scales to [0.0, 1.0] across keypoints. This removes a"
        },
        {
            "comment": "This code defines a function that takes heatmaps and reduces them to coordinates along one axis (x or y). It ensures the scales are within a reasonable range for an RNN. The function then returns a tensor with (x, y)-coordinates.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":59-92",
            "content": "  # degeneracy between the encoder and decoder heatmap scales and ensures that\n  # the scales are in a reasonable range for the RNN:\n  map_scales /= (EPSILON + tf.reduce_max(map_scales, axis=-1, keepdims=True))\n  return tf.stack([x_coordinates, y_coordinates, map_scales], axis=-1)\ndef _maps_to_coordinates(maps, axis):\n  \"\"\"Reduces heatmaps to coordinates along one axis (x or y).\n  Args:\n    maps: [batch_size, H, W, num_keypoints] tensors.\n    axis: Axis Enum.\n  Returns:\n    A [batch_size, num_keypoints, 2] tensor with (x, y)-coordinates.\n  \"\"\"\n  width = maps.get_shape()[axis.value]\n  grid = _get_pixel_grid(axis, width)\n  shape = [1, 1, 1, 1]\n  shape[axis.value] = -1\n  grid = tf.reshape(grid, shape)\n  if axis == Axis.x:\n    marginalize_dim = 1\n  elif axis == Axis.y:\n    marginalize_dim = 2\n  # Normalize the heatmaps to a probability distribution (i.e. sum to 1):\n  weights = tf.reduce_sum(maps + EPSILON, axis=marginalize_dim, keep_dims=True)\n  weights /= tf.reduce_sum(weights, axis=axis.value, keep_dims=True)\n  # Compute the center of mass of the marginalized maps to obtain scalar"
        },
        {
            "comment": "This code transforms (x, y, scale)-tuples into pixel maps with a Gaussian blob at (x, y). It splits the input keypoints tensor into coordinates and map_scales, and then creates a grid of pixel coordinates for each keypoint. The x and y coordinates are expanded to broadcast later. The function returns a [batch_size, heatmap_width, heatmap_width, num_keypoints] tensor representing the heatmaps.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":93-122",
            "content": "  # coordinates:\n  coordinates = tf.reduce_sum(weights * grid, axis=axis.value, keep_dims=True)\n  return tf.squeeze(coordinates, axis=[1, 2])\ndef keypoints_to_maps(keypoints, sigma=1.0, heatmap_width=16):\n  \"\"\"Turns (x, y, scale)-tuples into pixel maps with a Gaussian blob at (x, y).\n  Args:\n    keypoints: [batch_size, num_keypoints, 3] tensor of keypoints where the last\n      dimension contains (x, y, scale) triplets.\n    sigma: Std. dev. of the Gaussian blob, in units of heatmap pixels.\n    heatmap_width: Width of output heatmaps in pixels.\n  Returns:\n    A [batch_size, heatmap_width, heatmap_width, num_keypoints] tensor.\n  \"\"\"\n  coordinates, map_scales = tf.split(keypoints, [2, 1], axis=-1)\n  def get_grid(axis):\n    grid = _get_pixel_grid(axis, heatmap_width)\n    shape = [1, 1, 1, 1]\n    shape[axis.value] = -1\n    return tf.reshape(grid, shape)\n  # Expand to [batch_size, 1, 1, num_keypoints] for broadcasting later:\n  x_coordinates = coordinates[:, tf.newaxis, tf.newaxis, :, 0]\n  y_coordinates = coordinates[:, tf.newaxis, tf.newaxis, :, 1]"
        },
        {
            "comment": "This code creates two 1-D Gaussian vectors representing keypoint marginals and multiplies them to form a 2-D map. It then scales this map by a factor defined in map_scales and returns it. The function also adds pixel indices (x and y coordinates) as channels to an image for data augmentation, allowing convolutional networks to learn non-translation-equivariant outputs.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":124-147",
            "content": "  # Create two 1-D Gaussian vectors (marginals) and multiply to get a 2-d map:\n  sigma = tf.cast(sigma, tf.float32)\n  keypoint_width = 2.0 * (sigma / heatmap_width) ** 2.0\n  x_vec = tf.exp(-tf.square(get_grid(Axis.x) - x_coordinates)/keypoint_width)\n  y_vec = tf.exp(-tf.square(get_grid(Axis.y) - y_coordinates)/keypoint_width)\n  maps = tf.multiply(x_vec, y_vec)\n  return maps * map_scales[:, tf.newaxis, tf.newaxis, :, 0]\ndef _get_pixel_grid(axis, width):\n  \"\"\"Returns an array of length `width` containing pixel coordinates.\"\"\"\n  if axis == Axis.x:\n    return tf.linspace(-1.0, 1.0, width)  # Left is negative, right is positive.\n  elif axis == Axis.y:\n    return tf.linspace(1.0, -1.0, width)  # Top is positive, bottom is negative.\ndef add_coord_channels(image_tensor):\n  \"\"\"Adds channels containing pixel indices (x and y coordinates) to an image.\n  Note: This has nothing to do with keypoint coordinates. It is just a data\n  augmentation to allow convolutional networks to learn non-translation-\n  equivariant outputs. This is similar to the \"CoordConv\" layers:"
        },
        {
            "comment": "This code takes an image tensor and adds two new channels, one for x coordinates and the other for y coordinates. It does this by creating grids of x and y values, then tiling them according to batch size and image dimensions. Finally, it concatenates these new channels with the original image tensor along the last axis.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_structure/ops.py\":148-169",
            "content": "  https://arxiv.org/abs/1603.09382.\n  Args:\n    image_tensor: [batch_size, H, W, C] tensor.\n  Returns:\n    [batch_size, H, W, C + 2] tensor with x and y coordinate channels.\n  \"\"\"\n  batch_size = tf.shape(image_tensor)[0]\n  x_size = tf.shape(image_tensor)[2]\n  y_size = tf.shape(image_tensor)[1]\n  x_grid = tf.lin_space(-1.0, 1.0, x_size)\n  x_map = tf.tile(\n      x_grid[tf.newaxis, tf.newaxis, :, tf.newaxis], (batch_size, y_size, 1, 1))\n  y_grid = tf.lin_space(1.0, -1.0, y_size)\n  y_map = tf.tile(\n      y_grid[tf.newaxis, :, tf.newaxis, tf.newaxis], (batch_size, 1, x_size, 1))\n  return tf.concat([image_tensor, x_map, y_map], axis=-1)"
        }
    ]
}