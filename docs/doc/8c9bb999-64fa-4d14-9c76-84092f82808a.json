{
    "summary": "This code introduces a new dataset, YouTube-News-Timeline, for video timeline modeling in news story understanding with 12k timelines and 300k videos. The dataset structure is explained, and it's available in JSON format on Google Drive. It lists updated YouTube video URLs for news story timelines.",
    "details": [
        {
            "comment": "This code introduces the concept of video timeline modeling for news story understanding and presents a new dataset, YouTube-News-Timeline, to advance research in this field. The dataset contains over 12k timelines and 300k YouTube news videos with varying durations.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_timeline_modeling/README.md\":0-13",
            "content": "# YouTube-News-Timeline: Video Timeline Modeling For News Story Understanding\n## Introduction\nWe present a novel problem, namely **video timeline modeling**. Our objective is to create a video-associated timeline from a set of videos related to a specific topic, thereby facilitating the content and structure understanding of the story being told. This problem has significant potential in various real-world applications, such as news story summarization. To bootstrap research in this area, we curate a realistic benchmark dataset, **YouTube-News-Timeline**.\nFor more details please check our paper: https://arxiv.org/abs/2309.13446\n![](https://github.com/google-research/google-research/blob/master/video_timeline_modeling/vtm.png)\n## YouTube-News-Timeline Dataset\nYouTube-News-Timeline consists of over 12k timelines and 300k YouTube news videos. The duration of these videos ranges from 3 seconds to 12 hours, and their average duration is around 10 minutes. We randomly split the timelines into trai"
        },
        {
            "comment": "This code explains the dataset structure and provides a summary of its contents. It includes the number of timelines, nodes, and videos in training, validation, and testing subsets. The distributions of video per node, node per timeline, and video per timeline are shown in an image. The dataset is available via a Google Drive link, and each sample follows a specific JSON format.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_timeline_modeling/README.md\":13-30",
            "content": "ning, validation, and testing subsets. The number of timelines, timeline nodes, and videos on training/validation/testing split in the final dataset are summarized in the table below. \n| # Timelines | # Nodes | # Videos|\n| -------- | -------- | -------- |\n|9936/1255/1220|74886/9325/9171|242685/30369/29930|\nIn the following, we show the distributions of the number of videos per node, the number of nodes per timeline, and the number of videos per timeline in the training, validation, and testing subsets.\n![](https://github.com/google-research/google-research/blob/master/video_timeline_modeling/data_dist.png)\nThe dataset is available via [this Google Drive link](https://drive.google.com/drive/folders/1SChGxFb_Vl58Nn8jKOKTyoofxu6hz7tF?usp=sharing). Each data sample is organized in the following format.\n```json\n{\n     \"https://apnews.com/article/japan-accidents-tsunamis-earthquakes-42d4947609becd7f141e9524a8c98937\":  // The URL link of the webpage where we crawl the timeline.\n     [\n      [\n        \"OhEbGK4PnZg\","
        },
        {
            "comment": "This code represents a list of YouTube video URLs, each representing a node on the timeline for news story understanding. The nested lists show the order of videos for different nodes. The dataset is periodically refreshed to remove invalid videos, and more authors are mentioned in the citation.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_timeline_modeling/README.md\":31-68",
            "content": "        \"cl19tfn33hI\",\n        \"R0l6z0HaUAM\",\n        \"5QhCsR-t-qM\",\n        \"ev3FBIoHMX8\"\n      ],\n      [\n        \"psAuFr8Xeqs\",\n        \"BsRd7WQuBHc\",\n        \"Dp_8rLL1Y18\",\n        \"h1m7GFPAq3o\"\n      ],\n      [\n        \"f4TaKPKe1gg\",\n        \"DLlsKd-QC2o\"\n      ],\n      [\n        \"ocluW1Vhvcg\",\n        \"vusthiUFx_0\",\n        \"vGHzuZQLYtg\",\n        \"7XpLbhQxpLw\",\n        \"UsPFUzXisq4\"\n      ],\n      [\n        \"hA3fNK0rxcs\"\n      ]\n    ] // The URL links of the retrieved YouTube news videos. Each list in the nested list corresponds to one node on the timeline. These nodes are ordered in the nested list.\n}\n```\nDue to data privacy concern, we periodically refresh our dataset to remove invalid YouTube videos thus the exact size of our dataset may change slightly.\n## Citation \n```\n@inproceedings{\n  liu2023video,\n  title={Video Timeline Modeling For News Story Understanding},\n  author={Liu, Meng and Zhang, Mingda and Liu, Jialu and Dai, Hanjun and Yang, Ming-Hsuan and Ji, Shuiwang and Feng, Zheyun and Gong, Boqing},\n  boo"
        },
        {
            "comment": "The code is specifying the title and year of a conference paper related to neural information processing systems (NIPS) datasets and benchmarks track.",
            "location": "\"/media/root/Prima/works/google-research/docs/src/video_timeline_modeling/README.md\":68-74",
            "content": "ktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},\n  year={2023}\n}\n```\n## Disclaimer\nThe reference timelines used to construct the dataset are crawled from the web, and the videos are sourced from YouTube. The opinions expressed in the timelines and videos do not necessarily reflect our own, and we do not endorse or promote any specific viewpoint. The dataset is intended for research and educational purposes only, and users should exercise their own judgment when interpreting and using it."
        }
    ]
}