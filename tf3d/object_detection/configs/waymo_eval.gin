num_classes = 5


# Preprocessor
waymo_prepare_lidar_images_and_correspondences.resized_image_height = 481
waymo_prepare_lidar_images_and_correspondences.resized_image_width = 721

prepare_waymo_open_dataset.valid_object_classes = [1, 2, 3, 4]
object_detection_preprocess.input_field_mapping_fn = @prepare_waymo_open_dataset
object_detection_preprocess.images_points_correspondence_fn = @waymo_prepare_lidar_images_and_correspondences
object_detection_preprocess.points_pad_or_clip_size = None
object_detection_preprocess.voxel_grid_cell_size = (0.2, 0.2, 0.2)
object_detection_preprocess.voxels_pad_or_clip_size = None
object_detection_preprocess.point_feature_keys = ('point_offset_bins',)
object_detection_preprocess.x_min_degree_rotation = None
object_detection_preprocess.x_max_degree_rotation = None
object_detection_preprocess.y_min_degree_rotation = None
object_detection_preprocess.y_max_degree_rotation = None
object_detection_preprocess.z_min_degree_rotation = None
object_detection_preprocess.z_max_degree_rotation = None
object_detection_preprocess.min_scale_ratio = None
object_detection_preprocess.max_scale_ratio = None
object_detection_preprocess.translation_range = None
object_detection_preprocess.points_within_box_margin = 0.1
object_detection_preprocess.min_num_points_in_objects = 5


# Dataset
get_tf_data_dataset.dataset_name = 'waymo_object_per_frame'
get_tf_data_dataset.split_name = 'val'
get_tf_data_dataset.preprocess_fn = @object_detection_preprocess
get_tf_data_dataset.feature_keys = ['point_positions',
                                    'num_valid_points',
                                    'voxel_positions',
                                    'voxel_features',
                                    'voxel_xyz_indices',
                                    'points_to_voxel_mapping',
                                    'num_valid_voxels',
                                    'camera_image_name']
get_tf_data_dataset.label_keys = ['object_class_points',
                                  'object_class_voxels',
                                  'object_rotation_matrix_voxels',
                                  'object_length_voxels',
                                  'object_height_voxels',
                                  'object_width_voxels',
                                  'object_center_voxels',
                                  'object_instance_id_voxels',
                                  'objects_length',
                                  'objects_height',
                                  'objects_width',
                                  'objects_rotation_matrix',
                                  'objects_center',
                                  'objects_class']
get_tf_data_dataset.shuffle_buffer_size = 4
get_tf_data_dataset.filenames_shuffle_buffer_size = 4
get_tf_data_dataset.read_block_length = 1
get_tf_data_dataset.num_readers = 16


# 3D Network
SparseConvHourGlass.num_stacked_networks = 2
SparseConvHourGlass.conv_filter_size = 3
SparseConvHourGlass.encoder_dimensions = ((64, 64), (64, 128), (128, 192), (192, 256), (256, 320))
SparseConvHourGlass.bottleneck_dimensions = (320, 320)
SparseConvHourGlass.decoder_dimensions = ((320,), (256,), (192,), (128,), (64,))
SparseConvHourGlass.use_batch_norm = True


# Model
ObjectDetectionModel.num_classes = %num_classes
ObjectDetectionModel.predict_rotation_x = False
ObjectDetectionModel.predict_rotation_y = False
ObjectDetectionModel.predict_rotation_z = True
ObjectDetectionModel.nms_score_threshold = 0.1
ObjectDetectionModel.nms_iou_threshold = 0.3
ObjectDetectionModel.nms_max_num_predicted_boxes = 200
ObjectDetectionModel.use_furthest_voxel_sampling = False


# Evaluation
evaluation.input_fn = @get_tf_data_dataset
evaluation.model_class = @ObjectDetectionModel
evaluation.num_quantitative_examples = 1000
evaluation.num_qualitative_examples = 10

m1/ObjectDetectionMetric.iou_threshold = 0.25
m1/ObjectDetectionMetric.num_classes = %num_classes
m1/ObjectDetectionMetric.label_map_path = %label_map_path

m2/ObjectDetectionMetric.iou_threshold = 0.5
m2/ObjectDetectionMetric.num_classes = %num_classes
m2/ObjectDetectionMetric.label_map_path = %label_map_path

m3/ObjectDetectionMetric.iou_threshold = 0.7
m3/ObjectDetectionMetric.num_classes = %num_classes
m3/ObjectDetectionMetric.label_map_path = %label_map_path

CustomTensorBoard.metric_classes = [
    @m1/ObjectDetectionMetric,
    @m2/ObjectDetectionMetric,
    @m3/ObjectDetectionMetric
]
