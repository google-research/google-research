{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "959e0d4f",
      "metadata": {
        "id": "959e0d4f"
      },
      "source": [
        "Copyright 2022 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bd8ad7",
      "metadata": {
        "id": "b7bd8ad7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from scipy import special"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0591c609",
      "metadata": {
        "id": "0591c609"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3265fb61",
      "metadata": {
        "id": "3265fb61"
      },
      "outputs": [],
      "source": [
        "def KL(mu, nu, dist='Gaussian'):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu, nu:\n",
        "        array of size (K, n_instances), where K is the number of arms,\n",
        "        and n_instances is the number of problem instances.\n",
        "        values denote the expected reward of arms.\n",
        "    \"\"\"\n",
        "    if dist == 'Gaussian':\n",
        "        return (mu-nu)**2/2\n",
        "    elif dist == 'Bernoulli':\n",
        "        return mu*np.log(mu/nu) + (1-mu)*np.log((1-mu)/(1-nu))\n",
        "    elif dist == 'Exponential':\n",
        "        return np.log(mu/nu) + nu/mu - 1\n",
        "\n",
        "def KLRatio(mu, w, dist='Gaussian'):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu:\n",
        "        array of size (K, n_instances), where K is the number of arms,\n",
        "        and n_instances is the number of problem instances.\n",
        "        values denote the expected reward of arms.\n",
        "    w:\n",
        "        array of size (K, n_instances).\n",
        "        values denote the weight of each arm\n",
        "\n",
        "    Output\n",
        "    -------\n",
        "    KL(mu1, (w1*mu1+wa*mua)/(w1+wa))/KL(mua, (w1*mu1+wa*mua)/(w1+wa)) for every arm a\n",
        "    \"\"\"\n",
        "    K = mu.shape[0]\n",
        "    n = mu.shape[1]\n",
        "    best_arm_idx = np.argmax(mu, axis=0)\n",
        "    w_best = w[best_arm_idx, np.arange(n)]\n",
        "    mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "    mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "    return KL(mu_best[None,:], mu_avg, dist)/KL(mu, mu_avg, dist)\n",
        "\n",
        "def KLObjective(mu, w, dist='Gaussian'):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu:\n",
        "        array of size (K, n_instances), where K is the number of arms,\n",
        "        and n_instances is the number of problem instances.\n",
        "        values denote the expected reward of arms.\n",
        "    w:\n",
        "        array of size (K, n_instances).\n",
        "        values denote the weight of each arm\n",
        "\n",
        "    Output\n",
        "    -------\n",
        "    w1*KL(mu1, (w1*mu1+wa*mua)/(w1+wa)) + wa* KL(mua, (w1*mu1+wa*mua)/(w1+wa)) for every arm a\n",
        "    \"\"\"\n",
        "\n",
        "    K = mu.shape[0]\n",
        "    n = mu.shape[1]\n",
        "    best_arm_idx = np.argmax(mu, axis=0)\n",
        "    w_best = w[best_arm_idx, np.arange(n)]\n",
        "    mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "    mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "\n",
        "    return w_best[None,:]*KL(mu_best[None,:], mu_avg, dist) + w*KL(mu, mu_avg, dist)\n",
        "\n",
        "def KLObjectiveGrad(mu, w, dist='Gaussian'):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu:\n",
        "        array of size (K, n_instances), where K is the number of arms,\n",
        "        and n_instances is the number of problem instances.\n",
        "        values denote the expected reward of arms.\n",
        "    w:\n",
        "        array of size (K, n_instances).\n",
        "        values denote the weight of each arm\n",
        "\n",
        "    Output\n",
        "    -------\n",
        "    [KL(mu1, (w1*mu1+wa*mua)/(w1+wa)), KL(mua, (w1*mu1+wa*mua)/(w1+wa))]\n",
        "    where a is the arm with the smallest index\n",
        "    \"\"\"\n",
        "\n",
        "    K = mu.shape[0]\n",
        "    n = mu.shape[1]\n",
        "    best_arm_idx = np.argmax(mu, axis=0)\n",
        "    w_best = w[best_arm_idx, np.arange(n)]\n",
        "    mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "    mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "\n",
        "    t1 = KL(mu_best[None,:], mu_avg, dist)\n",
        "    t2 = KL(mu, mu_avg, dist)\n",
        "    kl_obj = w_best[None,:]*t1 + w*t2\n",
        "    kl_obj[best_arm_idx, np.arange(n)] = np.Inf\n",
        "    competitors = np.argmin(kl_obj, axis=0)\n",
        "    result = np.zeros_like(w)\n",
        "    result[best_arm_idx, np.arange(n)] = t1[competitors, np.arange(n)]\n",
        "    result[competitors, np.arange(n)] = t2[competitors, np.arange(n)]\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73bc805",
      "metadata": {
        "id": "e73bc805"
      },
      "source": [
        "# max-min solvers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b14b611f",
      "metadata": {
        "id": "b14b611f"
      },
      "outputs": [],
      "source": [
        "class OfflineOnlineMaxMinSolver(object):\n",
        "    def __init__(self, mu, delta, n_offline, dist='Gaussian'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu:\n",
        "            array of size (K, n_instances), where K is the number of arms,\n",
        "            and n_instances is the number of problem instances.\n",
        "            values denote the expected reward of arms.\n",
        "        delta:\n",
        "            confidence parameter (scalar)\n",
        "        n_offline:\n",
        "            array of size (K, n_instances).\n",
        "            number of offline samples available for each arm\n",
        "        dist:\n",
        "            distribution of the arms (string)\n",
        "            options: [Gaussian, Bernoulli, Exponential]\n",
        "        \"\"\"\n",
        "        self.mu = mu\n",
        "\n",
        "        self.K = mu.shape[0]\n",
        "        self.n_instances = mu.shape[1]\n",
        "        self.best_arm_idx = np.argmax(self.mu, axis=0)\n",
        "\n",
        "        self.delta = delta\n",
        "        self.beta = -np.log(delta) + np.log(-np.log(delta))\n",
        "\n",
        "        self.n_offline = n_offline\n",
        "        self.dist = dist\n",
        "\n",
        "        self.n_upper_bound = 1e9\n",
        "\n",
        "    def _na_star(self, n1_online, tol=1e-6):\n",
        "        # do bisection search to find Na*(N1)\n",
        "        n_total_lb = np.zeros_like(self.mu)\n",
        "        n_total_ub = self.n_upper_bound*np.ones_like(self.mu)\n",
        "        constraint_error = np.zeros_like(self.mu) # store the error in the constraint\n",
        "\n",
        "        n1_offline = self.n_offline[self.best_arm_idx, np.arange(self.n_instances)]\n",
        "        n1_total = n1_offline + n1_online\n",
        "        n_total_lb[self.best_arm_idx, np.arange(self.n_instances)] = n1_total\n",
        "        n_total_ub[self.best_arm_idx, np.arange(self.n_instances)] = n1_total\n",
        "\n",
        "        iter = 0\n",
        "\n",
        "        while np.any(n_total_ub - n_total_lb > tol):\n",
        "          # determine the next point for bisection search\n",
        "          n_total_next = 0.5*(n_total_lb+n_total_ub)\n",
        "\n",
        "          # do bisection search based on the constraint value\n",
        "          constraint = KLObjective(self.mu, n_total_next, self.dist)\n",
        "          constraint_error = np.abs(constraint - self.beta)\n",
        "          constraint_error[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "\n",
        "          idx_neg = np.where((constraint <= self.beta))\n",
        "          idx_pos = np.where((constraint > self.beta))\n",
        "          n_total_lb[idx_neg] = n_total_next[idx_neg]\n",
        "          n_total_ub[idx_pos] = n_total_next[idx_pos]\n",
        "\n",
        "          iter+=1\n",
        "          if iter%1000 == 0:\n",
        "            print('warning. bisection search is not converging')\n",
        "            print(n_total_ub)\n",
        "            print(n_total_lb)\n",
        "\n",
        "\n",
        "        return 0.5*(n_total_lb+n_total_ub) - n_offline, constraint_error\n",
        "\n",
        "    def _n1_sub_grad(self, n1_online, tol=1e-6):\n",
        "        # computes the gradient of N1+sum_{a>1} Na*(N1) w.r.t N1\n",
        "        n_online, constraint_error = self._na_star(n1_online, tol)\n",
        "        kl_ratio = KLRatio(self.mu, self.n_offline + n_online, self.dist)\n",
        "\n",
        "        inactive_arms = np.where(n_online <= 0)\n",
        "        kl_ratio[inactive_arms] = 0\n",
        "        kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = -1\n",
        "\n",
        "        sub_grad = -np.sum(kl_ratio, axis=0)\n",
        "\n",
        "        # if there exists any constraint that isn't satisfied, increase n1\n",
        "        idx_bad = np.where(np.any(constraint_error > 1e-3, axis = 0))\n",
        "        sub_grad[idx_bad] = -1\n",
        "        return sub_grad\n",
        "\n",
        "    def compute_optimal_proportions(self, tol=1e-2, algo='bisection'):\n",
        "        if algo == 'bisection':\n",
        "          # lower and upper bounds for n1 (number of online samples of the best arm)\n",
        "          n1_lb = np.zeros(self.n_instances)\n",
        "          n1_ub = self.n_upper_bound*np.ones(self.n_instances)\n",
        "          while np.any(n1_ub - n1_lb > tol):\n",
        "            # determine the next point for bisection search\n",
        "            n1_next = 0.5*(n1_lb+n1_ub)\n",
        "\n",
        "            # do bisection search based on the sign of the gradients\n",
        "            n1_grad = self._n1_sub_grad(n1_next)\n",
        "            idx_neg_grad = np.where((n1_grad <= 0))\n",
        "            idx_pos_grad = np.where((n1_grad > 0))\n",
        "            n1_lb[idx_neg_grad] = n1_next[idx_neg_grad]\n",
        "            n1_ub[idx_pos_grad] = n1_next[idx_pos_grad]\n",
        "\n",
        "          optimal_proportions, _ = self._na_star(0.5*(n1_lb+n1_ub))\n",
        "          optimal_proportions[np.where(optimal_proportions < 0.)] = 0.\n",
        "          return optimal_proportions/np.sum(optimal_proportions, axis=0)[None,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e22bc015",
      "metadata": {
        "id": "e22bc015"
      },
      "outputs": [],
      "source": [
        "class OnlineMaxMinSolver(object):\n",
        "    def __init__(self, mu, delta, dist='Gaussian'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu:\n",
        "            array of size (K, n_instances), where K is the number of arms,\n",
        "            and n_instances is the number of problem instances.\n",
        "            values denote the expected reward of arms.\n",
        "        delta:\n",
        "            confidence parameter (scalar)\n",
        "        n_offline:\n",
        "            array of size (K, n_instances)\n",
        "        dist:\n",
        "            distribution of the arms (string)\n",
        "            options: [Gaussian, Bernoulli, Exponential]\n",
        "        \"\"\"\n",
        "        self.mu = mu\n",
        "\n",
        "        self.K = mu.shape[0]\n",
        "        self.n_instances = mu.shape[1]\n",
        "        self.best_arm_idx = np.argmax(self.mu, axis=0)\n",
        "\n",
        "        self.delta = delta\n",
        "        self.beta = -np.log(delta) + np.log(-np.log(delta))\n",
        "\n",
        "        self.dist = dist\n",
        "\n",
        "\n",
        "    def compute_optimal_proportions(self, iters=10000, algo='Top2'):\n",
        "        if algo == 'FW': # FW doesn't work theoretically\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_ratio = KLRatio(self.mu, w, self.dist)\n",
        "            kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "\n",
        "            idx = np.argmin(kl_objective, axis=0)\n",
        "            idx1 = np.where(kl_ratio[idx, np.arange(self.n_instances)] >= 1)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "\n",
        "            idx2 = np.where(kl_ratio[idx, np.arange(self.n_instances)] < 1)\n",
        "            w_next[idx[idx2[0]], idx2] += 1\n",
        "            w = w_next/(i+1)\n",
        "\n",
        "          return w\n",
        "        elif algo == 'TCB': # Transportation Cost Balancing\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            idx = np.argmin(kl_objective, axis=0)\n",
        "\n",
        "            # w counterfactual for challenger\n",
        "            w_cf_ch = i*w\n",
        "            w_cf_ch[idx, np.arange(self.n_instances)]  += 1\n",
        "            w_cf_ch /= i+1\n",
        "            kl_objective_cf_ch = KLObjective(self.mu, w_cf_ch, self.dist)\n",
        "            kl_objective_cf_ch[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            kl_objective_cf_ch = np.ndarray.min(kl_objective_cf_ch, axis=0)\n",
        "            # w counterfactual for best arm\n",
        "            w_cf_eba = i*w\n",
        "            w_cf_eba[self.best_arm_idx, np.arange(self.n_instances)] += 1\n",
        "            w_cf_eba /= i+1\n",
        "            kl_objective_cf_eba = KLObjective(self.mu, w_cf_eba, self.dist)\n",
        "            kl_objective_cf_eba[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            kl_objective_cf_eba = np.ndarray.min(kl_objective_cf_eba, axis=0)\n",
        "\n",
        "            # pull arms based on the counterfactual objective values\n",
        "            idx1 = np.where(kl_objective_cf_ch < kl_objective_cf_eba)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "\n",
        "            idx2 = np.where(kl_objective_cf_ch > kl_objective_cf_eba)\n",
        "            w_next[idx[idx2[0]], idx2] += 1\n",
        "            w = w_next/(i+1)\n",
        "\n",
        "          return w\n",
        "        elif algo == 'Top2':\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_ratio = KLRatio(self.mu, w, self.dist)\n",
        "            kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "            sum_kl_ratio = np.sum(kl_ratio, axis=0)\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "\n",
        "            # pull arm 1 if the sum_kl_ratio is greater than 1\n",
        "            idx1 = np.where(sum_kl_ratio > 1)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "            w_next[:, idx1] /= (i+1)\n",
        "\n",
        "            # otherwise pull a competitor\n",
        "            idx2 = np.where(sum_kl_ratio <= 1)\n",
        "            idx2_ = idx2[0]\n",
        "            if idx2_.size == 0:\n",
        "              w = w_next\n",
        "              continue\n",
        "            for j in range(idx2_.size):\n",
        "              arm_pull = np.argmin(kl_objective[:, idx2_[j]])\n",
        "              w_next[arm_pull, idx2_[j]] += 1\n",
        "            w_next[:, idx2] /= (i+1)\n",
        "            w = w_next\n",
        "\n",
        "          return w\n",
        "        elif algo == 'EWA': # exponential weights algorithm\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          g = np.zeros_like(self.mu)\n",
        "          for i in range(1, iters):\n",
        "            eta = i**0.5\n",
        "            g = g + KLObjectiveGrad(self.mu, w, self.dist)\n",
        "            w = sp.special.softmax(eta*g, axis=0)\n",
        "          return w\n",
        "        elif algo == 'OEWA': # optimistic exponential weights algorithm\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          g = np.zeros_like(self.mu)\n",
        "          g_curr = np.zeros_like(self.mu)\n",
        "          for i in range(1, iters):\n",
        "            eta = i**0.5\n",
        "            g_curr = KLObjectiveGrad(self.mu, w, self.dist)\n",
        "            g = g + g_curr\n",
        "            w = sp.special.softmax(eta*(g+g_curr), axis=0)\n",
        "          return w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d01a14",
      "metadata": {
        "id": "45d01a14"
      },
      "source": [
        "# Test max-min solvers\n",
        "\n",
        "## Generate Problem Instances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3c0d8c",
      "metadata": {
        "id": "8a3c0d8c"
      },
      "outputs": [],
      "source": [
        "# generate the problem instance\n",
        "K = 10 # number of arms\n",
        "delta = 0.03 # gap between arms\n",
        "mu = np.random.uniform(0.0+delta, 1.0 - delta, K) # expected reward of the arms\n",
        "mu = -np.sort(-mu)\n",
        "mu[0] = 1-delta/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f845a6f",
      "metadata": {
        "scrolled": true,
        "id": "0f845a6f"
      },
      "outputs": [],
      "source": [
        "# run bisection search\n",
        "mu_rep = np.hstack((mu[:,None], mu[:, None]))\n",
        "n_offline = np.zeros_like(mu_rep)\n",
        "bisection_solver = OfflineOnlineMaxMinSolver(mu = mu_rep, delta = 1e-6, n_offline=n_offline, dist='Gaussian')\n",
        "opt_props = bisection_solver.compute_optimal_proportions()\n",
        "print(opt_props/np.sum(opt_props, axis=0)[None,:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c29d0fa",
      "metadata": {
        "id": "1c29d0fa"
      },
      "outputs": [],
      "source": [
        "# run top2\n",
        "Top2_solver = OnlineMaxMinSolver(mu = mu_rep, delta = 1e-6, dist='Gaussian')\n",
        "Top2_opt_props = Top2_solver.compute_optimal_proportions(algo='Top2')\n",
        "print(Top2_opt_props/np.sum(Top2_opt_props, axis=0)[None,:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b466e40f",
      "metadata": {
        "id": "b466e40f"
      },
      "source": [
        "# BAI-MAB\n",
        "\n",
        "Code only works for a single bandit instance. Can't simultaneously solve multiple bandit instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3941e70f",
      "metadata": {
        "id": "3941e70f"
      },
      "outputs": [],
      "source": [
        "def beta(N, delta):\n",
        "    K = len(N);\n",
        "    t = sum(N);\n",
        "    # beta = np.log(K-1) -np.log(delta) + 6*np.log(1 + np.log(t/2)) + 8*np.log(1 + np.log((K-1)/delta));\n",
        "    beta = np.log(K-1) - np.log(delta) + np.log(1 + np.log(t));\n",
        "    return beta\n",
        "\n",
        "# Define a Stopping condition function.\n",
        "def Stop(mu, N, delta, dist):\n",
        "    \"\"\"\n",
        "    mu : bandit instance\n",
        "    N : number of samples to each arm\n",
        "    delta : bound on error probability\n",
        "    \"\"\"\n",
        "\n",
        "    K = len(N);\n",
        "    t = sum(N);\n",
        "    w = N/t;\n",
        "    glrt = t*KLObjective(mu, w, dist);\n",
        "    best_idx = np.argmax(mu);\n",
        "    # index for best arm will always be minimum (~ 0). Exclude that.\n",
        "    glrt[best_idx] = float('inf')\n",
        "    m = min(glrt);\n",
        "    threshold = beta(N,delta)\n",
        "\n",
        "    return m >= threshold\n",
        "\n",
        "def track(w, N):\n",
        "    \"\"\"\n",
        "    w : weight to track\n",
        "    N : number of samples to each arm\n",
        "    returns the arm to pull\n",
        "    \"\"\"\n",
        "\n",
        "    K = len(N);\n",
        "    t = sum(N);\n",
        "    return np.argmax(w/N);\n",
        "\n",
        "def sample(mu, dist, idx):\n",
        "    \"\"\"\n",
        "    mu : mean vector\n",
        "    dist : class of SPEF\n",
        "    idx : index to sample from\n",
        "    \"\"\"\n",
        "    # Generate a sample from distribution dist with mean mu[idx]\n",
        "    if dist == 'Gaussian':\n",
        "        return np.random.normal(mu[idx], 1);\n",
        "    elif dist == 'Bernoulli':\n",
        "        return np.random.binomial(1, mu[idx]);\n",
        "    elif dist == 'Exponential':\n",
        "        return np.random.exponential(scale=mu[idx], size=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b269f33",
      "metadata": {
        "id": "9b269f33"
      },
      "source": [
        "# Online+Offline Bisection Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce414a05",
      "metadata": {
        "id": "ce414a05"
      },
      "outputs": [],
      "source": [
        "def batched_tas(mu, K, mu_hat, n_offline, dist, delta):\n",
        "    \"\"\"\n",
        "    mu : mean vector\n",
        "    mu_hat : emp. mean from offline samples\n",
        "    K : number of arms\n",
        "    n_offline : number of offline samples from each arm\n",
        "    dist : SPEF\n",
        "    delta : error bound\n",
        "    \"\"\"\n",
        "\n",
        "    N = np.copy(n_offline); # array to store number of samples for each arm\n",
        "    w = np.zeros_like(mu); # store the average w (to be tracked)\n",
        "    wt = np.zeros_like(mu); # store the current w\n",
        "\n",
        "    for _ in range(10):\n",
        "        for at in range(0,K):\n",
        "            X = sample(mu, dist, at);\n",
        "            mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "            N[at] += 1;\n",
        "\n",
        "    w = 1/K * np.ones_like(mu);\n",
        "    wt = w;\n",
        "    t = 10*K;\n",
        "\n",
        "    while (not Stop(mu_hat, N, delta, dist)):\n",
        "        if float(np.sqrt(np.floor(t/K))).is_integer():\n",
        "            # print(t, \"~~~~~~~ Entering Forced Exploration ~~~~~~~\")\n",
        "            t_ = 0;\n",
        "            while (t_ < K):\n",
        "                # Forced Exploration\n",
        "                wt = 1/K * np.ones_like(mu);\n",
        "\n",
        "                w = (1-1/(t+t_))*w + 1/(t+t_)*wt\n",
        "                at = track(w, N);\n",
        "                X = sample(mu, dist, at);\n",
        "                mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "                N[at] += 1;\n",
        "                t_ += 1;\n",
        "            t += K;\n",
        "            # print(t, \"~~~~~~~ Completed FE, computing oracle weights ~~~~~~~\")\n",
        "\n",
        "            bisection_solver = OfflineOnlineMaxMinSolver(mu_hat, 1e-6, n_offline, dist);\n",
        "            wt = bisection_solver.compute_optimal_proportions();\n",
        "        else:\n",
        "            w = (1-1/t)*w + (1/t)*wt\n",
        "            at = track(w,N);\n",
        "            X = sample(mu, dist, at);\n",
        "            mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "            N[at] += 1;\n",
        "            t += 1;\n",
        "\n",
        "    return np.argmax(mu_hat, axis=0), t;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b30bbd0",
      "metadata": {
        "id": "8b30bbd0"
      },
      "source": [
        "# LUCB1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44d1f9b",
      "metadata": {
        "id": "d44d1f9b"
      },
      "outputs": [],
      "source": [
        "def LUCB1(mu, K, mu_hat, n_offline, dist, delta, epsilon):\n",
        "    \"\"\"\n",
        "    mu : mean vector\n",
        "    mu_hat : emp. mean from offline samples\n",
        "    K : number of arms\n",
        "    n_offline : number of offline samples from each arm\n",
        "    dist : SPEF\n",
        "    delta : error bound\n",
        "    epsilon : lcb - ucb gap to sto\n",
        "    \"\"\"\n",
        "\n",
        "    N = np.copy(n_offline);  # array to store number of samples for each arm\n",
        "    lcb = np.zeros_like(mu); # store the lcb index\n",
        "    ucb = np.zeros_like(mu); # store the ucb index\n",
        "\n",
        "    # sample each arm once\n",
        "    for _ in range(10):\n",
        "        for at in range(0,K):\n",
        "            X = sample(mu, dist, at);\n",
        "            mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "            N[at] += 1;\n",
        "\n",
        "    t = sum(N);\n",
        "\n",
        "    # Compute the lcb and ucb indexes\n",
        "    for a in range(0, K):\n",
        "        lcb[a] = mu_hat[a] - np.sqrt(2*(np.log(K*t*t/delta)+np.log(np.log(K*t*t/delta)))/N[a]); # from Kaufmann, Kalyanakrishnan 2013\n",
        "        ucb[a] = mu_hat[a] + np.sqrt(2*(np.log(K*t*t/delta)+np.log(np.log(K*t*t/delta)))/N[a]); # from Kaufmann, Kalyanakrishnan 2013\n",
        "        # lcb[a] = mu_hat[a] - np.sqrt((np.log((1+np.log(t))/delta))/N[a]); # conjectured in Garivier, Kaufmann 2016\n",
        "        # ucb[a] = mu_hat[a] + np.sqrt((np.log((1+np.log(t))/delta))/N[a]); # conjectured in Garivier, Kaufmann 2016\n",
        "\n",
        "    emp_best = np.argmax(mu_hat);\n",
        "\n",
        "    # u_t = challenger - arm with largest ucb among the sub-optimal arms\n",
        "    u_t = -1;\n",
        "    max_ucb = float('-inf')\n",
        "    for a in range(0,K):\n",
        "        if a!= emp_best:\n",
        "            if ucb[a] > max_ucb:\n",
        "                u_t = a\n",
        "                max_ucb = ucb[a]\n",
        "\n",
        "    # l_t = optimal arm\n",
        "    l_t = emp_best;\n",
        "\n",
        "    # stopping threshold\n",
        "    b_t = ucb[u_t] - lcb[l_t];\n",
        "\n",
        "    while b_t > epsilon:\n",
        "        X1 = sample(mu, dist, u_t);\n",
        "        mu_hat[u_t] = (mu_hat[u_t] * N[u_t] + X1)/(N[u_t] + 1);\n",
        "        N[u_t] += 1;\n",
        "\n",
        "        # sample leader\n",
        "        X2 = sample(mu, dist, l_t);\n",
        "        mu_hat[l_t] = (mu_hat[l_t] * N[l_t] + X2)/(N[l_t] + 1);\n",
        "        N[l_t] += 1;\n",
        "\n",
        "        t += 2;\n",
        "\n",
        "        # update ucb and lcb for each arm\n",
        "        for a in range(0, K):\n",
        "            lcb[a] = mu_hat[a] - np.sqrt((np.log(K*t*t/delta)+np.log(np.log(K*t*t/delta)))/N[a]/2);\n",
        "            ucb[a] = mu_hat[a] + np.sqrt((np.log(K*t*t/delta)+np.log(np.log(K*t*t/delta)))/N[a]/2);\n",
        "            # lcb[a] = mu_hat[a] - np.sqrt((np.log((1+np.log(t))/delta))/N[a]); # conjectured in Garivier, Kaufmann 2016\n",
        "            # ucb[a] = mu_hat[a] + np.sqrt((np.log((1+np.log(t))/delta))/N[a]); # conjectured in Garivier, Kaufmann 2016\n",
        "\n",
        "        emp_best = np.argmax(mu_hat);\n",
        "\n",
        "        # u_t = challenger - arm with largest ucb among the sub-optimal arms\n",
        "        u_t = -1;\n",
        "        max_ucb = float('-inf')\n",
        "        for a in range(0,K):\n",
        "            if a!= emp_best:\n",
        "                if ucb[a] > max_ucb:\n",
        "                    u_t = a\n",
        "                    max_ucb = ucb[a]\n",
        "\n",
        "        # l_t = optimal arm\n",
        "        l_t = emp_best;\n",
        "\n",
        "        # stopping threshold\n",
        "        b_t = ucb[u_t] - lcb[l_t];\n",
        "\n",
        "    return np.argmax(mu_hat, axis=0), t-sum(n_offline);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebde19c1",
      "metadata": {
        "id": "ebde19c1"
      },
      "source": [
        "# $\\beta$-Top2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c229717",
      "metadata": {
        "id": "9c229717"
      },
      "outputs": [],
      "source": [
        "def beta_top2(mu, K, mu_hat, n_offline, dist, delta, bta):\n",
        "    \"\"\"\n",
        "    mu : mean vector\n",
        "    mu_hat : emp. mean from offline samples\n",
        "    K : number of arms\n",
        "    n_offline : number of offline samples from each arm\n",
        "    dist : SPEF\n",
        "    delta : error bound\n",
        "    bta : probability to sample best arm\n",
        "    \"\"\"\n",
        "\n",
        "    N = np.copy(n_offline);  # array to store number of samples for each arm\n",
        "    index = np.zeros_like(mu); # store the index for each arm\n",
        "    Delta = np.zeros_like(mu); # store sub-optimality gap for each arm\n",
        "    u_t = -1; # challenger arm index\n",
        "    l_t = -1; # leader arm index\n",
        "\n",
        "    # sample each arm 10 times\n",
        "    for _ in range(10):\n",
        "        for at in range(0,K):\n",
        "            X = sample(mu, dist, at);\n",
        "            mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "            N[at] += 1;\n",
        "\n",
        "    t = sum(N);\n",
        "\n",
        "    while (not Stop(mu_hat, N, delta, dist)):\n",
        "        # compute the best arm\n",
        "        emp_best = np.argmax(mu_hat);\n",
        "\n",
        "        # compute Delta for each arm\n",
        "        # Delta = [-mu_hat[x] + mu_hat[emp_best] for x in range(0,K)]\n",
        "\n",
        "        # Compute the indexes for each arm\n",
        "        index = KLObjective(mu_hat, N, dist);\n",
        "        index[emp_best] = float('inf');\n",
        "\n",
        "        # for a in range(0, K):\n",
        "        #    if a == emp_best:\n",
        "        #        index[a] = float('inf');\n",
        "        #    else:\n",
        "        #        # index[a] = N[emp_best]*N[a]*(Delta[a]**2)/((N[emp_best]+N[a])**2);\n",
        "        #        index[a] =\n",
        "\n",
        "        # u_t = challenger - arm with smallest index\n",
        "        u_t = np.argmin(index);\n",
        "\n",
        "        # l_t = leader - arm with the maximum mean\n",
        "        l_t = emp_best;\n",
        "\n",
        "        # sample from Bernoulli with bta\n",
        "        X1 = np.random.binomial(1, bta, 1);\n",
        "\n",
        "        if X1 == 1:\n",
        "            # sample leader (emp_best)\n",
        "            X2 = sample(mu, dist, l_t);\n",
        "            mu_hat[l_t] = (mu_hat[l_t] * N[l_t] + X2)/(N[l_t] + 1);\n",
        "            N[l_t] += 1;\n",
        "        else:\n",
        "            # sample challenger\n",
        "            X2 = sample(mu, dist, u_t);\n",
        "            mu_hat[u_t] = (mu_hat[u_t] * N[u_t] + X2)/(N[u_t] + 1);\n",
        "            N[u_t] += 1;\n",
        "\n",
        "        t += 1;\n",
        "\n",
        "    return np.argmax(mu_hat, axis=0), t-sum(n_offline);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "714ddc85",
      "metadata": {
        "id": "714ddc85"
      },
      "source": [
        "# Optimal Top2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a3c6f18",
      "metadata": {
        "id": "2a3c6f18"
      },
      "outputs": [],
      "source": [
        "def opt_top2(mu, K, mu_hat, n_offline, dist, delta):\n",
        "    \"\"\"\n",
        "    mu : mean vector\n",
        "    mu_hat : emp. mean from offline samples\n",
        "    K : number of arms\n",
        "    n_offline : number of offline samples from each arm\n",
        "    dist : SPEF\n",
        "    delta : error bound\n",
        "    bta : probability to sample best arm\n",
        "    \"\"\"\n",
        "\n",
        "    N = np.copy(n_offline);  # array to store number of samples for each arm\n",
        "    index = np.zeros_like(mu); # store the index for each arm\n",
        "    Delta = np.zeros_like(mu); # store sub-optimality gap for each arm\n",
        "    B = np.zeros_like(mu); # array to store arms in set B with minimum index (to include in sum-ratio)\n",
        "    u_t = -1; # challenger arm index\n",
        "    l_t = -1; # leader arm index\n",
        "\n",
        "    # sample each arm 10 times\n",
        "    for _ in range(10):\n",
        "        for at in range(0,K):\n",
        "            X = sample(mu, dist, at);\n",
        "            mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "            N[at] += 1;\n",
        "\n",
        "    t = sum(N);\n",
        "\n",
        "    while (not Stop(mu_hat, N, delta, dist)):\n",
        "        # compute the best arm\n",
        "        emp_best = np.argmax(mu_hat);\n",
        "\n",
        "        # compute Delta for each arm\n",
        "        # Delta = [-mu_hat[x] + mu_hat[emp_best] for x in range(0,K)]\n",
        "\n",
        "        # Compute the indexes for each arm\n",
        "        index = KLObjective(mu_hat, N, dist);\n",
        "        index[emp_best] = float('inf');\n",
        "\n",
        "        # u_t = challenger - arm with smallest index\n",
        "        u_t = np.argmin(index);\n",
        "        B[u_t] = 1; # include arm u_t in B\n",
        "\n",
        "        # l_t = leader - arm with the maximum mean\n",
        "        l_t = emp_best;\n",
        "\n",
        "        s = -1;\n",
        "        # Check for sum-ratio constraint\n",
        "        for a in range(0,K):\n",
        "            if B[a] == 1 and a != l_t:\n",
        "                x1a = (N[l_t]*mu_hat[l_t] + N[a]*mu_hat[a])/(N[l_t]+N[a]);\n",
        "                s+=KL(mu_hat[l_t],x1a , dist)/KL(mu_hat[a],x1a, dist);\n",
        "\n",
        "        if s >= 0:\n",
        "            # sample leader (emp_best)\n",
        "            X2 = sample(mu, dist, l_t);\n",
        "            mu_hat[l_t] = (mu_hat[l_t] * N[l_t] + X2)/(N[l_t] + 1);\n",
        "            N[l_t] += 1;\n",
        "        else:\n",
        "            # sample challenger\n",
        "            X2 = sample(mu, dist, u_t);\n",
        "            mu_hat[u_t] = (mu_hat[u_t] * N[u_t] + X2)/(N[u_t] + 1);\n",
        "            N[u_t] += 1;\n",
        "\n",
        "        t += 1;\n",
        "\n",
        "    print(B);\n",
        "    return np.argmax(mu_hat, axis=0), t-sum(n_offline);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "202846da",
      "metadata": {
        "id": "202846da"
      },
      "source": [
        "# Offline+Online Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889254e7",
      "metadata": {
        "id": "889254e7"
      },
      "source": [
        "### generate the problem instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de78461a",
      "metadata": {
        "id": "de78461a"
      },
      "outputs": [],
      "source": [
        "# generate the problem instance\n",
        "K = 10 # number of arms\n",
        "delta = 0.03 # gap between arms\n",
        "mu = np.random.uniform(0.0+delta, 1.0 - delta, K) # expected reward of the arms\n",
        "mu = -np.sort(-mu)\n",
        "mu[0] = 1-delta/2\n",
        "mu = np.asarray([0.985, 0.83741233, 0.73414625, 0.60694074, 0.50982398, 0.48770951, 0.29959668, 0.27820935, 0.23755138, 0.0356999 ])\n",
        "print(mu)\n",
        "\n",
        "# #mu = [0.322, 0.381, 0.87, 0.88, 0.9]\n",
        "# mu = [0.35, 0.381, 0.8, 0.9]\n",
        "# #mu = [0.322, 0.322, 0.322, 0.322, 0.322, 0.381, 0.8, 0.9]\n",
        "# K = len(mu);\n",
        "# delta = 0.05 #1e-3\n",
        "\n",
        "# mu = np.array(mu)\n",
        "# print(mu)\n",
        "\n",
        "\n",
        "\n",
        "mu = mu[:,None]\n",
        "# print(mu)\n",
        "\n",
        "dist = 'Gaussian';\n",
        "n_offline = np.zeros_like(mu);\n",
        "s_hat = np.zeros_like(mu);\n",
        "mu_hat = np.zeros_like(mu);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f395a11",
      "metadata": {
        "id": "6f395a11"
      },
      "source": [
        "### Online+offline Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c04d397",
      "metadata": {
        "scrolled": true,
        "id": "2c04d397"
      },
      "outputs": [],
      "source": [
        "ns = [1, 2, 10, 500, 1000, 5000, 10000, 50000]\n",
        "\n",
        "reps = 50\n",
        "result_oo = np.zeros((len(ns), reps))\n",
        "result_oo_lucb = np.zeros((len(ns), reps))\n",
        "result_oo_beta_top2 = np.zeros((len(ns), reps))\n",
        "result_oo_optimal_top2 = np.zeros((len(ns), reps))\n",
        "\n",
        "mistake_tas = 0;\n",
        "mistake_lucb = 0;\n",
        "mistake_beta_top2 = 0;\n",
        "mistake_optimal_top2 = 0;\n",
        "\n",
        "print(mu)\n",
        "for i in range(len(ns)):\n",
        "    ni = ns[i]\n",
        "    for j in range(reps):\n",
        "        # generate offline data\n",
        "        n_offline = np.ones(mu.shape)*ni\n",
        "\n",
        "        '''\n",
        "        #if poorly-explored offline data - Setting 1\n",
        "        n_offline = np.ones(mu.shape)*10;\n",
        "        n_offline[np.argmax(mu)] = 2000+ni*2;\n",
        "        n_offline[np.argmin(mu)] = 2000+ni*2;\n",
        "\n",
        "\n",
        "        #if poorly-explored offline data - Setting 2\n",
        "        n_offline = np.ones(mu.shape)*10;\n",
        "        n_offline[np.argmax(mu)] = 5000+ni*2;\n",
        "        n_offline[np.argmin(mu)] = 5000+ni*2;\n",
        "\n",
        "        #if poorly-explored offline data - Setting 3\n",
        "        n_offline[np.argmax(mu)] = ni*100;\n",
        "        n_offline[np.argmin(mu)] = ni*100;\n",
        "        '''\n",
        "\n",
        "        #if poorly-explored offline data - Setting 4\n",
        "        n_offline = np.ones(mu.shape)*10\n",
        "        n_offline[np.argmax(mu)] = ni*K;\n",
        "\n",
        "        mu_hat = np.zeros_like(mu)\n",
        "        for k in range(mu.shape[0]):\n",
        "            mu_hat[k, 0] = np.mean(np.random.normal(mu[k,0], 1, size=int(n_offline[k]))) # This is for Gaussians.\n",
        "            #mu_hat[k, 0] = np.mean(np.random.binomial(1, mu[k,0], size=int(n_offline[k]))) # This for Bernoulli.\n",
        "            #Bernoulli doesn't work directly as dist variable needs to be set appropriately.\n",
        "\n",
        "\n",
        "        tas = batched_tas(mu, K, np.copy(mu_hat), np.copy(n_offline), dist, delta)\n",
        "        print(tas)\n",
        "        if(tas[0][0] != np.argmax(mu)):\n",
        "            mistake_tas += 1;\n",
        "        result_oo[i,j] = tas[1]\n",
        "        print(result_oo[i,j], mistake_tas)\n",
        "\n",
        "        print(i,j, '~~~~~~~~~~~~~~~~~~~~~~~ TAS ~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "\n",
        "        '''\n",
        "        lucb = LUCB1(mu, K, np.copy(mu_hat), np.copy(n_offline), dist, delta, 0)\n",
        "        print(lucb)\n",
        "        if(lucb[0][0] != np.argmax(mu)):\n",
        "            mistake_lucb += 1;\n",
        "        result_oo_lucb[i,j] = lucb[1]\n",
        "        print(result_oo_lucb[i,j], mistake_lucb)\n",
        "\n",
        "        print(i,j,'~~~~~~~~~~~~~~~~~~~~~~~ LUCB ~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "\n",
        "        '''\n",
        "\n",
        "\n",
        "        bta = 0.5;\n",
        "        top2 = beta_top2(mu, K, np.copy(mu_hat), np.copy(n_offline), dist, delta, bta)\n",
        "        print(top2)\n",
        "        if(top2[0][0] != np.argmax(mu)):\n",
        "            mistake_beta_top2 += 1;\n",
        "        result_oo_beta_top2[i,j] = top2[1]\n",
        "        print(result_oo_beta_top2[i,j], mistake_beta_top2)\n",
        "\n",
        "        print(i,j,'~~~~~~~~~~~~~~~~~~~~~~~ bta top2, bta = 0.5 ~~~~~~~~~~~~~~~~~~~~~~~')\n",
        "\n",
        "        optimal_top2 = opt_top2(mu, K, np.copy(mu_hat), np.copy(n_offline), dist, delta)\n",
        "        print(optimal_top2)\n",
        "        if(optimal_top2[0][0] != np.argmax(mu)):\n",
        "            mistake_optimal_top2 += 1;\n",
        "        result_oo_optimal_top2[i,j] = optimal_top2[1]\n",
        "        print(result_oo_optimal_top2[i,j], mistake_optimal_top2)\n",
        "\n",
        "        print(i,j,'~~~~~~~~~~~~~~~~~~~~~~~ optimal top2 ~~~~~~~~~~~~~~~~~~~~~~~')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create pandas dataframe\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set(style=\"ticks\")\n",
        "\n",
        "ns_col = K*np.multiply(np.asarray(ns)[:, None], np.ones(reps)[None,:]).reshape(-1).astype(int)\n",
        "dataset = pd.DataFrame({'offline samples': ns_col})\n",
        "dataset['Batched TaS'] = result_oo.reshape(-1)\n",
        "dataset['Proposed Top2'] = result_oo_optimal_top2.reshape(-1)\n",
        "\n",
        "ax = (\n",
        "    dataset.set_index('offline samples', append=True)  # set offline samples as part of the index\n",
        "      .stack()                      # pull A - D into rows\n",
        "      .to_frame()                   # convert to a dataframe\n",
        "      .reset_index()                # make the index into reg. columns\n",
        "      .rename(columns={'level_2': 'quantity', 0: 'stopping time'})  # rename columns\n",
        "      .drop('level_0', axis='columns')   # drop junk columns\n",
        "      .pipe((seaborn.boxplot, 'data'), x='offline samples', y='stopping time', hue='quantity')\n",
        ")\n",
        "seaborn.set(rc={'figure.figsize':(6.4, 4.8)})\n",
        "seaborn.despine(trim=True)"
      ],
      "metadata": {
        "id": "fH_qrs4779Ls"
      },
      "id": "fH_qrs4779Ls",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pandas dataframe\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set(style=\"ticks\")\n",
        "\n",
        "ns_col = K*np.multiply(np.asarray(ns)[:, None], np.ones(reps)[None,:]).reshape(-1).astype(int)\n",
        "dataset = pd.DataFrame({'offline samples': ns_col})\n",
        "dataset['Batched TaS'] = result_oo.reshape(-1)\n",
        "dataset['Proposed Top2'] = result_oo_optimal_top2.reshape(-1)\n",
        "dataset['Beta Top2'] = result_oo_beta_top2.reshape(-1)\n",
        "\n",
        "ax = (\n",
        "    dataset.set_index('offline samples', append=True)  # set offline samples as part of the index\n",
        "      .stack()                      # pull A - D into rows\n",
        "      .to_frame()                   # convert to a dataframe\n",
        "      .reset_index()                # make the index into reg. columns\n",
        "      .rename(columns={'level_2': 'quantity', 0: 'stopping time'})  # rename columns\n",
        "      .drop('level_0', axis='columns')   # drop junk columns\n",
        "      .pipe((seaborn.boxplot, 'data'), x='offline samples', y='stopping time', hue='quantity')\n",
        ")\n",
        "seaborn.set(rc={'figure.figsize':(6.4, 4.8)})\n",
        "seaborn.despine(trim=True)"
      ],
      "metadata": {
        "id": "Dx6662k3Gc4g"
      },
      "id": "Dx6662k3Gc4g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pandas dataframe\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set(style=\"ticks\")\n",
        "\n",
        "ns_col = K*np.multiply(np.asarray(ns)[:, None], np.ones(reps)[None,:]).reshape(-1).astype(int)\n",
        "dataset = pd.DataFrame({'offline samples': ns_col})\n",
        "dataset['Batched TaS'] = result_oo.reshape(-1)\n",
        "dataset['Beta Top2'] = result_oo_beta_top2.reshape(-1)\n",
        "\n",
        "ax = (\n",
        "    dataset.set_index('offline samples', append=True)  # set offline samples as part of the index\n",
        "      .stack()                      # pull A - D into rows\n",
        "      .to_frame()                   # convert to a dataframe\n",
        "      .reset_index()                # make the index into reg. columns\n",
        "      .rename(columns={'level_2': 'quantity', 0: 'stopping time'})  # rename columns\n",
        "      .drop('level_0', axis='columns')   # drop junk columns\n",
        "      .pipe((seaborn.boxplot, 'data'), x='offline samples', y='stopping time', hue='quantity')\n",
        ")\n",
        "seaborn.set(rc={'figure.figsize':(6.4, 4.8)})\n",
        "seaborn.despine(trim=True)"
      ],
      "metadata": {
        "id": "D3wA86xZHBpK"
      },
      "id": "D3wA86xZHBpK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fb69e0dd",
      "metadata": {
        "id": "fb69e0dd"
      },
      "source": [
        "### Results for Batched TaS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272efcf5",
      "metadata": {
        "id": "272efcf5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#path = r\"/content/drive/My Drive/OfflineOnline\"\n",
        "#os.chdir(path)\n",
        "\n",
        "online_samples_list = []\n",
        "for i in range(0, len(ns)):\n",
        "    online_samples_list += [result_oo[i,:]]\n",
        "fig = plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
        "\n",
        "# Creating axes instance\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating plot\n",
        "bp = ax.boxplot(online_samples_list)\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8], [K*x for x in ns[0:]])\n",
        "#plt.xticks([1, 2, 3, 4], [10*x for x in ns[0:]])\n",
        "plt.xlabel('Offline samples', fontsize=15)\n",
        "plt.ylabel('Stopping Time (Batched TaS)', fontsize=15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "#plt.yscale(\"log\")\n",
        "plt.title('Bandits with {} arms'.format(K), fontsize=20)\n",
        "\n",
        "plt.savefig(\"/content/drive/My Drive/OfflineOnline/poorly_explored_BatchedTaS_Gauss10arms.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# with open('/content/gdrive/My Drive/BatchedTaS_Gauss4arns.pdf', 'wb') as f:\n",
        "#   f.write('content')\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71b3d138",
      "metadata": {
        "id": "71b3d138"
      },
      "source": [
        "### Results for beta_top2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948580c8",
      "metadata": {
        "id": "948580c8"
      },
      "outputs": [],
      "source": [
        "result_oo_beta_top2 = result_oo_beta_top2\n",
        "bta = 0.5\n",
        "\n",
        "online_samples_list = []\n",
        "for i in range(0, len(ns)):\n",
        "    online_samples_list += [result_oo_beta_top2[i,:]]\n",
        "fig = plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
        "\n",
        "# Creating axes instance\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating y-label\n",
        "y_str = 'Stopping Time (top2 with beta = '+str(bta)+')'\n",
        "\n",
        "# Creating plot\n",
        "bp = ax.boxplot(online_samples_list)\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8], [K*x for x in ns[0:]])\n",
        "#plt.xticks([1, 2, 3, 4], [10*x for x in ns[0:]])\n",
        "plt.xlabel('Offline samples', fontsize=15)\n",
        "plt.ylabel(y_str, fontsize=15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "#plt.yscale(\"log\")\n",
        "plt.title(r'Bandits with {} arms'.format(K), fontsize=20)\n",
        "\n",
        "\n",
        "plt.savefig(\"/content/drive/My Drive/OfflineOnline/poorly_explored_2Top2_Gauss10arms.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "#plt.savefig(\"OptTop2/2Top2_Gauss10arms.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee70c39",
      "metadata": {
        "id": "7ee70c39"
      },
      "source": [
        "### Results for opt_top2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef379173",
      "metadata": {
        "id": "ef379173"
      },
      "outputs": [],
      "source": [
        "\n",
        "bta = 0.5\n",
        "\n",
        "online_samples_list = []\n",
        "for i in range(0, len(ns)):\n",
        "    online_samples_list += [result_oo_optimal_top2[i,:]]\n",
        "fig = plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
        "\n",
        "# Creating axes instance\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating y-label\n",
        "y_str = 'Stopping Time (optimal top2)'\n",
        "\n",
        "# Creating plot\n",
        "bp = ax.boxplot(online_samples_list)\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8], [K*x for x in ns[0:]])\n",
        "#plt.xticks([1, 2, 3, 4], [10*x for x in ns[0:]])\n",
        "plt.xlabel('Offline samples', fontsize=15)\n",
        "plt.ylabel(y_str, fontsize=15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "#plt.yscale(\"log\")\n",
        "plt.title(r'Bandits with {} arms'.format(K), fontsize=20)\n",
        "\n",
        "\n",
        "plt.savefig(\"/content/drive/My Drive/OfflineOnline/poorly_explored_OptTop2_Gauss10arns.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "#plt.savefig(\"OptTop2/OptTop2_Gauss10arns.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a31ddfd",
      "metadata": {
        "id": "7a31ddfd"
      },
      "source": [
        "### Results for LUCB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8db3b7",
      "metadata": {
        "id": "0f8db3b7"
      },
      "outputs": [],
      "source": [
        "online_samples_list = []\n",
        "for i in range(1, len(ns)):\n",
        "    online_samples_list += [result_oo_lucb[i,:]]\n",
        "fig = plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
        "\n",
        "# Creating axes instance\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating plot\n",
        "bp = ax.boxplot(online_samples_list)\n",
        "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8], [10*x for x in ns[0:]])\n",
        "plt.xlabel('Offline samples (well explored offline data)', fontsize=15)\n",
        "plt.ylabel('Stopping Time (LUCB)', fontsize=15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.yscale(\"log\")\n",
        "plt.title(r'Bandits with 10 arms'.format(1), fontsize=20)\n",
        "\n",
        "\n",
        "#plt.savefig(\"LUCB_Bernoulli10.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24857c26",
      "metadata": {
        "id": "24857c26"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
