{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright 2022 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ],
      "metadata": {
        "id": "w8LaKNHHyGIB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCso6AsdwbVN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "from scipy import special"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "2Iw5hkjPCp7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KL(mu, nu, dist='Gaussian'):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  mu, nu:\n",
        "    array of size (K, n_instances), where K is the number of arms,\n",
        "    and n_instances is the number of problem instances.\n",
        "    values denote the expected reward of arms.\n",
        "  \"\"\"\n",
        "  if dist == 'Gaussian':\n",
        "    return (mu-nu)**2/2\n",
        "  elif dist == 'Bernoulli':\n",
        "    return mu*np.log(mu/nu) + (1-mu)*np.log((1-mu)/(1-nu))\n",
        "  elif dist == 'Exponential':\n",
        "    return np.log(mu/nu) + nu/mu - 1\n",
        "\n",
        "def KLRatio(mu, w, dist='Gaussian'):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  mu:\n",
        "    array of size (K, n_instances), where K is the number of arms,\n",
        "    and n_instances is the number of problem instances.\n",
        "    values denote the expected reward of arms.\n",
        "  w:\n",
        "    array of size (K, n_instances).\n",
        "    values denote the weight of each arm\n",
        "\n",
        "  Output\n",
        "  -------\n",
        "  KL(mu1, (w1*mu1+wa*mua)/(w1+wa))/KL(mua, (w1*mu1+wa*mua)/(w1+wa)) for every arm a\n",
        "  \"\"\"\n",
        "  K = mu.shape[0]\n",
        "  n = mu.shape[1]\n",
        "  best_arm_idx = np.argmax(mu, axis=0)\n",
        "  w_best = w[best_arm_idx, np.arange(n)]\n",
        "  mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "  mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "\n",
        "  return KL(mu_best[None,:], mu_avg, dist)/KL(mu, mu_avg, dist)\n",
        "\n",
        "def KLObjective(mu, w, dist='Gaussian'):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  mu:\n",
        "    array of size (K, n_instances), where K is the number of arms,\n",
        "    and n_instances is the number of problem instances.\n",
        "    values denote the expected reward of arms.\n",
        "  w:\n",
        "    array of size (K, n_instances).\n",
        "    values denote the weight of each arm\n",
        "\n",
        "  Output\n",
        "  -------\n",
        "  w1*KL(mu1, (w1*mu1+wa*mua)/(w1+wa)) + wa* KL(mua, (w1*mu1+wa*mua)/(w1+wa)) for every arm a\n",
        "  \"\"\"\n",
        "  K = mu.shape[0]\n",
        "  n = mu.shape[1]\n",
        "  best_arm_idx = np.argmax(mu, axis=0)\n",
        "  w_best = w[best_arm_idx, np.arange(n)]\n",
        "  mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "  mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "\n",
        "  return w_best[None,:]*KL(mu_best[None,:], mu_avg, dist) + w*KL(mu, mu_avg, dist)\n",
        "\n",
        "def KLObjectiveGrad(mu, w, dist='Gaussian'):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  mu:\n",
        "    array of size (K, n_instances), where K is the number of arms,\n",
        "    and n_instances is the number of problem instances.\n",
        "    values denote the expected reward of arms.\n",
        "  w:\n",
        "    array of size (K, n_instances).\n",
        "    values denote the weight of each arm\n",
        "\n",
        "  Output\n",
        "  -------\n",
        "  [KL(mu1, (w1*mu1+wa*mua)/(w1+wa)), KL(mua, (w1*mu1+wa*mua)/(w1+wa))]\n",
        "  where a is the arm with the smallest index\n",
        "  \"\"\"\n",
        "  K = mu.shape[0]\n",
        "  n = mu.shape[1]\n",
        "  best_arm_idx = np.argmax(mu, axis=0)\n",
        "  w_best = w[best_arm_idx, np.arange(n)]\n",
        "  mu_best = mu[best_arm_idx, np.arange(n)]\n",
        "  mu_avg = (w*mu+(w_best*mu_best)[None,:])/(w+w_best[None,:])\n",
        "\n",
        "  t1 = KL(mu_best[None,:], mu_avg, dist)\n",
        "  t2 = KL(mu, mu_avg, dist)\n",
        "  kl_obj = w_best[None,:]*t1 + w*t2\n",
        "  kl_obj[best_arm_idx, np.arange(n)] = np.Inf\n",
        "  competitors = np.argmin(kl_obj, axis=0)\n",
        "  result = np.zeros_like(w)\n",
        "  result[best_arm_idx, np.arange(n)] = t1[competitors, np.arange(n)]\n",
        "  result[competitors, np.arange(n)] = t2[competitors, np.arange(n)]\n",
        "  return result"
      ],
      "metadata": {
        "id": "CbVuiCDuw3Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# max-min solvers"
      ],
      "metadata": {
        "id": "qcw6xGLXj0bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OfflineOnlineMaxMinSolver(object):\n",
        "    def __init__(self, mu, delta, n_offline, dist='Gaussian'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu:\n",
        "            array of size (K, n_instances), where K is the number of arms,\n",
        "            and n_instances is the number of problem instances.\n",
        "            values denote the expected reward of arms.\n",
        "        delta:\n",
        "            confidence parameter (scalar)\n",
        "        n_offline:\n",
        "            array of size (K, n_instances).\n",
        "            number of offline samples available for each arm\n",
        "        dist:\n",
        "            distribution of the arms (string)\n",
        "            options: [Gaussian, Bernoulli, Exponential]\n",
        "        \"\"\"\n",
        "        self.mu = mu\n",
        "\n",
        "        self.K = mu.shape[0]\n",
        "        self.n_instances = mu.shape[1]\n",
        "        self.best_arm_idx = np.argmax(self.mu, axis=0)\n",
        "\n",
        "        self.delta = delta\n",
        "        self.beta = -np.log(delta) + np.log(-np.log(delta))\n",
        "\n",
        "        self.n_offline = n_offline\n",
        "        self.dist = dist\n",
        "\n",
        "        self.n_upper_bound = 1e9\n",
        "\n",
        "    def _na_star(self, n1_online, tol=1e-6):\n",
        "        # do bisection search to find Na*(N1)\n",
        "        n_total_lb = np.zeros_like(self.mu)\n",
        "        n_total_ub = self.n_upper_bound*np.ones_like(self.mu)\n",
        "        constraint_error = np.zeros_like(self.mu) # store the error in the constraint\n",
        "\n",
        "        n1_offline = self.n_offline[self.best_arm_idx, np.arange(self.n_instances)]\n",
        "        n1_total = n1_offline + n1_online\n",
        "        n_total_lb[self.best_arm_idx, np.arange(self.n_instances)] = n1_total\n",
        "        n_total_ub[self.best_arm_idx, np.arange(self.n_instances)] = n1_total\n",
        "\n",
        "        iter = 0\n",
        "\n",
        "        while np.any(n_total_ub - n_total_lb > tol):\n",
        "          # determine the next point for bisection search\n",
        "          n_total_next = 0.5*(n_total_lb+n_total_ub)\n",
        "\n",
        "          # do bisection search based on the constraint value\n",
        "          constraint = KLObjective(self.mu, n_total_next, self.dist)\n",
        "          constraint_error = np.abs(constraint - self.beta)\n",
        "          constraint_error[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "\n",
        "          idx_neg = np.where((constraint <= self.beta))\n",
        "          idx_pos = np.where((constraint > self.beta))\n",
        "          n_total_lb[idx_neg] = n_total_next[idx_neg]\n",
        "          n_total_ub[idx_pos] = n_total_next[idx_pos]\n",
        "\n",
        "          iter+=1\n",
        "          if iter%1000 == 0:\n",
        "            print('warning. bisection search is not converging')\n",
        "            print(n_total_ub)\n",
        "            print(n_total_lb)\n",
        "\n",
        "\n",
        "        return 0.5*(n_total_lb+n_total_ub) - n_offline, constraint_error\n",
        "\n",
        "    def _n1_sub_grad(self, n1_online, tol=1e-6):\n",
        "        # computes the gradient of N1+sum_{a>1} Na*(N1) w.r.t N1\n",
        "        n_online, constraint_error = self._na_star(n1_online, tol)\n",
        "        kl_ratio = KLRatio(self.mu, self.n_offline + n_online, self.dist)\n",
        "\n",
        "        inactive_arms = np.where(n_online <= 0)\n",
        "        kl_ratio[inactive_arms] = 0\n",
        "        kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = -1\n",
        "\n",
        "        sub_grad = -np.sum(kl_ratio, axis=0)\n",
        "\n",
        "        # if there exists any constraint that isn't satisfied, increase n1\n",
        "        idx_bad = np.where(np.any(constraint_error > 1e-3, axis = 0))\n",
        "        sub_grad[idx_bad] = -1\n",
        "        return sub_grad\n",
        "\n",
        "    def compute_optimal_proportions(self, tol=1e-2, algo='bisection'):\n",
        "        if algo == 'bisection':\n",
        "          # lower and upper bounds for n1 (number of online samples of the best arm)\n",
        "          n1_lb = np.zeros(self.n_instances)\n",
        "          n1_ub = self.n_upper_bound*np.ones(self.n_instances)\n",
        "          while np.any(n1_ub - n1_lb > tol):\n",
        "            # determine the next point for bisection search\n",
        "            n1_next = 0.5*(n1_lb+n1_ub)\n",
        "\n",
        "            # do bisection search based on the sign of the gradients\n",
        "            n1_grad = self._n1_sub_grad(n1_next)\n",
        "            idx_neg_grad = np.where((n1_grad <= 0))\n",
        "            idx_pos_grad = np.where((n1_grad > 0))\n",
        "            n1_lb[idx_neg_grad] = n1_next[idx_neg_grad]\n",
        "            n1_ub[idx_pos_grad] = n1_next[idx_pos_grad]\n",
        "\n",
        "          optimal_proportions, _ = self._na_star(0.5*(n1_lb+n1_ub))\n",
        "          optimal_proportions[np.where(optimal_proportions < 0.)] = 0.\n",
        "          return optimal_proportions/np.sum(optimal_proportions, axis=0)[None,:]"
      ],
      "metadata": {
        "id": "IPXZcgxaw7nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OnlineMaxMinSolver(object):\n",
        "    def __init__(self, mu, delta, dist='Gaussian'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        mu:\n",
        "            array of size (K, n_instances), where K is the number of arms,\n",
        "            and n_instances is the number of problem instances.\n",
        "            values denote the expected reward of arms.\n",
        "        delta:\n",
        "            confidence parameter (scalar)\n",
        "        n_offline:\n",
        "            array of size (K, n_instances)\n",
        "        dist:\n",
        "            distribution of the arms (string)\n",
        "            options: [Gaussian, Bernoulli, Exponential]\n",
        "        \"\"\"\n",
        "        self.mu = mu\n",
        "\n",
        "        self.K = mu.shape[0]\n",
        "        self.n_instances = mu.shape[1]\n",
        "        self.best_arm_idx = np.argmax(self.mu, axis=0)\n",
        "\n",
        "        self.delta = delta\n",
        "        self.beta = -np.log(delta) + np.log(-np.log(delta))\n",
        "\n",
        "        self.dist = dist\n",
        "\n",
        "\n",
        "    def compute_optimal_proportions(self, iters=10000, algo='Top2'):\n",
        "        if algo == 'FW': # FW doesn't work theoretically\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_ratio = KLRatio(self.mu, w, self.dist)\n",
        "            kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "\n",
        "            idx = np.argmin(kl_objective, axis=0)\n",
        "            idx1 = np.where(kl_ratio[idx, np.arange(self.n_instances)] >= 1)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "\n",
        "            idx2 = np.where(kl_ratio[idx, np.arange(self.n_instances)] < 1)\n",
        "            w_next[idx[idx2[0]], idx2] += 1\n",
        "            w = w_next/(i+1)\n",
        "\n",
        "          return w\n",
        "        elif algo == 'TCB': # Transportation Cost Balancing\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            idx = np.argmin(kl_objective, axis=0)\n",
        "\n",
        "            # w counterfactual for challenger\n",
        "            w_cf_ch = i*w\n",
        "            w_cf_ch[idx, np.arange(self.n_instances)]  += 1\n",
        "            w_cf_ch /= i+1\n",
        "            kl_objective_cf_ch = KLObjective(self.mu, w_cf_ch, self.dist)\n",
        "            kl_objective_cf_ch[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            kl_objective_cf_ch = np.ndarray.min(kl_objective_cf_ch, axis=0)\n",
        "            # w counterfactual for best arm\n",
        "            w_cf_eba = i*w\n",
        "            w_cf_eba[self.best_arm_idx, np.arange(self.n_instances)] += 1\n",
        "            w_cf_eba /= i+1\n",
        "            kl_objective_cf_eba = KLObjective(self.mu, w_cf_eba, self.dist)\n",
        "            kl_objective_cf_eba[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "            kl_objective_cf_eba = np.ndarray.min(kl_objective_cf_eba, axis=0)\n",
        "\n",
        "            # pull arms based on the counterfactual objective values\n",
        "            idx1 = np.where(kl_objective_cf_ch < kl_objective_cf_eba)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "\n",
        "            idx2 = np.where(kl_objective_cf_ch > kl_objective_cf_eba)\n",
        "            w_next[idx[idx2[0]], idx2] += 1\n",
        "            w = w_next/(i+1)\n",
        "\n",
        "          return w\n",
        "        elif algo == 'Top2':\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          for i in range(1, iters):\n",
        "            kl_ratio = KLRatio(self.mu, w, self.dist)\n",
        "            kl_ratio[self.best_arm_idx, np.arange(self.n_instances)] = 0\n",
        "            sum_kl_ratio = np.sum(kl_ratio, axis=0)\n",
        "            kl_objective = KLObjective(self.mu, w, self.dist)\n",
        "            kl_objective[self.best_arm_idx, np.arange(self.n_instances)] = np.Inf\n",
        "\n",
        "            # pull arm 1 if the sum_kl_ratio is greater than 1\n",
        "            idx1 = np.where(sum_kl_ratio > 1)\n",
        "            w_next = i*w\n",
        "            w_next[self.best_arm_idx[idx1], idx1] += 1\n",
        "            w_next[:, idx1] /= (i+1)\n",
        "\n",
        "            # otherwise pull a competitor\n",
        "            idx2 = np.where(sum_kl_ratio <= 1)\n",
        "            idx2_ = idx2[0]\n",
        "            if idx2_.size == 0:\n",
        "              w = w_next\n",
        "              continue\n",
        "            for j in range(idx2_.size):\n",
        "              arm_pull = np.argmin(kl_objective[:, idx2_[j]])\n",
        "              w_next[arm_pull, idx2_[j]] += 1\n",
        "            w_next[:, idx2] /= (i+1)\n",
        "            w = w_next\n",
        "\n",
        "          return w\n",
        "        elif algo == 'EWA': # exponential weights algorithm\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          g = np.zeros_like(self.mu)\n",
        "          for i in range(1, iters):\n",
        "            eta = i**0.5\n",
        "            g = g + KLObjectiveGrad(self.mu, w, self.dist)\n",
        "            w = sp.special.softmax(eta*g, axis=0)\n",
        "          return w\n",
        "        elif algo == 'OEWA': # optimistic exponential weights algorithm\n",
        "          w = np.ones_like(self.mu)/self.K\n",
        "          g = np.zeros_like(self.mu)\n",
        "          g_curr = np.zeros_like(self.mu)\n",
        "          for i in range(1, iters):\n",
        "            eta = i**0.5\n",
        "            g_curr = KLObjectiveGrad(self.mu, w, self.dist)\n",
        "            g = g + g_curr\n",
        "            w = sp.special.softmax(eta*(g+g_curr), axis=0)\n",
        "          return w\n"
      ],
      "metadata": {
        "id": "1a5EgwTcw9qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test max-min solvers\n",
        "### Generate Problem Instances"
      ],
      "metadata": {
        "id": "HdIWc9dEw_xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the problem instance\n",
        "K = 10 # number of arms\n",
        "delta = 0.03 # gap between arms\n",
        "mu = np.random.uniform(0.0+delta, 1.0 - delta, K) # expected reward of the arms\n",
        "mu = -np.sort(-mu)\n",
        "mu[0] = 1-delta/2"
      ],
      "metadata": {
        "id": "Am4mPZCcxASn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run bisection search\n",
        "mu_rep = np.hstack((mu[:,None], mu[:, None]))\n",
        "n_offline = np.zeros_like(mu_rep)\n",
        "bisection_solver = OfflineOnlineMaxMinSolver(mu = mu_rep, delta = 1e-6, n_offline=n_offline, dist='Gaussian')\n",
        "opt_props = bisection_solver.compute_optimal_proportions()\n",
        "print(opt_props/np.sum(opt_props, axis=0)[None,:])"
      ],
      "metadata": {
        "id": "wdBRHN0jxB2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run top2\n",
        "Top2_solver = OnlineMaxMinSolver(mu = mu_rep, delta = 1e-6, dist='Gaussian')\n",
        "Top2_opt_props = Top2_solver.compute_optimal_proportions(algo='Top2')\n",
        "print(Top2_opt_props/np.sum(Top2_opt_props, axis=0)[None,:])\n"
      ],
      "metadata": {
        "id": "pARag8MCxDY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BAI-MAB\n",
        "### **Code only works for a single bandit instance. Can't simultaneously solve multiple bandit instances**"
      ],
      "metadata": {
        "id": "ItqxG6RZxLP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beta(N, delta):\n",
        "  K = len(N);\n",
        "  t = sum(N);\n",
        "  # beta = np.log(K-1) -np.log(delta) + 6*np.log(1 + np.log(t/2)) + 8*np.log(1 + np.log((K-1)/delta));\n",
        "  beta = np.log(K-1) - np.log(delta) + np.log(1 + np.log(t));\n",
        "  return beta\n",
        "\n",
        "# Define a Stopping condition function.\n",
        "def Stop(mu, N, delta, dist):\n",
        "  \"\"\"\n",
        "  mu : bandit instance\n",
        "  N : number of samples to each arm\n",
        "  delta : bound on error probability\n",
        "  \"\"\"\n",
        "\n",
        "  K = len(N);\n",
        "  t = sum(N);\n",
        "  w = N/t;\n",
        "  glrt = t*KLObjective(mu, w, dist);\n",
        "  best_idx = np.argmax(mu);\n",
        "  # index for best arm will always be minimum (~ 0). Exclude that.\n",
        "  glrt[best_idx] = float('inf')\n",
        "  m = min(glrt);\n",
        "  threshold = beta(N,delta)\n",
        "\n",
        "  return m >= threshold\n",
        "\n",
        "def track(w, N):\n",
        "  \"\"\"\n",
        "  w : weight to track\n",
        "  N : number of samples to each arm\n",
        "  returns the arm to pull\n",
        "  \"\"\"\n",
        "  K = len(N);\n",
        "  t = sum(N);\n",
        "  return np.argmax(w/N);\n",
        "\n",
        "def sample(mu, dist, idx):\n",
        "  \"\"\"\n",
        "  mu : mean vector\n",
        "  dist : class of SPEF\n",
        "  idx : index to sample from\n",
        "  \"\"\"\n",
        "  # Generate a sample from distribution dist with mean mu[idx]\n",
        "  if dist == 'Gaussian':\n",
        "    return np.random.normal(mu[idx], 1);\n",
        "  elif dist == 'Bernoulli':\n",
        "    return np.random.binomial(1, mu[idx]);\n",
        "  elif dist == 'Exponential':\n",
        "    return np.random.exponential(scale=mu[idx], size=1)"
      ],
      "metadata": {
        "id": "Pe31HTzWxM39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online+Offline Bisection Search"
      ],
      "metadata": {
        "id": "nAgz4pV4k7nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batched_tas(mu, K, mu_hat, n_offline, dist, delta):\n",
        "  \"\"\"\n",
        "  mu : mean vector\n",
        "  mu_hat : emp. mean from offline samples\n",
        "  K : number of arms\n",
        "  n_offline : number of offline samples from each arm\n",
        "  dist : SPEF\n",
        "  delta : error bound\n",
        "  \"\"\"\n",
        "\n",
        "  N = np.copy(n_offline); # array to store number of samples for each arm\n",
        "  w = np.zeros_like(mu); # store the average w (to be tracked)\n",
        "  wt = np.zeros_like(mu); # store the current w\n",
        "\n",
        "  for _ in range(10):\n",
        "    for at in range(0,K):\n",
        "      X = sample(mu, dist, at);\n",
        "      mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "      N[at] += 1;\n",
        "\n",
        "  w = 1/K * np.ones_like(mu);\n",
        "  wt = w;\n",
        "  t = 10*K;\n",
        "\n",
        "  while (not Stop(mu_hat, N, delta, dist)):\n",
        "    if float(np.sqrt(np.floor(t/K))).is_integer():\n",
        "      # print(t, \"~~~~~~~ Entering Forced Exploration ~~~~~~~\")\n",
        "      t_ = 0;\n",
        "      while (t_ < K):\n",
        "        # Forced Exploration\n",
        "        wt = 1/K * np.ones_like(mu);\n",
        "\n",
        "        w = (1-1/(t+t_))*w + 1/(t+t_)*wt\n",
        "        at = track(w, N);\n",
        "        X = sample(mu, dist, at);\n",
        "        mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "        N[at] += 1;\n",
        "        t_ += 1;\n",
        "      t += K;\n",
        "      # print(t, \"~~~~~~~ Completed FE, computing oracle weights ~~~~~~~\")\n",
        "\n",
        "      bisection_solver = OfflineOnlineMaxMinSolver(mu_hat, 1e-6, n_offline, dist);\n",
        "      wt = bisection_solver.compute_optimal_proportions();\n",
        "    else:\n",
        "      w = (1-1/t)*w + (1/t)*wt\n",
        "      at = track(w,N);\n",
        "      X = sample(mu, dist, at);\n",
        "      mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "      N[at] += 1;\n",
        "      t += 1;\n",
        "    if t%1000 == 0:\n",
        "      print(t, \"~~~~~~~~~~iteration~~~~~~~~~~~\")\n",
        "\n",
        "  return np.argmax(mu_hat, axis=0), t;"
      ],
      "metadata": {
        "id": "7XCtUFmIxNBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Beta Top2"
      ],
      "metadata": {
        "id": "WKwgYCn2lBgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement beta top2\n",
        "def beta_top2(mu, K, dist, delta, beta_alg=0.5):\n",
        "  \"\"\"\n",
        "  mu : mean vector\n",
        "  K : number of arms\n",
        "  dist : SPEF (Gaussian or Bernoulli)\n",
        "  delta : error bound\n",
        "  beta_alg: probability of choosing the leader\n",
        "  \"\"\"\n",
        "\n",
        "  N = np.zeros_like(mu); # array to store number of samples for each arm\n",
        "  mu_hat = np.zeros_like(mu); # store estimated means\n",
        "  n_instances = 1\n",
        "  t=0\n",
        "\n",
        "  for _ in range(9):\n",
        "    for at in range(0,K):\n",
        "      X = sample(mu, dist, at);\n",
        "      mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "      N[at] += 1;\n",
        "\n",
        "  t = 9*K;\n",
        "\n",
        "  while (not Stop(mu_hat, N, delta, dist)):\n",
        "    best_arm_idx = np.argmax(mu_hat);\n",
        "    kl_objective = KLObjective(mu_hat, N/np.sum(N), dist)\n",
        "    kl_objective[best_arm_idx, np.arange(n_instances)] = np.Inf\n",
        "    uniform_rnd = np.random.uniform(size=1)\n",
        "\n",
        "    # can't implement this using if else?\n",
        "    # pull best arm if the sum_kl_ratio is greater than 1\n",
        "    if uniform_rnd < beta_alg:\n",
        "      # pull best arm\n",
        "      X = sample(mu, dist, best_arm_idx)\n",
        "      mu_hat[best_arm_idx] = (mu_hat[best_arm_idx] * N[best_arm_idx] + X)/(N[best_arm_idx] + 1)\n",
        "      N[best_arm_idx] += 1\n",
        "    else:\n",
        "      competitor = np.argmin(kl_objective)\n",
        "      X = sample(mu, dist, competitor)\n",
        "      mu_hat[competitor] = (mu_hat[competitor] * N[competitor] + X)/(N[competitor] + 1)\n",
        "      N[competitor] += 1\n",
        "\n",
        "    t += 1\n",
        "    if float(np.sqrt(np.floor(t/K))).is_integer():\n",
        "      #print(t, \"~~~~~~~ Entering Forced Exploration ~~~~~~~\")\n",
        "      t_ = 0;\n",
        "      while (t_ < K):\n",
        "        at = t_\n",
        "        X = sample(mu, dist, at);\n",
        "        mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "        N[at] += 1;\n",
        "        t_ += 1;\n",
        "      t += K;\n",
        "      #print(t, \"~~~~~~~ Completed FE, computing oracle weights ~~~~~~~\")\n",
        "\n",
        "  print('arm sampling proportions')\n",
        "  print(N/np.sum(t))\n",
        "  return np.argmax(mu_hat, axis=0), t;"
      ],
      "metadata": {
        "id": "8BV9GcadlB5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Online Top2"
      ],
      "metadata": {
        "id": "SfQNPqmJlFRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement top2\n",
        "def online_top2(mu, K, dist, delta):\n",
        "  \"\"\"\n",
        "  mu : mean vector\n",
        "  K : number of arms\n",
        "  dist : SPEF (Gaussian or Bernoulli)\n",
        "  delta : error bound\n",
        "  \"\"\"\n",
        "\n",
        "  N = np.zeros_like(mu); # array to store number of samples for each arm\n",
        "  mu_hat = np.zeros_like(mu); # store estimated means\n",
        "  n_instances = 1\n",
        "  t=0\n",
        "\n",
        "  for at in range(0,K):\n",
        "    X = sample(mu, dist, at);\n",
        "    mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "    N[at] += 1;\n",
        "\n",
        "  t = K;\n",
        "\n",
        "  while (not Stop(mu_hat, N, delta, dist)):\n",
        "    best_arm_idx = np.argmax(mu_hat);\n",
        "    # Check ratio constraint\n",
        "    kl_ratio = KLRatio(mu_hat, N/np.sum(N), dist)\n",
        "    kl_ratio[best_arm_idx, np.arange(n_instances)] = 0\n",
        "    sum_kl_ratio = np.sum(kl_ratio, axis=0)\n",
        "    kl_objective = KLObjective(mu_hat, N/np.sum(N), dist)\n",
        "    kl_objective[best_arm_idx, np.arange(n_instances)] = np.Inf\n",
        "\n",
        "    # can't implement this using if else?\n",
        "    # pull best arm if the sum_kl_ratio is greater than 1\n",
        "    if sum_kl_ratio > 1:\n",
        "      # pull best arm\n",
        "      X = sample(mu, dist, best_arm_idx)\n",
        "      mu_hat[best_arm_idx] = (mu_hat[best_arm_idx] * N[best_arm_idx] + X)/(N[best_arm_idx] + 1)\n",
        "      N[best_arm_idx] += 1\n",
        "    else:\n",
        "      competitor = np.argmin(kl_objective)\n",
        "      X = sample(mu, dist, competitor)\n",
        "      mu_hat[competitor] = (mu_hat[competitor] * N[competitor] + X)/(N[competitor] + 1)\n",
        "      N[competitor] += 1\n",
        "\n",
        "    t += 1\n",
        "    if float(np.sqrt(np.floor(t/K))).is_integer():\n",
        "      #print(t, \"~~~~~~~ Entering Forced Exploration ~~~~~~~\")\n",
        "      t_ = 0;\n",
        "      while (t_ < K):\n",
        "        at = t_\n",
        "        X = sample(mu, dist, at);\n",
        "        mu_hat[at] = (mu_hat[at] * N[at] + X)/(N[at] + 1);\n",
        "        N[at] += 1;\n",
        "        t_ += 1;\n",
        "      t += K;\n",
        "      #print(t, \"~~~~~~~ Completed FE, computing oracle weights ~~~~~~~\")\n",
        "\n",
        "  print('arm sampling proportions')\n",
        "  print(N/np.sum(t))\n",
        "  return np.argmax(mu_hat, axis=0), t;"
      ],
      "metadata": {
        "id": "T7rSX8iblFtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test BAI-MAB algorithms"
      ],
      "metadata": {
        "id": "NFhyryEqlK7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Online experiments"
      ],
      "metadata": {
        "id": "P7qTPBLjlNZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the problem instance\n",
        "\n",
        "K = 3 # number of arms\n",
        "delta = 1e-3\n",
        "gap = 0.05 # gap between arms\n",
        "mu = np.random.uniform(0.0, 1.0, K) # expected reward of the arms\n",
        "mu[0] = 0.4\n",
        "mu[1] = 0.4\n",
        "mu[2] = mu[1] + gap\n",
        "print(mu)\n",
        "mu = mu[:,None]\n",
        "\n",
        "dist = 'Gaussian';\n",
        "n_offline = np.zeros_like(mu);\n",
        "s_hat = np.zeros_like(mu);\n",
        "mu_hat = np.zeros_like(mu);"
      ],
      "metadata": {
        "id": "13Z9crMElLNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "betas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "reps = 50\n",
        "result_beta_top2 = np.zeros((len(betas), reps))\n",
        "for i in range(len(betas)):\n",
        "  beta_alg = betas[i]\n",
        "  for j in range(reps):\n",
        "    tas = beta_top2(mu, K, dist, delta, beta_alg)\n",
        "    print(tas)\n",
        "    assert(tas[0][0] == np.argmax(mu))\n",
        "    result_beta_top2[i,j] = tas[1]\n",
        "    print(result_beta_top2[i,j])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BDTa8QHElPqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_top2 = np.zeros((1, reps))\n",
        "for j in range(reps):\n",
        "  tas = online_top2(mu, K, dist, delta)\n",
        "  print(tas)\n",
        "  assert(tas[0][0] == np.argmax(mu))\n",
        "  result_top2[0,j] = tas[1]\n",
        "  print(result_top2[0,j])"
      ],
      "metadata": {
        "id": "NiaqzvFglRTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_batch_tas = np.zeros((1, reps))\n",
        "for j in range(reps):\n",
        "  n_offline = np.zeros_like(mu);\n",
        "  mu_hat = np.zeros_like(mu);\n",
        "  tas = batched_tas(mu, K, mu_hat, n_offline, dist, delta)\n",
        "  print(tas)\n",
        "  assert(tas[0][0] == np.argmax(mu))\n",
        "  result_batch_tas[0,j] = tas[1]\n",
        "  print(result_batch_tas[0,j])"
      ],
      "metadata": {
        "id": "ySHDCej_lTUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Offline+Online Experiments"
      ],
      "metadata": {
        "id": "5fqtRlHqlnO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the problem instance\n",
        "\n",
        "K = 10 # number of arms\n",
        "delta = 1e-3\n",
        "gap = 0.1 # gap between arms\n",
        "mu = np.random.uniform(0.0, 1.0, K) # expected reward of the arms\n",
        "mu = 0.4*np.ones(K)\n",
        "mu[K-1] = 0.4+gap\n",
        "print(mu)\n",
        "mu = mu[:,None]\n",
        "\n",
        "dist = 'Gaussian';\n",
        "n_offline = np.zeros_like(mu);\n",
        "s_hat = np.zeros_like(mu);\n",
        "mu_hat = np.zeros_like(mu);"
      ],
      "metadata": {
        "id": "2pSm4u16lnim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Online+offline Bisection search algorithm\n",
        "ns = [1, 10, 100, 1000, 5000, 10000, 20000, 50000]\n",
        "reps = 50\n",
        "result_oo = np.zeros((len(ns), reps))\n",
        "for i in range(len(ns)):\n",
        "  ni = ns[i]\n",
        "  for j in range(reps):\n",
        "    # generate offline data\n",
        "    n_offline = np.ones(mu.shape)*ni\n",
        "    mu_hat = np.zeros_like(mu)\n",
        "    for k in range(mu.shape[0]):\n",
        "      mu_hat[k, 0] = np.mean(np.random.normal(mu[k,0], 1, size=int(n_offline[k])))\n",
        "    tas = batched_tas(mu, K, np.copy(mu_hat), np.copy(n_offline), dist, delta)\n",
        "    print(tas)\n",
        "    assert(tas[0][0] == np.argmax(mu))\n",
        "    result_oo[i,j] = tas[1]\n",
        "    print(result_oo[i,j])"
      ],
      "metadata": {
        "id": "Ka43mik4lpMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result\n",
        "online_samples_list = []\n",
        "for i in range(1, len(ns)):\n",
        "  online_samples_list += [result_oo[i,:]]\n",
        "fig = plt.figure()\n",
        "plt.rcParams[\"figure.figsize\"] = (6.4, 4.8)\n",
        "\n",
        "# Creating axes instance\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "# Creating plot\n",
        "bp = ax.boxplot(online_samples_list)\n",
        "plt.xticks([1, 2, 3, 4, 5, 6,  7], [K*x for x in ns[1:]])\n",
        "plt.xlabel('Offline samples (well explored offline data)', fontsize=15)\n",
        "plt.ylabel('Stopping Time', fontsize=15)\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 15)\n",
        "plt.yscale(\"log\")\n",
        "plt.title(r'Bandits with $10$ arms'.format(1), fontsize=20)\n",
        "\n",
        "\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SzZCplQslz_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
