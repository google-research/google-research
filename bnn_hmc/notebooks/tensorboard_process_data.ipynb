{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.getcwd(), \"../.runs/seq_multiseed/cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = os.listdir(log_dir)\n",
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils to load experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sgd_events(eventfile):\n",
    "    value_by_tag = defaultdict(dict)\n",
    "    for event in summary_iterator(eventfile):\n",
    "        for value in event.summary.value:\n",
    "            value_by_tag[value.tag][event.step] = tf.make_ndarray(value.tensor).squeeze()\n",
    "    df = pd.DataFrame(value_by_tag).rename_axis(\"step\")\n",
    "    return df.drop(columns=['command']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sgd_experiment_logs(experiment, experiment_instance=None, events_log=None):\n",
    "    if experiment_instance is None:\n",
    "        instances = os.listdir(os.path.join(log_dir, experiment))\n",
    "        assert len(instances) == 1, f\"Manually need to provice experiment instance: {instances}\"\n",
    "        experiment_instance = instances[0]\n",
    "    if events_log is None:\n",
    "        events_log = max((os.path.getmtime(os.path.join(log_dir, experiment, experiment_instance, filename)), filename)\n",
    "                                for filename in filter(\n",
    "                                    lambda filename: filename.startswith(\"event\"),\n",
    "                                    os.listdir(os.path.join(log_dir, experiment, experiment_instance))\n",
    "                                ))[1]\n",
    "    eventfile = os.path.join(log_dir, experiment, experiment_instance, events_log)\n",
    "    df = parse_sgd_events(eventfile)\n",
    "    return df.iloc[list(range(10, len(df), 10)) + [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mfvi_events(eventfile):\n",
    "    value_by_tag = defaultdict(dict)\n",
    "    for event in summary_iterator(eventfile):\n",
    "        for value in event.summary.value:\n",
    "            value_by_tag[value.tag][event.step] = tf.make_ndarray(value.tensor).squeeze()\n",
    "    df = pd.DataFrame(value_by_tag).rename_axis(\"step\")\n",
    "    # TODO generate insights from sigma histograms\n",
    "    return df.drop(columns=['command', 'MFVI/param_stds']).astype(float)\n",
    "def load_mfvi_experiment_logs(experiment, experiment_instance=None, events_log=None):\n",
    "    if experiment_instance is None:\n",
    "        instances = os.listdir(os.path.join(log_dir, experiment))\n",
    "        assert len(instances) == 1, f\"Manually need to provice experiment instance: {instances}\"\n",
    "        experiment_instance = instances[0]\n",
    "    if events_log is None:\n",
    "        events_log = max((os.path.getmtime(os.path.join(log_dir, experiment, experiment_instance, filename)), filename)\n",
    "                                for filename in filter(\n",
    "                                    lambda filename: filename.startswith(\"event\"),\n",
    "                                    os.listdir(os.path.join(log_dir, experiment, experiment_instance))\n",
    "                                ))[1]\n",
    "    eventfile = os.path.join(log_dir, experiment, experiment_instance, events_log)\n",
    "    df = parse_mfvi_events(eventfile)\n",
    "    return df.iloc[list(range(10, len(df), 10)) + [-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils to clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(xs: pd.Series, q_low=0., q_high=1.):\n",
    "    return xs.clip(*xs.quantile([q_low, q_high]))\n",
    "\n",
    "def rolling_median(xs, window=5, centred=False):\n",
    "    return xs.rolling(window, min_periods=2).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agg(df, ax, label):\n",
    "    ax.plot(df.index, df['mean'], label=label)\n",
    "    ax.fill_between(df.index, df['mean']-df['std'], df['mean']+df['std'], alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repro SGD & VI baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = range(1, 3+1)\n",
    "df_sgd_nonseq = pd.concat({\n",
    "    seed: load_sgd_experiment_logs(\n",
    "        \"../../multiseed/sgd/cifar10\",\n",
    "        experiment_instance=f\"sgd_mom_0.9__lr_sch_i_3e-07___epochs_500_wd_10.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"])\n",
    "# df_sgd_nonseq['test/accuracy'].unstack(\"seed\").apply(winsorize, q_low=0.0).plot()\n",
    "# df_sgd_nonseq.apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)]).pipe(lambda df: plot_agg(df, ax=ax, label=\"SGD\"))\n",
    "SEEDS = range(1, 3+1)\n",
    "df_mfvi_nonseq = pd.concat({\n",
    "    seed: load_mfvi_experiment_logs(\n",
    "        \"../../multiseed/vi/cifar10\",\n",
    "        experiment_instance=f\"mfvi_initsigma_0.01_meaninit__opt_adam__lr_sch_i_0.0001___epochs_300_wd_5.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_mfvi_nonseq.groupby(level=\"step\")['test/accuracy'].agg(['mean', 'std']).pipe(lambda df: plot_agg(df, ax=ax, label=\"MFVI\"))\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_title(\"ResNet-20 FRN Swish on CIFAR10\")\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"plots/nonseq_seed1-3.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS = range(1, 3+1)\n",
    "df_mfvi_split1 = pd.concat({\n",
    "    seed: load_mfvi_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/mfvi_1_of_2\",\n",
    "        experiment_instance=f\"mfvi_initsigma_0.01_meaninit__opt_adam__lr_sch_i_0.0001___epochs_300_wd_5.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).groupby(level=\"step\")['test/accuracy'].agg(['mean', 'std'])\n",
    "df_mfvi_split2 = pd.concat({\n",
    "    seed: load_mfvi_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/mfvi_2_of_2\",\n",
    "        experiment_instance=f\"mfvi_initsigma_0.01_meaninit__opt_adam__lr_sch_i_0.0001___epochs_300_pretr_{pretrain_hex}_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed, pretrain_hex in zip(SEEDS, [7069824, 7235200, 5441280])\n",
    "}, names=[\"seed\", \"step\"]).groupby(level=\"step\")['test/accuracy'].agg(['mean', 'std'])\n",
    "df_sgd_split1 = pd.concat({\n",
    "    seed: load_sgd_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/sgd_1_of_2\",\n",
    "        experiment_instance=f\"sgd_mom_0.9__lr_sch_i_3e-07___epochs_500_wd_10.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)])\n",
    "df_sgd_split2_from_split1_init = pd.concat({\n",
    "    seed: load_sgd_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/sgd_2_of_2_from_split1_init\",\n",
    "        experiment_instance=f\"sgd_mom_0.9__lr_sch_i_3e-07___epochs_500_wd_10.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_agg(df_sgd_nonseq.apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)]), ax=ax, label=\"SGD\")\n",
    "plot_agg(df_mfvi_nonseq.groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)]), ax=ax, label=\"MFVI\")\n",
    "seq_plot_df = pd.concat([\n",
    "    df_mfvi_split1,\n",
    "    df_mfvi_split2.reset_index().assign(step=lambda df: df.step+df_mfvi_split1.index.max()).set_index(\"step\"),\n",
    "])\n",
    "# Halve the epochs as each epoch is only using half the dataset\n",
    "seq_plot_df.index /= 2.0\n",
    "plot_agg(seq_plot_df, ax=ax, label=\"Sequential MFVI\")\n",
    "ax.axvline(x=seq_plot_df.index.max()/2.0, ymin=0, ymax=1, alpha=0.2, dashes=(2,3))\n",
    "ADD_SGD_BASELINE = True\n",
    "if ADD_SGD_BASELINE:\n",
    "    # Add SGD baseline\n",
    "    seq_plot_df = pd.concat([\n",
    "        df_sgd_split1,\n",
    "        df_sgd_split2_from_split1_init.reset_index().assign(step=lambda df: df.step+df_sgd_split1.index.max()).set_index(\"step\"),\n",
    "    ])\n",
    "    seq_plot_df.index /= 2.0\n",
    "    plot_agg(seq_plot_df, ax=ax, label='\"Sequential SGD\"')\n",
    "    ax.axvline(x=seq_plot_df.index.max()/2.0, ymin=0, ymax=1, alpha=0.2, dashes=(2,3))\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_title(\"Sequentially training ResNet-20 FRN Swish on CIFAR10\")\n",
    "ax.legend(loc='lower right')\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"plots/seq_mfvi_random_split_with_baseline_seed1-3.png\", dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but for the stratified experiment\n",
    "SEEDS = range(1, 3+1)\n",
    "df_mfvi_split1_stratified = pd.concat({\n",
    "    seed: load_mfvi_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/mfvi_1_of_2_stratified\",\n",
    "        experiment_instance=f\"mfvi_initsigma_0.01_meaninit__opt_adam__lr_sch_i_0.0001___epochs_300_wd_5.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).groupby(level=\"step\")['test/accuracy'].agg(['mean', 'std'])\n",
    "df_mfvi_split2_stratified = pd.concat({\n",
    "    seed: load_mfvi_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/mfvi_2_of_2_stratified\",\n",
    "        experiment_instance=f\"mfvi_initsigma_0.01_meaninit__opt_adam__lr_sch_i_0.0001___epochs_300_pretr_{pretrain_hex}_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed, pretrain_hex in zip(SEEDS, [276224, 2256096, 3312512])\n",
    "}, names=[\"seed\", \"step\"]).groupby(level=\"step\")['test/accuracy'].agg(['mean', 'std'])\n",
    "df_sgd_split1_stratified = pd.concat({\n",
    "    seed: load_sgd_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/sgd_1_of_2_stratified\",\n",
    "        experiment_instance=f\"sgd_mom_0.9__lr_sch_i_3e-07___epochs_500_wd_10.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)])\n",
    "df_sgd_split2_stratified_from_split1_init = pd.concat({\n",
    "    seed: load_sgd_experiment_logs(\n",
    "        \"../../seq_multiseed/cifar10/sgd_2_of_2_stratified_from_split1_init\",\n",
    "        experiment_instance=f\"sgd_mom_0.9__lr_sch_i_3e-07___epochs_500_wd_10.0_batchsize_80_temp_1.0__seed_{seed}\"\n",
    "    )\n",
    "    for seed in SEEDS\n",
    "}, names=[\"seed\", \"step\"]).apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_agg(df_sgd_nonseq.apply(rolling_median).groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)]), ax=ax, label=\"SGD\")\n",
    "plot_agg(df_mfvi_nonseq.groupby(level=\"step\")['test/accuracy'].agg([partial(pd.Series.mean, skipna=False), partial(pd.Series.std, skipna=False)]), ax=ax, label=\"MFVI\")\n",
    "seq_plot_df = pd.concat([\n",
    "    df_mfvi_split1_stratified,\n",
    "    df_mfvi_split2_stratified.reset_index().assign(step=lambda df: df.step+df_mfvi_split1_stratified.index.max()).set_index(\"step\"),\n",
    "])\n",
    "# Halve the epochs as each epoch is only using half the dataset\n",
    "seq_plot_df.index /= 2.0\n",
    "plot_agg(seq_plot_df, ax=ax, label=\"Sequential MFVI (stratified)\")\n",
    "ax.axvline(x=seq_plot_df.index.max()/2.0, ymin=0, ymax=1, alpha=0.2, dashes=(2,3))\n",
    "ADD_SGD_BASELINE = True\n",
    "if ADD_SGD_BASELINE:\n",
    "    # Add SGD baseline\n",
    "    seq_plot_df = pd.concat([\n",
    "        df_sgd_split1_stratified,\n",
    "        df_sgd_split2_stratified_from_split1_init.reset_index().assign(step=lambda df: df.step+df_sgd_split1.index.max()).set_index(\"step\"),\n",
    "    ])\n",
    "    seq_plot_df.index /= 2.0\n",
    "    plot_agg(seq_plot_df, ax=ax, label='\"Sequential SGD\" (stratified)')\n",
    "    ax.axvline(x=seq_plot_df.index.max()/2.0, ymin=0, ymax=1, alpha=0.2, dashes=(2,3))\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_title(\"Sequentially training ResNet-20 FRN Swish on CIFAR10\")\n",
    "ax.legend(loc='center right')\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"plots/seq_mfvi_stratified_split_with_baseline_seed1-3.png\", dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
